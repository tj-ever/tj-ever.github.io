{"meta":{"title":"Ever的个人博客","subtitle":"","description":"Ever的个人博客","author":"Ever","url":"https://tj-ever.github.io","root":"/"},"pages":[],"posts":[{"title":"Rabbitmq 消息可靠性投递两种方案","slug":"Rabbitmq实现消息可靠性投递","date":"2021-10-31T16:00:00.000Z","updated":"2021-11-01T08:33:38.395Z","comments":true,"path":"2021/11/01/Rabbitmq实现消息可靠性投递/","link":"","permalink":"https://tj-ever.github.io/2021/11/01/Rabbitmq%E5%AE%9E%E7%8E%B0%E6%B6%88%E6%81%AF%E5%8F%AF%E9%9D%A0%E6%80%A7%E6%8A%95%E9%80%92/","excerpt":"","text":"消息入库打标方案（需要跨库事务）消息可靠性投递，就是确保生产端的消息准确无误的发送到消费端进行消费。 流程图如下，共七步： 正常链路流程 (该环节调用了操作了二次数据库):在创建订单的操作的时候，把数据插入到订单相关的表中,并且构造调用物流模块的数据消息，把消息插入到消息表中,初始状态为0 把物流消息投递到消息队列中 消息队列访问一个确认消息，并且由订单服务来监控mq-server的确认消息 根据收到的确认消息来更新数据库中的消息记录的状态 异常链路流程 (该环节调用了操作了二次数据库):在创建订单的操作的时候，把数据插入到订单相关的表中,并且构造调用物流模块的数据消息，把消息插入到消息表中,初始状态为0 把物流消息投递到消息队列中 由于网络闪断，导致消费端监控mq服务访问的确认消息没有收到，那么在msg_db中的那条消息的状态永远就是0状态。这个时候，我们需要对这种情况下做出补偿 补偿机制: 启动一个分布式的定时任务,不定时的去扫描msg_db的这个表，状态为0的消息记录，在这里我们可以根据业务来设置扫描重发规则 规则1：插入msg_db 表中5Min后状态还是为0的记录，进行消息重试 规则2:若重试的次数超过五次状态还是为0的话，我们就把消息状态改为2，此时我们需要人工的去确认状态为2的消息是什么原因导致没有成功的 消息入库打标的缺点: 在第一步的过程中，既插入了业务数据表，也同时插入了消息记录表，进行了二次db操作，在高并发的环境下，这个环境就会造成性能瓶颈 直接上代码，以保存订单消费库存为例。 生产者代码消息路由配置类 12345678910111213141516171819@Configurationpublic class RabbitmqConfig &#123; @Bean public DirectExchange orderExchange() &#123; DirectExchange directExchange = new DirectExchange(&quot;order-exchange&quot;,true,false); return directExchange; &#125; @Bean public Queue orderQueue() &#123; Queue queue = new Queue(&quot;order-queue&quot;,true,false,false); return queue; &#125; @Bean public Binding orderBinding() &#123; return BindingBuilder.bind(orderQueue()).to(orderExchange()).with(&quot;order-key&quot;); &#125;&#125; 消息发送组件 12345678910111213141516171819202122232425262728@Component@Slf4jpublic class MsgSender implements InitializingBean &#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private MsgComfirm msgComfirm; @Autowired private MsgRetrunListener msgRetrunListener; public void senderMsg(Order order) &#123; CorrelationData correlationData = new CorrelationData(order.getId()); rabbitTemplate.convertAndSend(&quot;order-exchange&quot;,&quot;order-key&quot;, msgTxtBo, correlationData); &#125; @Override public void afterPropertiesSet() throws Exception &#123; rabbitTemplate.setConfirmCallback(msgComfirm); rabbitTemplate.setReturnCallback(msgRetrunListener); //设置消息转换器 Jackson2JsonMessageConverter jackson2JsonMessageConverter = new Jackson2JsonMessageConverter(); rabbitTemplate.setMessageConverter(jackson2JsonMessageConverter); &#125;&#125; 消息确认回调组件 12345678910111213141516171819202122@Component@Slf4jpublic class MsgComfirm implements RabbitTemplate.ConfirmCallback&#123; @Autowired private MsgContentMapper msgContentMapper; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; String msgId = correlationData.getId(); if(ack) &#123; log.info(&quot;消息Id:&#123;&#125;对应的消息被broker签收成功&quot;,msgId); //更新消息表状态发送成功 updateMsgStatusWithAck(msgId); &#125;else&#123; log.warn(&quot;消息Id:&#123;&#125;对应的消息被broker签收失败:&#123;&#125;&quot;,msgId,cause); //更新消息表状态发送失败 updateMsgStatusWithNack(msgId,cause); &#125; &#125;&#125; 消息不可达回调组件 123456789101112131415161718192021222324252627@Component@Slf4jpublic class MsgRetrunListener implements RabbitTemplate.ReturnCallback &#123; @Autowired private MsgContentMapper msgContentMapper; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; try&#123; ObjectMapper objectMapper = new ObjectMapper(); MsgTxtBo msgTxtBo = objectMapper.readValue(message.getBody(),MsgTxtBo.class); log.info(&quot;无法路由消息内容:&#123;&#125;,cause:&#123;&#125;&quot;,msgTxtBo,replyText); //构建消息对象 MessageContent messageContent = new MessageContent(); messageContent.setErrCause(replyText); messageContent.setUpdateTime(new Date()); messageContent.setMsgStatus(&quot;send faild&quot;); messageContent.setMsgId(msgTxtBo.getMsgId()); //更新消息表 msgContentMapper.updateMsgStatus(messageContent); &#125;catch (Exception e) &#123; log.error(&quot;更新消息表异常:&#123;&#125;&quot;,e); &#125; &#125;&#125; 控制层 1234@RequestMapping(&quot;/saveOrder&quot;)public void saveOrder(Order order) throws JsonProcessingException &#123; orderInfoService.saveOrderInfoWithMessage(oid);&#125; 业务层 12345678910111213141516171819202122232425262728public void saveOrderInfoWithMessage(Order order) throws JsonProcessingException &#123; //构建消息对象 (省略构建) MessageContent messageContent = new MessageContent(); //保存数据库 saveOrderInfo(order,messageContent); //构建消息发送对象 (省略构建) MsgTxtBo msgTxtBo = new MsgTxtBo(); //发送消息 msgSender.senderMsg(msgTxtBo);&#125;//保存数据操作@Transactional@Overridepublic void saveOrderInfo(Order order, MessageContent messageContent) &#123; try &#123; //插入业务表 orderInfoMapper.saveOrderInfo(order); //插入消息表 msgContentMapper.saveMsgContent(messageContent); &#125;catch (Exception e) &#123; log.error(&quot;操作数据库失败:&#123;&#125;&quot;,e); throw new RuntimeException(&quot;操作数据库失败&quot;); &#125;&#125; 定时任务 重发未送达消息 12345678910111213141516171819202122232425262728293031@Component@Slf4jpublic class RetryMsgTask &#123; @Autowired private MsgSender msgSender; @Autowired private MsgContentMapper msgContentMapper; @Scheduled(initialDelay = 5000,fixedDelay = 5000) public void retrySend() &#123; //查询五分钟消息状态还没有完结的消息 List&lt;MessageContent&gt; messageContentList = msgContentMapper.qryNeedRetryMsg(); //满足重发状态的重新发送 for(MessageContent messageContent:messageContentList) &#123; if(messageContent.getMaxRetry()&gt;messageContent.getCurrentRetry()) &#123; MsgTxtBo msgTxtBo = new MsgTxtBo(); msgTxtBo.setMsgId(messageContent.getMsgId()); msgTxtBo.setProductNo(messageContent.getProductNo()); msgTxtBo.setOrderNo(messageContent.getOrderNo()); //更新消息重试次数 msgContentMapper.updateMsgRetryCount(msgTxtBo.getMsgId()); msgSender.senderMsg(msgTxtBo); &#125;else &#123; log.warn(&quot;消息:&#123;&#125;以及达到最大重试次数&quot;,messageContent); &#125; &#125; &#125;&#125; 消费者代码消费者组件（未加分布式锁，可能存在重复消费问题） ps：比如消息刚到消费者正准备处理，服务端网络抖动又重发一条，这是就消费两条 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Component@Slf4jpublic class MqConsumer &#123; public static final String ORDER_TO_PRODUCT_QUEUE_NAME = &quot;order-to-product.queue&quot;; public static final String LOCK_KEY=&quot;LOCK_KEY&quot;; @Autowired private IProductService productService; @Autowired private MsgContentMapper msgContentMapper; @Autowired private RedisTemplate redisTemplate; /** * 没有加分布式锁的版本,可能存在重复消费问题 */ @RabbitListener(queues = &#123;ORDER_TO_PRODUCT_QUEUE_NAME&#125;) @RabbitHandler public void consumerMsg(Message message, Channel channel) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); MsgTxtBo msgTxtBo = objectMapper.readValue(message.getBody(),MsgTxtBo.class); log.info(&quot;消费消息:&#123;&#125;&quot;,msgTxtBo); Long deliveryTag = (Long) message.getMessageProperties().getDeliveryTag(); try &#123; //更新消息表业务表 productService.updateProductStore(msgTxtBo); //模拟网络抖动 导致重复发送 System.out.println(1/0); //消息签收 channel.basicAck(deliveryTag,false); &#125;catch (Exception e) &#123; //更新msg表为消费失败 //更新消息表状态 MessageContent messageContent = new MessageContent(); messageContent.setMsgId(msgTxtBo.getMsgId()); messageContent.setUpdateTime(new Date()); messageContent.setMsgStatus(MsgStatusEnum.CONSUMER_FAIL.getCode()); msgContentMapper.updateMsgStatus(messageContent); channel.basicReject(deliveryTag,false); &#125; &#125;&#125; 消费者组件（带分布式锁） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Component@Slf4jpublic class MqConsumer &#123; public static final String ORDER_TO_PRODUCT_QUEUE_NAME = &quot;order-to-product.queue&quot;; public static final String LOCK_KEY=&quot;LOCK_KEY&quot;; @Autowired private IProductService productService; @Autowired private MsgContentMapper msgContentMapper; @Autowired private RedisTemplate redisTemplate; @RabbitListener(queues = &#123;ORDER_TO_PRODUCT_QUEUE_NAME&#125;) @RabbitHandler public void consumerMsgWithLock(Message message, Channel channel) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); MsgTxtBo msgTxtBo = objectMapper.readValue(message.getBody(), MsgTxtBo.class); Long deliveryTag = (Long) message.getMessageProperties().getDeliveryTag(); if (redisTemplate.opsForValue().setIfAbsent(LOCK_KEY + msgTxtBo.getMsgId(), msgTxtBo.getMsgId())) &#123; log.info(&quot;消费消息:&#123;&#125;&quot;, msgTxtBo); try &#123; //更新消息表也业务表 productService.updateProductStore(msgTxtBo); //消息签收 System.out.println(1/0); channel.basicAck(deliveryTag, false); &#125; catch (Exception e) &#123; /** * 更新数据库异常说明业务没有操作成功需要删除分布式锁 * BizExp自行封装业务异常 */ if (e instanceof BizExp) &#123; BizExp bizExp = (BizExp) e; log.info(&quot;数据业务异常:&#123;&#125;,即将删除分布式锁&quot;, bizExp.getErrMsg()); //删除分布式锁 redisTemplate.delete(LOCK_KEY); &#125; //更新消息表状态 MessageContent messageContent = new MessageContent(); messageContent.setMsgStatus(&quot;send success&quot;); messageContent.setUpdateTime(new Date()); messageContent.setErrCause(e.getMessage()); messageContent.setMsgId(msgTxtBo.getMsgId()); msgContentMapper.updateMsgStatus(messageContent); channel.basicReject(deliveryTag,false); &#125; &#125; else &#123; log.warn(&quot;请不要重复消费消息&#123;&#125;&quot;, msgTxtBo); channel.basicReject(deliveryTag,false); &#125; &#125;&#125; 业务层 12345678910111213141516171819202122@Transactional@Overridepublic boolean updateProductStore(MsgTxtBo msgTxtBo) &#123; boolean updateFlag = true; try&#123; //更新库存 productInfoMapper.updateProductStoreById(msgTxtBo.getProductNo()); //更新消息表状态 MessageContent messageContent = new MessageContent(); messageContent.setMsgId(msgTxtBo.getMsgId()); messageContent.setUpdateTime(new Date()); messageContent.setMsgStatus(&quot;send success&quot;); msgContentMapper.updateMsgStatus(messageContent); //System.out.println(1/0); &#125;catch (Exception e) &#123; log.error(&quot;更新数据库失败:&#123;&#125;&quot;,e); throw new BizExp(0,&quot;更新数据库异常&quot;); &#125; return updateFlag;&#125; 延时投递，二次确认检测，回调检测方案（无需跨库事务） 需要新增一个毁掉检查服务。 在order服务中，执行1，2，3步骤 第1，2步将业务数据插入数据库，同时发送入库消息给到mq服务 其中第三步发送延迟检查消息的时间要大于库存服务和回调检查服务的执行时间，目的是为了在一开始创建订单后，立马发送个延迟消息，半小时后再检查是否操作成功，没有成功则重发消息 1234567891011121314151617181920public void saveOrderInfoWithMessage(OrderInfo orderInfo) &#123; //构建消息对象 MessageContent messageContent = builderMessageContent(orderInfo.getOrderNo(),orderInfo.getProductNo()); //保存数据库 saveOrderInfo(orderInfo); //构建消息发送对象 MsgTxtBo msgTxtBo = new MsgTxtBo(); msgTxtBo.setMsgId(messageContent.getMsgId()); msgTxtBo.setOrderNo(orderInfo.getOrderNo()); msgTxtBo.setProductNo(orderInfo.getProductNo()); //第一次发送消息 msgSender.senderMsg(msgTxtBo); //发送延时消息 msgSender.senderDelayCheckMsg(msgTxtBo); &#125; 在库存服务中，执行4，5步骤 第四步监听入库消息，执行业务操作。第五步发送业务成功的消息到mq服务器 12345678910111213141516171819202122232425262728293031@RabbitListener(queues = &#123;ORDER_TO_PRODUCT_QUEUE_NAME&#125;) @RabbitHandler public void consumerMsgWithLock(Message message, Channel channel) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); MsgTxtBo msgTxtBo = objectMapper.readValue(message.getBody(), MsgTxtBo.class); Long deliveryTag = (Long) message.getMessageProperties().getDeliveryTag(); if (redisTemplate.opsForValue().setIfAbsent(LOCK_KEY + msgTxtBo.getMsgId(), msgTxtBo.getMsgId())) &#123; log.info(&quot;消费消息:&#123;&#125;&quot;, msgTxtBo); try &#123; //更新消息表也业务表 productService.updateProductStore(msgTxtBo); //发送一条确认消费消息到callback服务上 msgSender.senderMsg(msgTxtBo); //消息签收 channel.basicAck(deliveryTag,false); &#125; catch (Exception e) &#123; if (e instanceof BizExp) &#123; BizExp bizExp = (BizExp) e; log.info(&quot;数据业务异常:&#123;&#125;,即将删除分布式锁&quot;, bizExp.getErrMsg()); //删除分布式锁 redisTemplate.delete(LOCK_KEY); &#125; &#125; &#125; else &#123; log.warn(&quot;请不要重复消费消息&#123;&#125;&quot;, msgTxtBo); channel.basicReject(deliveryTag,false); &#125; &#125; 在回调服务中，执行6，7，8，9，10操作 第六步需要创建监听方法，监听第五步的业务操作成功消息 第七步入库消息表（能存在表里说明业务肯定执行成功） 第8，9，10步需要创建监听方法，监听订单服务发出的延迟检查消息，然后判断消息是否存在于消息表中，若不存在，则重发消息 1234567891011121314151617181920212223242526@RabbitListener(queues = &#123;MqConst.ORDER_TO_PRODUCT_DELAY_QUEUE_NAME&#125;) @RabbitHandler public void consumerCheckMsg(Message message, Channel channel) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); MsgTxtBo msgTxtBo = objectMapper.readValue(message.getBody(), MsgTxtBo.class); System.out.println(&quot;==================&gt;&quot;+msgTxtBo.toString()); Long deliveryTag = (Long) message.getMessageProperties().getDeliveryTag(); //替换延时消息ID String msgId = msgTxtBo.getMsgId().replace(&quot;_delay&quot;,&quot;&quot;); MessageContent messageContent = msgContentMapper.qryMessageContentById(msgId); log.info(&quot;消费延时消息:&#123;&#125;&quot;,msgTxtBo.toString()); //表示消息消费者没有发送确认消息,需要回调生产者重新发送消息 if(messageContent == null) &#123; //回调订单服务,从新发送消息 RestTemplate restTemplate = new RestTemplate(); restTemplate.postForEntity(&quot;http://localhost:8080/retryMsg&quot;,msgTxtBo,String.class); &#125; //签收消息 channel.basicAck(deliveryTag,false); &#125;","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://tj-ever.github.io/tags/rabbitmq/"}]},{"title":"Rabbitmq 高级特性及整合springboot","slug":"Rabbitmq 高级特性及整合springboot","date":"2021-10-24T16:00:00.000Z","updated":"2021-11-01T07:07:26.975Z","comments":true,"path":"2021/10/25/Rabbitmq 高级特性及整合springboot/","link":"","permalink":"https://tj-ever.github.io/2021/10/25/Rabbitmq%20%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7%E5%8F%8A%E6%95%B4%E5%90%88springboot/","excerpt":"","text":"消息幂等性对接口发起的一次调用和多次调用，结果都是一致的。 某些接口具有天然的幂等性: 比如长查询接口，不管是查询一次还是多次，返回的结果都 是一致的 MQ 是如何解决幂等性的发送消息的流程 消息生产者向Mq服务端发送消息 mq 服务端把消息进行落地 消息服务端向消息生产者发送ack 消息消费者消费消息 消费者发送ack mq服务将落地消息删除 消息重复发送的原因为了保障消息的百分之百的投递，我们使用了消息重发，确认机制，使得消息可能被重复发送，由上图可知，由于网络原因，第三步ack丢失还是第五步的ack丢失，都会导致消息重复发送 mq服务端如何保证幂等性消息队列的服务中，对每一条消息都会生成一个全局唯一的与业务无关的ID(inner_msg_id),当mq_server 接受到消息的时候，先根据inner_msg_id 是否需要重复发送，再决定消息是否落DB ,这样保证每条消息都 只会落一次DB 消费端如何来做到幂等性对每条消息做生成一个唯一性的ID 通过redis的来setnx命令来保证幂等性。 整合springboot创建两个工程，一个生产者provider，一个消费者consumer 代码结构如下图 pom依赖 12345678910111213141516171819202122232425&lt;!--rabbitmq--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; yml文件 12345678910111213server: port: 9021spring: application: name: rabbitmq-provider #配置rabbitMq 服务器 rabbitmq: host: 127.0.0.1 port: 5672 username: admin password: admin #虚拟host 可以不设置,使用server默认host virtual-host: /tj-vhost direct模式在生产者provider下创建direct模式配置类 123456789101112131415161718192021222324252627@Configurationpublic class DirectRabbitConfig &#123; private static final String EXCHANGE = &quot;tj-direct-exchange&quot;; private static final String QUEUE = &quot;tj-direct-queue&quot;; private static final String ROUTING_KEY = &quot;tj.direct&quot;; @Bean DirectExchange directExchange() &#123; return new DirectExchange(EXCHANGE, true, false); &#125; @Bean public Queue directQueue() &#123; // durable:是否持久化,默认是false,持久化队列：会被存储在磁盘上，当消息代理重启时仍然存在，暂存队列：当前连接有效 // exclusive:默认也是false，只能被当前创建的连接使用，而且当连接关闭后队列即被删除。此参考优先级高于durable // autoDelete:是否自动删除，当没有生产者或者消费者使用此队列，该队列会自动删除。 //一般设置一下队列的持久化就好,其余两个就是默认false return new Queue(QUEUE, true); &#125; @Bean Binding bindingDirect() &#123; return BindingBuilder.bind(directQueue()).to(directExchange()).with(ROUTING_KEY); &#125;&#125; 创建测试类，用于发送消息 12345678910111213141516@SpringBootTestclass ProviderApplicationTests &#123; @Autowired RabbitTemplate rabbitTemplate; //使用RabbitTemplate,这提供了接收/发送等等方法 @Test public void sendDirectMessage() &#123; for (int i = 0; i &lt; 10; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, i); map.put(&quot;messageData&quot;, &quot;第 &quot; + i + &quot; 个消息&quot;); rabbitTemplate.convertAndSend(&quot;tj-direct-exchange&quot;, &quot;tj.direct&quot;, map); &#125; &#125;&#125; 在消费者consumer下创建监听类 12345678910@Component@RabbitListener(queues = &quot;tj-direct-queue&quot;)public class DirectListener &#123; @RabbitHandler public void process(Map testMessage) throws InterruptedException &#123; System.out.println(&quot;DirectListener消费者收到消息 : &quot; + testMessage.toString()); &#125;&#125; 测试结果如下 topic模式在生产者provider下创建topic模式配置类 配置类中定义一个通配符路由，一个固定值路由 123456789101112131415161718192021222324252627282930313233343536@Configurationpublic class TopicRabbitConfig &#123; private static final String EXCHANGE = &quot;tj-topic-exchange&quot;; private static final String QUEUE_SINGLE = &quot;tj-topic-queue-single&quot;; private static final String QUEUE_ALL = &quot;tj-topic-queue-all&quot;; private static final String ROUTING_KEY_SINGLE = &quot;tj.topic.single&quot;; private static final String ROUTING_KEY_ALL = &quot;tj.topic.#&quot;; @Bean TopicExchange topicExchange() &#123; return new TopicExchange(EXCHANGE, true, false); &#125; @Bean public Queue topicQueueSingle() &#123; return new Queue(QUEUE_SINGLE, true); &#125; @Bean public Queue topicQueueAll() &#123; return new Queue(QUEUE_ALL, true); &#125; @Bean Binding bindingTopicSingle() &#123; return BindingBuilder.bind(topicQueueSingle()).to(topicExchange()).with(ROUTING_KEY_1); &#125; @Bean Binding bindingTopicAll() &#123; return BindingBuilder.bind(topicQueueAll()).to(topicExchange()).with(ROUTING_KEY_ALL); &#125;&#125; 创建测试类，用于发送消息 两个测试类对应两个路由，通配符路由可以接受到两种消息，固定路由只能接受到一种消息 12345678910111213141516171819@Testpublic void sendTopicSingleMessage() &#123; for (int i = 0; i &lt; 5; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, i); map.put(&quot;messageData&quot;, &quot;第 &quot; + i + &quot; 个消息&quot;); rabbitTemplate.convertAndSend(&quot;tj-topic-exchange&quot;, &quot;tj.topic.single&quot;, map); &#125;&#125;@Testpublic void sendTopicAllMessage() &#123; for (int i = 0; i &lt; 5; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, i); map.put(&quot;messageData&quot;, &quot;第 &quot; + i + &quot; 个消息&quot;); rabbitTemplate.convertAndSend(&quot;tj-topic-exchange&quot;, &quot;tj.topic.all&quot;, map); &#125;&#125; 在消费者consumer下创建两个监听类，分别监听single路由和all路由 123456789101112131415161718192021222324@Component@RabbitListener(queues = &quot;tj-topic-queue-single&quot;)public class TopicListener &#123; @RabbitHandler public void process(Map testMessage) &#123; System.out.println(&quot;TopicListener 消费者收到消息 : &quot; + testMessage.toString()); &#125;&#125;@Component@RabbitListener(queues = &quot;tj-topic-queue-all&quot;)public class AllTopicListener &#123; @RabbitHandler public void process(Map testMessage) &#123; System.out.println(&quot;AllTopicListener 消费者收到消息 : &quot; + testMessage.toString()); &#125;&#125; sendTopicSingleMessage测试结果如下 sendTopicAllMessage测试结果如下 fanout模式在生产者provider下创建fanout模式配置类 1234567891011121314151617181920212223242526272829303132333435363738@Configurationpublic class FanoutRabbitConfig &#123; private static final String EXCHANGE = &quot;tj-fanout-exchange&quot;; private static final String QUEUE_A = &quot;tj-fanout-queue-a&quot;; private static final String QUEUE_B = &quot;tj-fanout-queue-b&quot;; /** * 因为是扇型交换机, 路由键无需配置,配置也不起作用 */ @Bean public Queue queueA() &#123; return new Queue(QUEUE_A); &#125; @Bean public Queue queueB() &#123; return new Queue(QUEUE_B); &#125; @Bean FanoutExchange fanoutExchange() &#123; return new FanoutExchange(EXCHANGE); &#125; @Bean Binding bindingExchangeA() &#123; return BindingBuilder.bind(queueA()).to(fanoutExchange()); &#125; @Bean Binding bindingExchangeB() &#123; return BindingBuilder.bind(queueB()).to(fanoutExchange()); &#125;&#125; 创建测试类，用于发送消息 123456789@Test public void sendFanoutMessage() &#123; for (int i = 0; i &lt; 5; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, i); map.put(&quot;messageData&quot;, &quot;第 &quot; + i + &quot; 个消息&quot;); rabbitTemplate.convertAndSend(&quot;tj-fanout-exchange&quot;, null, map); &#125; &#125; 在消费者consumer下创建两个监听类，分别监听a，b两个队列 123456789101112131415161718192021@Component@RabbitListener(queues = &quot;tj-fanout-queue-a&quot;)public class FanoutReceiverA &#123; @RabbitHandler public void process(Map testMessage) &#123; System.out.println(&quot;FanoutReceiverA 消费者收到消息 : &quot; + testMessage.toString()); &#125;&#125;@Component@RabbitListener(queues = &quot;tj-fanout-queue-b&quot;)public class FanoutReceiverB &#123; @RabbitHandler public void process(Map testMessage) &#123; System.out.println(&quot;FanoutReceiverB 消费者收到消息 : &quot; + testMessage.toString()); &#125;&#125; 测试结果如下 消息确认机制在生产者配置文件中增加消息确认配置 123456789101112131415161718server: port: 9021spring: application: name: rabbitmq-provider #配置rabbitMq 服务器 rabbitmq: host: 127.0.0.1 port: 5672 username: admin password: admin #虚拟host 可以不设置,使用server默认host virtual-host: /tj-vhost #确认消息已发送到交换机(Exchange) publisher-confirm-type: correlated #确认消息已发送到队列(Queue) publisher-returns: true 配置RabbitTemplate，增加消息确认回调函数 12345678910111213141516171819202122232425262728293031323334@Configurationpublic class RabbitConfig &#123; @Bean public RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory)&#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(); rabbitTemplate.setConnectionFactory(connectionFactory); //设置开启Mandatory,才能触发回调函数,无论消息推送结果怎么样都强制调用回调函数 rabbitTemplate.setMandatory(true); rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; System.out.println(&quot;ConfirmCallback: &quot;+&quot;相关数据：&quot;+correlationData); System.out.println(&quot;ConfirmCallback: &quot;+&quot;确认情况：&quot;+ack); System.out.println(&quot;ConfirmCallback: &quot;+&quot;原因：&quot;+cause); &#125; &#125;); rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() &#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; System.out.println(&quot;ReturnCallback: &quot;+&quot;消息：&quot;+message); System.out.println(&quot;ReturnCallback: &quot;+&quot;回应码：&quot;+replyCode); System.out.println(&quot;ReturnCallback: &quot;+&quot;回应信息：&quot;+replyText); System.out.println(&quot;ReturnCallback: &quot;+&quot;交换机：&quot;+exchange); System.out.println(&quot;ReturnCallback: &quot;+&quot;路由键：&quot;+routingKey); &#125; &#125;); return rabbitTemplate; &#125; &#125; 消息发送情况测试上面写了两个回调函数，一个叫 ConfirmCallback ，一个叫 RetrunCallback； 那么以上这两种回调函数都是在什么情况会触发呢？ 先从总体的情况分析，推送消息存在三种情况： 消息推送到server，但是在server里找不到交换机 消息推送到server，找到交换机了，但是没找到队列 消息推送成功 消息推送到server，但是在server里找不到交换机 写个测试类，把消息推送到名为‘non-existent-exchange’的交换机上（这个交换机是没有创建没有配置的）： 123456789@Test public void testNoExchange() &#123; for (int i = 0; i &lt; 1; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, i); map.put(&quot;messageData&quot;, &quot;第 &quot; + i + &quot; 个消息&quot;); rabbitTemplate.convertAndSend(&quot;non-existent-exchange&quot;, &quot;tj.routing&quot;, map); &#125; &#125; 结论： 这种情况触发的是 ConfirmCallback 回调函数。 消息推送到server，找到交换机了，但是没找到队列 这种情况就是需要新增一个交换机，但是不给这个交换机绑定队列 简单地在DirectRabitConfig里面新增一个直连交换机，名叫‘lonelyDirectExchange’，但没给它做任何绑定配置操作： 1234@Bean DirectExchange lonelyDirectExchange() &#123; return new DirectExchange(&quot;lonelyDirectExchange&quot;); &#125; 写个测试类，把消息推送到名为‘lonelyDirectExchange’的交换机上（这个交换机是没有任何队列配置的）： 123456789@Test public void testLonelyDirectExchange() &#123; for (int i = 0; i &lt; 1; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, i); map.put(&quot;messageData&quot;, &quot;第 &quot; + i + &quot; 个消息&quot;); rabbitTemplate.convertAndSend(&quot;lonelyDirectExchange&quot;, &quot;tj.routing&quot;, map); &#125; &#125; 可以看到两个函数都被调用了 这种情况下，消息是推送成功到服务器了的，所以ConfirmCallback对消息确认情况是true；而在RetrunCallback回调函数的打印参数里面可以看到，消息是推送到了交换机成功了，但是在路由分发给队列的时候，找不到队列，所以报了错误 NO_ROUTE 。结论：这种情况触发的是 ConfirmCallback和RetrunCallback两个回调函数。 消息推送成功 那么测试下，按照正常调用之前消息推送的接口就行，就调用下 /sendFanoutMessage接口，可以看到控制台输出： 结论： 这种情况触发的是 ConfirmCallback 回调函数。 消息确认测试消费者接收到消息的消息确认机制，和生产者的消息确认机制不同，因为消息接收本来就是在监听消息，符合条件的消息就会消费下来。所以，消息接收的确认机制主要存在三种模式： ①自动确认， 这也是默认的消息确认情况。 AcknowledgeMode.NONERabbitMQ成功将消息发出（即将消息成功写入TCP Socket）中立即认为本次投递已经被正确处理，不管消费者端是否成功处理本次投递。所以这种情况如果消费端消费逻辑抛出异常，也就是消费端没有处理成功这条消息，那么就相当于丢失了消息。一般这种情况我们都是使用try catch捕捉异常后，打印日志用于追踪数据，这样找出对应数据再做后续处理。 ② 根据情况确认， 这个不做介绍 ③ 手动确认 ， 这个比较关键，也是我们配置接收消息确认机制时，多数选择的模式。消费者收到消息后，手动调用basic.ack/basic.nack/basic.reject后，RabbitMQ收到这些消息后，才认为本次投递成功。basic.ack用于肯定确认basic.nack用于否定确认（注意：这是AMQP 0-9-1的RabbitMQ扩展）basic.reject用于否定确认，但与basic.nack相比有一个限制:一次只能拒绝单条消息 消费者端以上的3个方法都表示消息已经被正确投递，但是basic.ack表示消息已经被正确处理。而basic.nack,basic.reject表示没有被正确处理： 着重讲下reject，因为有时候一些场景是需要重新入列的。 channel.basicReject(deliveryTag, true); 拒绝消费当前消息，如果第二参数传入true，就是将数据重新丢回队列里，那么下次还会消费这消息。设置false，就是告诉服务器，我已经知道这条消息数据了，因为一些原因拒绝它，而且服务器也把这个消息丢掉就行。 下次不想再消费这条消息了。 使用拒绝后重新入列这个确认模式要谨慎，因为一般都是出现异常的时候，catch异常再拒绝入列，选择是否重入列。 但是如果使用不当会导致一些每次都被你重入列的消息一直消费-入列-消费-入列这样循环，会导致消息积压。 简单讲讲 nack，这个也是相当于设置不消费某条消息。 channel.basicNack(deliveryTag, false, true);第一个参数依然是当前消息到的数据的唯一id;第二个参数是指是否针对多条消息；如果是true，也就是说一次性针对当前通道的消息的tagID小于当前这条消息的，都拒绝确认。第三个参数是指是否重新入列，也就是指不确认的消息是否重新丢回到队列里面去。 同样使用不确认后重新入列这个确认模式要谨慎，因为这里也可能因为考虑不周出现消息一直被重新丢回去的情况，导致积压。 在消费者下创建监听配置类 123456789101112131415161718192021222324252627282930@Configurationpublic class MessageListenerConfig &#123; @Autowired private CachingConnectionFactory connectionFactory; //消息接收处理类 @Autowired private MyAckReceiver myAckReceiver; @Bean public SimpleMessageListenerContainer simpleMessageListenerContainer() &#123; SimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory); container.setConcurrentConsumers(1); container.setMaxConcurrentConsumers(1); container.setAcknowledgeMode(AcknowledgeMode.MANUAL); // RabbitMQ默认是自动确认，这里改为手动确认消息 //设置一个队列 container.setQueueNames(&quot;TestDirectQueue&quot;); //如果同时设置多个如下： 前提是队列都是必须已经创建存在的 // container.setQueueNames(&quot;TestDirectQueue&quot;,&quot;TestDirectQueue2&quot;,&quot;TestDirectQueue3&quot;); //另一种设置队列的方法,如果使用这种情况,那么要设置多个,就使用addQueues //container.setQueues(new Queue(&quot;TestDirectQueue&quot;,true)); //container.addQueues(new Queue(&quot;TestDirectQueue2&quot;,true)); //container.addQueues(new Queue(&quot;TestDirectQueue3&quot;,true)); container.setMessageListener(myAckReceiver); return container; &#125;&#125; 手动确认模式需要实现 ChannelAwareMessageListener 创建对应的手动确认消息监听类 123456789101112131415161718@Componentpublic class MyAckReceiver implements ChannelAwareMessageListener &#123; @Override public void onMessage(Message message, Channel channel) throws Exception &#123; long deliveryTag = message.getMessageProperties().getDeliveryTag(); try &#123; String msg = message.toString(); System.out.println(&quot; MyAckReceiver msg:&quot; + msg); System.out.println(&quot;消费的主题消息来自：&quot; + message.getMessageProperties().getConsumerQueue()); channel.basicAck(deliveryTag, true); //第二个参数，手动确认可以被批处理，当该参数为 true 时，则可以一次性确认 delivery_tag 小于等于传入值的所有消息// channel.basicReject(deliveryTag, true);//第二个参数，true会重新放回队列，所以需要自己根据业务逻辑判断什么时候使用拒绝 &#125; catch (Exception e) &#123; channel.basicReject(deliveryTag, false); e.printStackTrace(); &#125; &#125;&#125; 测试结果 TTL和死信队列什么是TTL time to live 消息存活时间 如果消息在存活时间内未被消费，则会被清除 RabbitMQ支持两种ttl设置 单独消息进行配置ttl 整个队列进行配置ttl（居多） 什么是rabbitmq的死信队列 没有被及时消费的消息存放的队列 什么是rabbitmq的死信交换机 Dead Letter Exchange（死信交换机，缩写：DLX）当消息成为死信后，会被重新发送到另⼀个交换机，这个交换机就是DLX死信交换机。 消息有哪几种情况成为死信 消费者拒收消息（basic.reject/ basic.nack） ，并且没有重新入队 requeue=false 消息在队列中未被消费，且超过队列或者消息本身的过期时间TTL(time-to-live) 队列的消息长度达到极限 结果：消息成为死信后，如果该队列绑定了死信交换机，则消息会被死信交换机重新路由到死信队列 管控台消息TTL测试队列过期时间使用参数，对整个队列消息统⼀过期 x-message-ttl 单位ms(毫秒) 消息过期时间使用参数（如果队列头部消息未过期，队列中级消息已经过期，消息还在队列里面） expiration ) 两者都配置的话，时间短的先触发 新建死信交换机(和普通没区别) 新建死信队列(和普通没区别) 死信交换机和队列绑定 新建普通队列，设置过期时间、指定死信交换机 测试：直接web控制台往product_qeueu发送消息即可，会看到消息先是在product_qeueu队列停留10秒（因为没有消费者消费），然后该消息从product_qeueu移入到dead_queue。 延迟队列和应用场景什么是延迟队列⼀种带有延迟功能的消息队列， Producer 将消息发送到消息队列服务端，但并不期望这条消息立马投递，而是推迟到在当前时间点之后的某⼀个时间投递到Consumer进行消费，该消息即定时消息。 使用场景 通过消息触发⼀些定时任务，比如在某⼀固定时间点向用户发送提醒消息 用户登录之后5分钟给用户做分类推送、用户多少天未登录给用户做召回推送； 消息生产和消费有时间窗⼝要求：比如在天猫电商交易中超时未支付关闭订单的场景，在订单创建时会发送⼀条延时消息。这条消息将会在30分钟以后投递给消费者，消费者收到此消息后需要判断对应的订单是否已完成支付。如支付未完成，则关闭订单。如已完成支付则忽略 使用TTL和死信队列实现延迟队列在privider创建死信相关配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566@Configurationpublic class DeadRabbitConfig &#123; //死信队列 public static final String DEAD_QUEUE = &quot;dead_queue&quot;; //死信交换机 public static final String DEAD_EXCHANGE = &quot;dead_exchange&quot;; //进入死信队列的路由key public static final String DEAD_ROUTING_KEY = &quot;dead_routing_key&quot;; //创建死信交换机 @Bean public Exchange deadExchange() &#123; return new TopicExchange(DEAD_EXCHANGE, true, false); &#125; //创建死信队列 @Bean public Queue deadQueue() &#123; return QueueBuilder.durable(DEAD_QUEUE).build(); &#125; //绑定死信交换机和死信队列 @Bean public Binding deadBinding() &#123; return new Binding(DEAD_QUEUE, Binding.DestinationType.QUEUE, DEAD_EXCHANGE, DEAD_QUEUE, null); &#125; //普通队列，绑定的个死信交换机 public static final String NORMAL_QUEUE = &quot;normal_queue&quot;; //普通的topic交换机 public static final String NORMAL_EXCHANGE = &quot;normal_exchange&quot;; //路由key public static final String NORMAL_ROUTIING_KEY = &quot;normal_routing_key&quot;; //创建普通交换机 @Bean public Exchange normalExchange() &#123; return new TopicExchange(NORMAL_EXCHANGE, true, false); &#125; //创建普通队列 @Bean public Queue normalQueue() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(3); //消息过期后，进入到死信交换机 args.put(&quot;x-dead-letter-exchange&quot;, deadExchange()); //消息过期后，进入到死信交换机的路由key args.put(&quot;x-dead-letter-routing-key&quot;, DEAD_ROUTING_KEY); //过期时间，单位毫秒 args.put(&quot;x-message-ttl&quot;, 10000); return QueueBuilder.durable(NORMAL_QUEUE).withArguments(args).build(); &#125; //绑定交换机和队列 @Bean public Binding normalBinding() &#123; return new Binding(NORMAL_QUEUE, Binding.DestinationType.QUEUE, NORMAL_EXCHANGE, NORMAL_ROUTIING_KEY, null); &#125;&#125; 创建测试类发送消息 1234567@Test public void sendDeadMessage() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;messageId&quot;, 0); map.put(&quot;messageData&quot;, &quot;这是死信消息&quot;); rabbitTemplate.convertAndSend(&quot;dead_exchange&quot;, &quot;dead_routing_key&quot;, map); &#125; 在consumer创建监听类 12345678910111213141516@Component@RabbitListener(queues = &quot;lock_merchant_dead_queue&quot;)public class MerchantMQListener &#123; @RabbitHandler public void messageHandler(String body, Message message, Channel channel) throws IOException &#123; long msgTag = message.getMessageProperties().getDeliveryTag(); System.out.println(&quot;msgTag=&quot;+msgTag); System.out.println(&quot;body=&quot;+body); //做复杂业务逻辑 TODO //告诉broker，消息已经被确认 channel.basicAck(msgTag,false); &#125;&#125; 使用延迟插件实现延迟队列安装插件 去RabbitMQ的官网下载插件，插件地址：https://www.rabbitmq.com/community-plugins.html 直接搜索rabbitmq_delayed_message_exchange即可找到我们需要下载的插件，下载和RabbitMQ配套的版本，不要弄错； 将插件文件复制到RabbitMQ安装目录的plugins目录下； 进入RabbitMQ安装目录的sbin目录下，使用如下命令启用延迟插件； 1rabbitmq-plugins enable rabbitmq_delayed_message_exchange 启用插件成功后重新启动RabbitMQ服务即可。 代码测试创建消费者 监听类 12345678910111213141516171819@Component@Slf4jpublic class TulingMsgReceiver &#123; /** * 消费延时消息 */ @RabbitListener(queues = &#123;&quot;delay.queue&quot;&#125;) public void consumerDelayMsg(Message message, Channel channel) throws IOException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); ObjectMapper objectMapper = new ObjectMapper(); Order order = objectMapper.readValue(message.getBody(),Order.class); log.info(&quot;在&#123;&#125;,签收:&#123;&#125;&quot;,sdf.format(new Date()),order); channel.basicAck(message.getMessageProperties().getDeliveryTag(),false); &#125;&#125; 消费者配置，签收模式设置为手动，防止二次消费 1234567891011121314server: port: 8899spring: rabbitmq: host: localhost # rabbitmq的连接地址 port: 5672 # rabbitmq的连接端口号 virtual-host: /tj-vhost # rabbitmq的虚拟host username: admin # rabbitmq的用户名 password: admin # rabbitmq的密码 publisher-confirms: true #如果对异步消息需要回调必须设置为true publisher-returns: true # 开启发送失败退回 listener: simple: acknowledge-mode: manual 创建生产者 生产者配置，用于连接rabbitmq 123456789server: port: 8899spring: rabbitmq: host: localhost # rabbitmq的连接地址 port: 5672 # rabbitmq的连接端口号 virtual-host: /tj-vhost # rabbitmq的虚拟host username: admin # rabbitmq的用户名 password: admin # rabbitmq的密码 rabbitmq配置类，注入操作类，设置回调函数 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Configurationpublic class RabbitmqConfig &#123; @Bean public RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory)&#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(); rabbitTemplate.setConnectionFactory(connectionFactory); //设置开启Mandatory,才能触发回调函数,无论消息推送结果怎么样都强制调用回调函数 rabbitTemplate.setMandatory(true); rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -&gt; &#123; System.out.println(&quot;ConfirmCallback: &quot;+&quot;相关数据：&quot;+correlationData); System.out.println(&quot;ConfirmCallback: &quot;+&quot;确认情况：&quot;+ack); System.out.println(&quot;ConfirmCallback: &quot;+&quot;原因：&quot;+cause); &#125;); rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -&gt; &#123; System.out.println(&quot;ReturnCallback: &quot;+&quot;消息：&quot;+message); System.out.println(&quot;ReturnCallback: &quot;+&quot;回应码：&quot;+replyCode); System.out.println(&quot;ReturnCallback: &quot;+&quot;回应信息：&quot;+replyText); System.out.println(&quot;ReturnCallback: &quot;+&quot;交换机：&quot;+exchange); System.out.println(&quot;ReturnCallback: &quot;+&quot;路由键：&quot;+routingKey); &#125;); return rabbitTemplate; &#125; @Bean public CustomExchange delayExchange() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(&quot;x-delayed-type&quot;, &quot;direct&quot;); return new CustomExchange(&quot;delay.exchange&quot;, &quot;x-delayed-message&quot;,true, false,args); &#125; @Bean public Queue delayQueue() &#123; Queue queue = new Queue(&quot;delay.queue&quot;,true,false,false); return queue; &#125; @Bean public Binding binding() &#123; return BindingBuilder.bind(delayQueue()).to(delayExchange()).with(&quot;delay.key&quot;).noargs(); &#125;&#125; 创建测试类发送消息，延时五秒 1234567891011121314151617@Test public void testSenderDelay() &#123; Order order = new Order(); order.setOrderNo(UUID.randomUUID().toString()); order.setUserName(&quot;smlz&quot;); order.setPayMoney(10000.00); order.setCreateDt(new Date()); //构建correlationData 用于做可靠性投递得,ID:必须为全局唯一的 根据业务规则 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); String jsonStr = JSONUtil.toJsonStr(order); rabbitTemplate.convertAndSend(&quot;delay.exchange&quot;, &quot;delay.key&quot;, jsonStr, message -&gt; &#123; message.getMessageProperties().setHeader(&quot;x-delay&quot;, 5000);//设置延迟时间 return message; &#125;, correlationData); &#125; 测试结果，可以看到五秒后签收消息 a","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://tj-ever.github.io/tags/rabbitmq/"}]},{"title":"Rabbitmq 环境搭建及基本使用","slug":"Rabbitmq 环境搭建及基本使用","date":"2021-10-21T16:00:00.000Z","updated":"2021-10-28T03:51:22.157Z","comments":true,"path":"2021/10/22/Rabbitmq 环境搭建及基本使用/","link":"","permalink":"https://tj-ever.github.io/2021/10/22/Rabbitmq%20%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","excerpt":"","text":"概述MQ全称 Message Queue（消息队列），是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。 优势应用解耦 系统的耦合性越高，容错性就越低，可维护性就越低。 使用 MQ 使得应用间解耦，提升容错性和可维护性。 异步提速 一个下单操作耗时：20 + 300 + 300 + 300 = 920ms 用户点击完下单按钮后，需要等待920ms才能得到下单响应，太慢 用户点击完下单按钮后，只需等待25ms就能得到下单响应 (20 + 5 = 25ms)。 提升用户体验和系统吞吐量（单位时间内处理请求的数目）。 削峰填谷 使用了 MQ 之后，限制消费消息的速度为1000，这样一来，高峰期产生的数据势必会被积压在 MQ 中，高峰就被“削”掉了，但是因为消息积压，在高峰期过后的一段时间内，消费消息的速度还是会维持在1000，直到消费完积压的消息，这就叫做“填谷”。 使用MQ后，可以提高系统稳定性。 劣势 系统可用性降低系统引入的外部依赖越多，系统稳定性越差。一旦 MQ 宕机，就会对业务造成影响。如何保证MQ的高可用？ 系统复杂度提高MQ 的加入大大增加了系统的复杂度，以前系统间是同步的远程调用，现在是通过 MQ 进行异步调用。如何保证消息不被丢失等情况？ 常见的MQ产品 RabbitMQ简介AMQP，即 Advanced Message Queuing Protocol（高级消息队列协议），是一个网络协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。2006年，AMQP 规范发布。类比HTTP。 2007年，Rabbit 技术公司基于 AMQP 标准开发的 RabbitMQ 1.0 发布。RabbitMQ 采用 Erlang 语言开发。Erlang 语言由 Ericson 设计，专门为开发高并发和分布式系统的一种语言，在电信领域使用广泛。 RabbitMQ 基础架构如下图： RabbitMQ 中的相关概念： Broker：接收和分发消息的应用，RabbitMQ Server就是 Message Broker Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个vhost，每个用户在自己的 vhost 创建 exchange／queue 等 Connection：publisher／consumer 和 broker 之间的 TCP 连接 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的 channel 进行通讯，AMQP method 包含了channel id 帮助客户端和message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast) Queue：消息最终被送到这里等待 consumer 取走 Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key。Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据 环境安装 更新软件包 1yum -y update 安装依赖 1yum -y install gcc glibc-devel make ncurses-devel openssl-devel xmlto perl wget gtk2-devel binutils-devel 安装Erlang 12345678910111213141516171819202122232425wget http:&#x2F;&#x2F;erlang.org&#x2F;download&#x2F;otp_src_22.0.tar.gztar -zxvf otp_src_22.0.tar.gzmv otp_src_22.0 &#x2F;usr&#x2F;local&#x2F;cd &#x2F;usr&#x2F;local&#x2F;otp_src_22.0&#x2F;&#x2F;&#x2F;创建即将安装的目录mkdir ..&#x2F;erlang&#x2F;&#x2F;配置安装路径.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;erlang&#x2F;&#x2F;安装make install&#x2F;&#x2F;查看一下是否安装成功ll &#x2F;usr&#x2F;local&#x2F;erlang&#x2F;bin&#x2F;&#x2F;添加环境变量echo &#39;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;erlang&#x2F;bin&#39; &gt;&gt; &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile&#x2F;&#x2F;测试erl&#x2F;&#x2F;退出halt(). 安装RabbitMQ 1234567891011121314151617181920212223242526272829wget https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;rabbitmq-server&#x2F;releases&#x2F;download&#x2F;v3.7.15&#x2F;rabbitmq-server-generic-unix-3.7.15.tar.xz&#x2F;&#x2F;安装解压工具yum install -y xz&#x2F;&#x2F;解压&#x2F;bin&#x2F;xz -d rabbitmq-server-generic-unix-3.7.15.tar.xztar -xvf rabbitmq-server-generic-unix-3.7.15.tar&#x2F;&#x2F;创建目录mv rabbitmq_server-3.7.15&#x2F; &#x2F;usr&#x2F;local&#x2F;mv &#x2F;usr&#x2F;local&#x2F;rabbitmq_server-3.7.15 rabbitmq&#x2F;&#x2F;配置环境变量echo &#39;export PATH&#x3D;$PATH:&#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;sbin&#39; &gt;&gt; &#x2F;etc&#x2F;profilesource &#x2F;etc&#x2F;profile&#x2F;&#x2F;创建配置目录mkdir &#x2F;etc&#x2F;rabbitmq&#x2F;&#x2F;启动rabbitmq-server -detached&#x2F;&#x2F;停止rabbitmqctl stop&#x2F;&#x2F;状态rabbitmqctl status 延时插件安装 1234567wget https:&#x2F;&#x2F;github.com&#x2F;rabbitmq&#x2F;rabbitmq-delayed-message-exchange&#x2F;releases&#x2F;download&#x2F;v3.8.0&#x2F;rabbitmq_delayed_message_exchange-3.8.0.ez&#x2F;&#x2F;拷贝至插件目录cp rabbitmq_delayed_message_exchange-3.8.0.ez &#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;plugins&#x2F;&#x2F;启动延时插件rabbitmq-plugins enable rabbitmq_delayed_message_exchange 访问web控制台 1rabbitmq-plugins enable rabbitmq_management 修改配置 1vim &#x2F;usr&#x2F;local&#x2F;rabbitmq&#x2F;ebin&#x2F;rabbit.app 将 &#123;loopback_users, [&lt;&lt;&quot;guest&quot;&gt;&gt;]&#125;修改为 &#123;loopback_users, [guest]&#125;，否则只能使用localhost访问 创建用户 为RabbitMQ Web管理控制台创建管理用户 123rabbitmqctl add_user admin StrongPasswordrabbitmqctl set_user_tags admin administratorrabbitmqctl set_permissions -p &#x2F; admin “.*” “.*” “.*” 使用guest登陆 访问IP:15672，用户名/密码 guest 界面说明 connections：无论生产者还是消费者，都需要与RabbitMQ建立连接后才可以完成消息的生产和消费，在这里可以查看连接情况 channels：通道，建立连接后，会形成通道，消息的投递获取依赖通道。 Exchanges：交换机，用来实现消息的路由 Queues：队列，即消息队列，消息存放在队列中，等待消费，消费后被移除队列。 端口 添加用户 上面的Tags选项是指定用户的角色，可选的有以下几个： 超级管理员(administrator) 可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring) 可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker) 可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management) 仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他 无法登陆管理控制台，通常就是普通的生产者和消费者。 创建虚拟主机 为了让各个用户可以互不干扰的工作，RabbitMQ添加了虚拟主机（Virtual Hosts）的概念。其实就是一个独立的访问路径，不同用户使用不同路径，各自有自己的队列、交换机，互相不会影响。 设置虚拟主机用户和权限 示例demo（未整合Spring，用channel操作）RabbitMQ 提供了 6 种工作模式：简单模式、work queues、Publish/Subscribe 发布与订阅模式、Routing 路由模式、Topics 主题模式、RPC 远程调用模式（远程调用，不太算 MQ；）。 官网对应模式介绍：https://www.rabbitmq.com/getstarted.html 工程搭建普通的maven工程，此处略过 添加依赖 12345678910&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;version&gt;2.8.5&lt;/version&gt;&lt;/dependency&gt; 创建连接工具类 12345678910111213141516171819public class RabbitUtils &#123; private static ConnectionFactory connectionFactory = new ConnectionFactory(); static &#123; connectionFactory.setHost(&quot;localhost&quot;); connectionFactory.setPort(5672); connectionFactory.setUsername(&quot;admin&quot;); connectionFactory.setPassword(&quot;admin&quot;); connectionFactory.setVirtualHost(&quot;/tj-vhost&quot;); &#125; public static Connection getConnection()&#123; Connection conn = null; try &#123; conn = connectionFactory.newConnection(); return conn; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125;&#125; 创建常量类 123456789public class RabbitConstant &#123; public static final String QUEUE_HELLOWORLD = &quot;helloworld&quot;; public static final String QUEUE_SMS = &quot;sms&quot;; public static final String EXCHANGE_WEATHER = &quot;weather&quot;; public static final String EXCHANGE_WEATHER_ROUTING = &quot;weather-routing&quot;; public static final String QUEUE_BAIDU = &quot;baidu&quot;; public static final String QUEUE_SINA = &quot;sina&quot;; public static final String EXCHANGE_WEATHER_TOPIC = &quot;weather-topic&quot;;&#125; 创建完成后需要在页面手动新建vhost 简单模式 在上图的模型中，有以下概念： lP：生产者，也就是要发送消息的程序 lC：消费者：消息的接收者，会一直等待消息到来 lqueue：消息队列，图中红色部分。类似一个邮箱，可以缓存消息；生产者向其中投递消息，消费者从其中取出消息 创建消费者 1234567891011121314151617181920212223242526272829303132333435public class Consumer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; //获取TCP长连接 Connection conn = RabbitUtils.getConnection(); //创建通信“通道”，相当于TCP中的虚拟连接 Channel channel = conn.createChannel(); //创建队列,声明并创建一个队列，如果队列已存在，则使用这个队列 //第一个参数：队列名称ID //第二个参数：是否持久化，false对应不持久化数据，MQ停掉数据就会丢失 //第三个参数：是否队列私有化，false则代表所有消费者都可以访问，true代表只有第一次拥有它的消费者才能一直使用，其他消费者不让访问 //第四个：是否自动删除,false代表连接停掉后不自动删除掉这个队列 //其他额外的参数, null channel.queueDeclare(RabbitConstant.QUEUE_HELLOWORLD, false, false, false, null); //从MQ服务器中获取数据 //创建一个消息消费者 //第一个参数：队列名 //第二个参数代表是否自动确认收到消息，false代表手动编程来确认消息，这是MQ的推荐做法 //第三个参数要传入DefaultConsumer的实现类 channel.basicConsume(RabbitConstant.QUEUE_HELLOWORLD, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String message = new String(body); System.out.println(&quot;消费者接收到的消息：&quot; + message); System.out.println(&quot;消息的TagId：&quot; + envelope.getDeliveryTag()); //false只确认签收当前的消息，设置为true的时候则代表签收该消费者所有未签收的消息 channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 创建生产者 123456789101112131415161718192021222324252627public class Producer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; //获取TCP长连接 Connection conn = RabbitUtils.getConnection(); //创建通信“通道”，相当于TCP中的虚拟连接 Channel channel = conn.createChannel(); //创建队列,声明并创建一个队列，如果队列已存在，则使用这个队列 //第一个参数：队列名称ID //第二个参数：是否持久化，false对应不持久化数据，MQ停掉数据就会丢失 //第三个参数：是否队列私有化，false则代表所有消费者都可以访问，true代表只有第一次拥有它的消费者才能一直使用，其他消费者不让访问 //第四个：是否自动删除,false代表连接停掉后不自动删除掉这个队列 //其他额外的参数, null channel.queueDeclare(RabbitConstant.QUEUE_HELLOWORLD,false, false, false, null); String message = &quot;测试推送消息&quot;; //四个参数 //exchange 交换机，暂时用不到，在后面进行发布订阅时才会用到 //队列名称 //额外的设置属性 //最后一个参数是要传递的消息字节数组 channel.basicPublish(&quot;&quot;, RabbitConstant.QUEUE_HELLOWORLD, null,message.getBytes()); channel.close(); conn.close(); System.out.println(&quot;===发送成功===&quot;); &#125;&#125; 工作队列模式 Work Queues：与入门程序的简单模式相比，多了一个或一些消费端，多个消费端共同消费同一个队列中的消息。 应用场景：对于任务过重或任务较多情况使用工作队列可以提高任务处理的速度。 创建订单类 123456789101112131415public class OrderSystem &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SMS, false, false, false, null); for (int i = 1; i &lt;= 100; i++) &#123; String sms = &quot;乘客&quot; + i + &quot;, 您的车票已预订成功&quot;; channel.basicPublish(&quot;&quot;, RabbitConstant.QUEUE_SMS, null, sms.getBytes()); &#125; System.out.println(&quot;发送数据成功&quot;); channel.close(); connection.close(); &#125;&#125; 创建三个消费者，不同地方只修改sout输出 123456789101112131415161718192021public class SMSSender1 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SMS, false, false, false, null); channel.basicConsume(RabbitConstant.QUEUE_SMS , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String jsonSMS = new String(body); System.out.println(&quot;SMSSender1-短信发送成功:&quot; + jsonSMS); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125; 此时会发现，消息被平均分发到三个消费队列中 再来看一下加上channel.basicQos(1);的效果 123456789101112131415161718192021222324252627public class SMSSender1 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SMS, false, false, false, null); //如果不写basicQos（1），则自动MQ会将所有请求平均发送给所有消费者 //basicQos,MQ不再对消费者一次发送多个请求，而是消费者处理完一个消息后（确认后），在从队列中获取一个新的 channel.basicQos(1);//处理完一个取一个 channel.basicConsume(RabbitConstant.QUEUE_SMS, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String jsonSMS = new String(body); System.out.println(&quot;SMSSender1-短信发送成功:&quot; + jsonSMS); try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 此处模拟服务器性能好坏，将服务器1休眠10毫秒，服务器2休眠100毫秒，服务器3休眠500毫秒 可以看到，由于服务器1处理任务耗时最短，所以消费的消息是最多的，同理，服务器3只消费了3条消息 发布订阅模式 在订阅模型中，多了一个 Exchange 角色，而且过程略有变化： P：生产者，也就是要发送消息的程序，但是不再发送到队列中，而是发给X（交换机） C：消费者，消息的接收者，会一直等待消息到来 Queue：消息队列，接收消息、缓存消息 Exchange：交换机（X）。一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于Exchange的类型。Exchange有常见以下3种类型： Fanout：广播，将消息交给所有绑定到交换机的队列 Direct：定向，把消息交给符合指定routing key 的队列 Topic：通配符，把消息交给符合routing pattern（路由模式） 的队列 Exchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与 Exchange 绑定，或者没有符合路由规则的队列，那么消息会丢失！ 新建一个交换机，选择发布订阅模式 创建天气发布类 123456789101112public class Weather &#123; public static void main(String[] args) throws Exception &#123; Connection connection = RabbitUtils.getConnection(); // 等待输入文字，按回车键结束 String input = new Scanner(System.in).next(); Channel channel = connection.createChannel(); //第一个参数交换机名字 其他参数和之前的一样 channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER,&quot;&quot; , null , input.getBytes()); channel.close(); connection.close(); &#125;&#125; 创建百度订阅类 123456789101112131415161718192021public class Baidu &#123; public static void main(String[] args) throws IOException &#123; //获取TCP长连接 Connection connection = RabbitUtils.getConnection(); //获取虚拟连接 final Channel channel = connection.createChannel(); //声明队列信息 channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); //queueBind用于将队列与交换机绑定 //参数1：队列名 参数2：交互机名 参数三：路由key（暂时用不到) channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER, &quot;&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;百度天气收到气象信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125; 创建新浪订阅类 123456789101112131415161718192021public class Sina &#123; public static void main(String[] args) throws IOException &#123; //获取TCP长连接 Connection connection = RabbitUtils.getConnection(); //获取虚拟连接 final Channel channel = connection.createChannel(); //声明队列信息 channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); //queueBind用于将队列与交换机绑定 //参数1：队列名 参数2：交互机名 参数三：路由key（暂时用不到) channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER, &quot;&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;新浪天气收到气象信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125; 在发布类的控制台输入消息，按回车键发送，可在其他两个订阅类收到消息 路由模式模式说明： 队列与交换机的绑定，不能是任意绑定了，而是要指定一个 RoutingKey（路由key） 消息的发送方在向 Exchange 发送消息时，也必须指定消息的 RoutingKey Exchange 不再把消息交给每一个绑定的队列，而是根据消息的 Routing Key 进行判断，只有队列的Routingkey 与消息的 Routing key 完全一致，才会接收到消息 图解： P：生产者，向 Exchange 发送消息，发送消息时，会指定一个routing key X：Exchange（交换机），接收生产者的消息，然后把消息递交给与 routing key 完全匹配的队列 C1：消费者，其所在队列指定了需要 routing key 为 error 的消息 C2：消费者，其所在队列指定了需要 routing key 为 info、error、warning 的消息 新建一个交换机，选择路由模式 创建天气发布类，对同一个交换机绑定了四个路由，测试新浪和百度是否根据对应的路由收消息 1234567891011121314public class Weather &#123; public static void main(String[] args) throws Exception &#123; Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;百度--路由key&quot;, null, &quot;百度消息-天气不错&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;百度--路由key-1&quot;, null, &quot;百度消息-空气不错-1&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;新浪--路由key&quot;, null, &quot;新浪消息-天气不错&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;新浪--路由key-1&quot;, null, &quot;新浪消息-空气不错-1&quot;.getBytes()); channel.close(); connection.close(); &#125;&#125; 创建百度类 12345678910111213141516171819public class Baidu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); //queueBind用于将队列与交换机绑定 //参数1：队列名 参数2：交互机名 参数三：路由key channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;百度--路由key&quot;); channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;百度--路由key-1&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;百度收到信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 创建新浪类 1234567891011121314151617181920212223public class Sina &#123; public static void main(String[] args) throws IOException &#123; //获取TCP长连接 Connection connection = RabbitUtils.getConnection(); //获取虚拟连接 final Channel channel = connection.createChannel(); //声明队列信息 channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); //指定队列与交换机以及routing key之间的关系 channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;新浪--路由key&quot;); channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_ROUTING, &quot;新浪--路由key-1&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;新浪收到信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 测试结果，百度和新浪收到了各自对应的路由消息 通配符模式模式说明： Topic 类型与 Direct 相比，都是可以根据 RoutingKey 把消息路由到不同的队列。只不过 Topic 类型Exchange 可以让队列在绑定 Routing key 的时候使用通配符 Routingkey 一般都是有一个或多个单词组成，多个单词之间以”.”分割，例如： item.insert 通配符规则：# 匹配一个或多个词，* 匹配不多不少恰好1个词，例如：item.# 能够匹配 item.insert.abc 或者 item.insert，item.* 只能匹配 item.insert 图解： 红色 Queue：绑定的是 usa.# ，因此凡是以 usa. 开头的 routing key 都会被匹配到 黄色 Queue：绑定的是 #.news ，因此凡是以 .news 结尾的 routing key 都会被匹配 新建一个交换机，类型选择通配符模式 创建天气发布类，此处修改了交换机和路由格式 1234567891011121314public class Weather &#123; public static void main(String[] args) throws Exception &#123; Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;百度.路由key&quot;, null, &quot;百度消息-天气不错&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;百度.路由key.1&quot;, null, &quot;百度消息-空气不错-1&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;新浪.路由key&quot;, null, &quot;新浪消息-天气不错&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;新浪.路由key.1&quot;, null, &quot;新浪消息-空气不错-1&quot;.getBytes()); channel.close(); connection.close(); &#125;&#125; 创建百度类，此处将路由修改为“百度.#”，#可以匹配多个词 123456789101112131415161718public class Baidu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); //queueBind用于将队列与交换机绑定 //参数1：队列名 参数2：交互机名 参数三：路由key channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;百度.#&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;百度收到信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 创建百度类，此处将路由修改为“新浪.*”，✳️只能匹配一个词 123456789101112131415161718192021public class Sina &#123; public static void main(String[] args) throws IOException &#123; //获取TCP长连接 Connection connection = RabbitUtils.getConnection(); //获取虚拟连接 final Channel channel = connection.createChannel(); //声明队列信息 channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); //指定队列与交换机以及routing key之间的关系 channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;新浪.*&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;新浪收到信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 测试结果，百度类接收到了两个消息，因为使用的是#通配符，可以匹配多个路由。新浪类只收到了一个消息，因为使用的是*通配符，只能匹配一个 工作模式总结 简单模式 HelloWorld 一个生产者、一个消费者，不需要设置交换机（使用默认的交换机）。 工作队列模式 Work Queue 一个生产者、多个消费者（竞争关系），不需要设置交换机（使用默认的交换机）。 发布订阅模式 Publish/subscribe 需要设置类型为 fanout 的交换机，并且交换机和队列进行绑定，当发送消息到交换机后，交换机会将消息发送到绑定的队列。 路由模式 Routing 需要设置类型为 direct 的交换机，交换机和队列进行绑定，并且指定 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 通配符模式 Topic 需要设置类型为 topic 的交换机，交换机和队列进行绑定，并且指定通配符方式的 routing key，当发送消息到交换机后，交换机会根据 routing key 将消息发送到对应的队列。 消息确认机制 创建天气发布类，注意publish第三个参数需要指定为true，否则消息收不到将被直接删除 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Weather &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = RabbitUtils.getConnection(); Channel channel = connection.createChannel(); //开启confirm监听模式 channel.confirmSelect(); channel.addConfirmListener(new ConfirmListener() &#123; @Override public void handleAck(long l, boolean b) &#123; //第二个参数代表接收的数据是否为批量接收，一般我们用不到。 System.out.println(&quot;消息已被Broker接收,Tag:&quot; + l); &#125; @Override public void handleNack(long l, boolean b) &#123; System.out.println(&quot;消息已被Broker拒收,Tag:&quot; + l); &#125; &#125;); channel.addReturnListener(new ReturnCallback() &#123; @Override public void handle(Return r) &#123; System.err.println(&quot;===========================&quot;); System.err.println(&quot;Return编码：&quot; + r.getReplyCode() + &quot;-Return描述:&quot; + r.getReplyText()); System.err.println(&quot;交换机:&quot; + r.getExchange() + &quot;-路由key:&quot; + r.getRoutingKey()); System.err.println(&quot;Return主题：&quot; + new String(r.getBody())); System.err.println(&quot;===========================&quot;); &#125; &#125;); //Routing key 第二个参数相当于数据筛选的条件 //第三个参数为：mandatory true代表如果消息无法正常投递则return回生产者，如果false，则直接将消息放弃。 channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;百度.路由key&quot;, true, null, &quot;百度消息-天气不错&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;百度.路由key.1&quot;, true, null, &quot;百度消息-空气不错-1&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;新浪.路由key&quot;, true, null, &quot;新浪消息-天气不错&quot;.getBytes()); channel.basicPublish(RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;新浪.路由key.1&quot;, true, null, &quot;新浪消息-空气不错-1&quot;.getBytes()); //如果关闭则无法进行监听，因此此处不需要关闭 /*channel.close(); connection.close();*/ &#125;&#125; 创建百度订阅类，不使用通配符只指定一个路由 123456789101112131415161718public class Baidu &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_BAIDU, false, false, false, null); //queueBind用于将队列与交换机绑定 //参数1：队列名 参数2：交互机名 参数三：路由key channel.queueBind(RabbitConstant.QUEUE_BAIDU, RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;百度.路由key&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_BAIDU , false , new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;百度收到信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag() , false); &#125; &#125;); &#125;&#125; 创建新浪订阅类，不使用通配符只指定一个路由 12345678910111213141516public class Sina &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitUtils.getConnection(); final Channel channel = connection.createChannel(); channel.queueDeclare(RabbitConstant.QUEUE_SINA, false, false, false, null); channel.queueBind(RabbitConstant.QUEUE_SINA, RabbitConstant.EXCHANGE_WEATHER_TOPIC, &quot;新浪.路由key&quot;); channel.basicQos(1); channel.basicConsume(RabbitConstant.QUEUE_SINA, false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;新浪收到信息：&quot; + new String(body)); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 在天气发布类中共发布了四个消息，其中百度类和新浪类各接收到一个，还剩两个由于没有路由导致消息不可达，会被addReturnListener监听到 Spring整合rabbitmq（用rabbitTemplate操作）创建配置类，需要创建连接工厂，启动类，交换机，队列，绑定以及简单的消费监听（需要传入） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182@Configurationpublic class RabbitmqConfig &#123; /** * 创建连接工厂 */ @Bean public ConnectionFactory connectionFactory() &#123; CachingConnectionFactory cachingConnectionFactory = new CachingConnectionFactory(); cachingConnectionFactory.setAddresses(&quot;192.168.159.8:5672&quot;); cachingConnectionFactory.setVirtualHost(&quot;tuling&quot;); cachingConnectionFactory.setUsername(&quot;smlz&quot;); cachingConnectionFactory.setPassword(&quot;smlz&quot;); cachingConnectionFactory.setConnectionTimeout(10000); cachingConnectionFactory.setCloseTimeout(10000); return cachingConnectionFactory; &#125; @Bean public RabbitAdmin rabbitAdmin(ConnectionFactory connectionFactory) &#123; RabbitAdmin rabbitAdmin = new RabbitAdmin(connectionFactory); //spring容器启动加载该类 rabbitAdmin.setAutoStartup(true); return rabbitAdmin; &#125; //=====================================申明三个交换机==================================================================== @Bean public TopicExchange topicExchange() &#123; TopicExchange topicExchange = new TopicExchange(&quot;tuling.topic.exchange&quot;, true, false); return topicExchange; &#125; @Bean public DirectExchange directExchange() &#123; DirectExchange directExchange = new DirectExchange(&quot;tuling.direct.exchange&quot;, true, false); return directExchange; &#125; @Bean public FanoutExchange fanoutExchange() &#123; FanoutExchange fanoutExchange = new FanoutExchange(&quot;tuling.faout.exchange&quot;, true, false); return fanoutExchange; &#125; //===========================================申明队列=========================================================== @Bean public Queue testTopicQueue() &#123; Queue queue = new Queue(&quot;testTopicQueue&quot;, true, false, false, null); return queue; &#125; @Bean public Queue testTopicQueue2() &#123; Queue queue = new Queue(&quot;testTopicQueue2&quot;, true, false, false, null); return queue; &#125; @Bean public Queue testDirectQueue() &#123; Queue queue = new Queue(&quot;testDirectQueue&quot;, true, false, false, null); return queue; &#125; @Bean public Queue testFaoutQueue() &#123; Queue queue = new Queue(&quot;testfaoutQueue&quot;, true, false, false, null); return queue; &#125; @Bean public Queue orderQueue() &#123; Queue queue = new Queue(&quot;orderQueue&quot;, true, false, false, null); return queue; &#125; //========================================申明绑定============================================================== @Bean public Binding topicBingding() &#123; return BindingBuilder.bind(testTopicQueue()).to(topicExchange()).with(&quot;topic.#&quot;); &#125; @Bean public Binding topicBingding2() &#123; return BindingBuilder.bind(testTopicQueue2()).to(topicExchange()).with(&quot;topic.key.#&quot;); &#125; @Bean public Binding directBinding() &#123; return BindingBuilder.bind(testDirectQueue()).to(directExchange()).with(&quot;direct.key&quot;); &#125; @Bean public Binding orderQueueBinding() &#123; return BindingBuilder.bind(orderQueue()).to(directExchange()).with(&quot;rabbitmq.order&quot;); &#125; @Bean public Binding fanoutBinding() &#123; return BindingBuilder.bind(testFaoutQueue()).to(fanoutExchange()); &#125; //========================================申明操作模板============================================================== @Bean public RabbitTemplate rabbitTemplate() &#123; RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory()); rabbitTemplate.setReceiveTimeout(50000); return rabbitTemplate; &#125; /** * 简单的消息监听容器 */ @Bean public SimpleMessageListenerContainer simpleMessageListenerContainer() &#123; SimpleMessageListenerContainer simpleMessageListenerContainer = new SimpleMessageListenerContainer(connectionFactory()); //监听我们的队列 simpleMessageListenerContainer.setQueues(testTopicQueue(), testDirectQueue(), testTopicQueue2(), orderQueue()); //消费者的数量 simpleMessageListenerContainer.setConcurrentConsumers(5); //最大消费者数量 simpleMessageListenerContainer.setMaxConcurrentConsumers(10); //签收模式 simpleMessageListenerContainer.setAcknowledgeMode(AcknowledgeMode.AUTO); //设置拒绝重回队列 simpleMessageListenerContainer.setDefaultRequeueRejected(false); /** * 设置使用默认的监听方法（默认监听的方法名是 &#x27;handleMessage&#x27;） */// MessageListenerAdapter messageListenerAdapter = new MessageListenerAdapter(new TulingMsgDelegate());// simpleMessageListenerContainer.setMessageListener(messageListenerAdapter); /** * 指定消费方法（需要指定方法名） */// MessageListenerAdapter messageListenerAdapter = new MessageListenerAdapter(new TulingMsgDelegate());// messageListenerAdapter.setDefaultListenerMethod(&quot;consumerMsg&quot;);// simpleMessageListenerContainer.setMessageListener(messageListenerAdapter); /** * 不同的队列使用不同的消费方法（同样还是amqp提供的方法，通过指定队列名称和方法名称） */// MessageListenerAdapter messageListenerAdapter = new MessageListenerAdapter(new TulingMsgDelegate());// Map&lt;String, String&gt; queueMaps = new HashMap&lt;&gt;();// queueMaps.put(&quot;testTopicQueue&quot;, &quot;consumerTopicQueue&quot;);// queueMaps.put(&quot;testTopicQueue2&quot;, &quot;consumerTopicQueue2&quot;);// messageListenerAdapter.setQueueOrTagToMethodName(queueMaps);// simpleMessageListenerContainer.setMessageListener(messageListenerAdapter); /** * 处理Json的（使用ampq提供的转换器） */// MessageListenerAdapter messageListenerAdapter = new MessageListenerAdapter(new TulingMsgDelegate());// messageListenerAdapter.setDefaultListenerMethod(&quot;consumerJsonMessage&quot;);// // ampq包下的转换器// Jackson2JsonMessageConverter jackson2JsonMessageConverter = new Jackson2JsonMessageConverter();// messageListenerAdapter.setMessageConverter(jackson2JsonMessageConverter);// simpleMessageListenerContainer.setMessageListener(messageListenerAdapter); /** * 处理java对象（使用ampq提供的转换器） */ MessageListenerAdapter messageListenerAdapter = new MessageListenerAdapter(new TulingMsgDelegate()); messageListenerAdapter.setDefaultListenerMethod(&quot;consumerJavaObjMessage&quot;); Jackson2JsonMessageConverter jackson2JsonMessageConverter = new Jackson2JsonMessageConverter(); DefaultJackson2JavaTypeMapper javaTypeMapper = new DefaultJackson2JavaTypeMapper(); javaTypeMapper.setTrustedPackages(&quot;com.tuling.entity&quot;); //设置java转json的 jackson2JsonMessageConverter.setJavaTypeMapper(javaTypeMapper); messageListenerAdapter.setMessageConverter(jackson2JsonMessageConverter); simpleMessageListenerContainer.setMessageListener(messageListenerAdapter); return simpleMessageListenerContainer; &#125;&#125; 创建消费代理类 12345678910111213141516171819202122232425262728293031323334353637383940public class TulingMsgDelegate &#123; public void handleMessage(String msgBody) &#123; System.out.println(&quot;TulingMsgDelegate。。。。。。handleMessage&quot; + msgBody); &#125; public void consumerMsg(String msg) &#123; System.out.println(&quot;TulingMsgDelegate。。。。。。consumerMsg&quot; + msg); &#125; public void consumerTopicQueue(String msgBody) &#123; System.out.println(&quot;TulingMsgDelegate。。。。。。consumerTopicQueue&quot; + msgBody); &#125; public void consumerTopicQueue2(String msgBody) &#123; System.out.println(&quot;TulingMsgDelegate。。。。。。consumerTopicQueue2&quot; + msgBody); &#125; /** * 处理json * * @param jsonMap */ public void consumerJsonMessage(Map jsonMap) &#123; System.out.println(&quot;TulingMsgDelegate ============================处理json&quot; + jsonMap); &#125; /** * 处理order得 * * @param order */ public void consumerJavaObjMessage(Order order) &#123; System.out.println(&quot;TulingMsgDelegate ============================处理java对象&quot; + order.toString()); &#125;&#125; 创建测试类发送消息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package com.tuling;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import com.tuling.entity.*;import com.tuling.entity.Address;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.amqp.core.*;import org.springframework.amqp.rabbit.core.RabbitAdmin;import org.springframework.amqp.rabbit.core.RabbitTemplate;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.context.annotation.Bean;import org.springframework.test.context.junit4.SpringRunner;import java.io.IOException;import java.nio.file.Files;import java.nio.file.Paths;import java.util.Date;import java.util.UUID;@RunWith(SpringRunner.class)@SpringBootTestpublic class TulingvipRabbitmqSpringwithrabbitmqApplicationTests &#123; @Autowired //该类封装了对 RabbitMQ 的管理操作 private RabbitAdmin rabbitAdmin; @Test public void contextLoads() &#123; &#125; @Test public void testTopicExchange() &#123; //声明一个交换机 TopicExchange topicExchange = new TopicExchange(&quot;rabbitadmin.topic.exchange&quot;,true,false); rabbitAdmin.declareExchange(topicExchange); //申明一个队列 Queue queue = new Queue(&quot;rabbitadmin.topic.queue&quot;,true); rabbitAdmin.declareQueue(queue); //申明一个绑定 Binding binding = new Binding(&quot;rabbitadmin.topic.queue&quot;,Binding.DestinationType.QUEUE, &quot;rabbitadmin.topic.exchange&quot;,&quot;rabbitadmin.#&quot;,null); rabbitAdmin.declareBinding(binding); &#125; @Test public void testDirectExchange() &#123; DirectExchange directExchange = new DirectExchange(&quot;rabbitadmin.direct.exchange&quot;,true,false); rabbitAdmin.declareExchange(directExchange); Queue queue = new Queue(&quot;rabbitadmin.direct.queue&quot;,true); rabbitAdmin.declareQueue(queue); rabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(directExchange).with(&quot;rabbitadmin.key.#&quot;)); &#125; @Autowired //Spring AMQP 提供了 RabbitTemplate 来简化 RabbitMQ 发送和接收消息操作 private RabbitTemplate rabbitTemplate; @Test public void testRabbitmqTemplate() &#123; MessageProperties messageProperties = new MessageProperties(); messageProperties.getHeaders().put(&quot;company&quot;,&quot;tuling&quot;); messageProperties.getHeaders().put(&quot;name&quot;,&quot;smlz&quot;); String msgBody = &quot;hello tuling&quot;; Message message = new Message(msgBody.getBytes(),messageProperties); //不需要message对象发送 rabbitTemplate.convertAndSend(&quot;tuling.direct.exchange&quot;,&quot;direct.key&quot;,&quot;smlz&quot;); &#125; @Test public void simpleMessageListenerContainerTest() &#123; rabbitTemplate.convertAndSend(&quot;tuling.topic.exchange&quot;,&quot;topic.xixi&quot;,&quot;你好 图灵&quot;); &#125; @Test public void messageListenerAdaperQueueOrTagToMethodName()&#123; rabbitTemplate.convertAndSend(&quot;tuling.topic.exchange&quot;,&quot;topic.xixi&quot;,&quot;你好 图灵&quot;); rabbitTemplate.convertAndSend(&quot;tuling.topic.exchange&quot;,&quot;topic.key.xixi&quot;,&quot;你好 smlz&quot;); &#125; @Test public void sendJson() throws JsonProcessingException &#123; Order order = new Order(); order.setOrderNo(UUID.randomUUID().toString()); order.setCreateDt(new Date()); order.setPayMoney(10000.00); order.setUserName(&quot;smlz&quot;); ObjectMapper objectMapper = new ObjectMapper(); String orderJson = objectMapper.writeValueAsString(order); MessageProperties messageProperties = new MessageProperties(); messageProperties.setContentType(&quot;application/json&quot;); Message orderMsg = new Message(orderJson.getBytes(),messageProperties); rabbitTemplate.convertAndSend(&quot;tuling.direct.exchange&quot;,&quot;rabbitmq.order&quot;,orderMsg); &#125; @Test public void sendJavaObj() throws JsonProcessingException &#123; Order order = new Order(); order.setOrderNo(UUID.randomUUID().toString()); order.setCreateDt(new Date()); order.setPayMoney(10000.00); order.setUserName(&quot;smlz&quot;); ObjectMapper objectMapper = new ObjectMapper(); String orderJson = objectMapper.writeValueAsString(order); MessageProperties messageProperties = new MessageProperties(); messageProperties.setContentType(&quot;application/json&quot;); messageProperties.getHeaders().put(&quot;__TypeId__&quot;,&quot;com.tuling.entity.Order&quot;); Message orderMsg = new Message(orderJson.getBytes(),messageProperties); rabbitTemplate.convertAndSend(&quot;tuling.direct.exchange&quot;,&quot;rabbitmq.order&quot;,orderMsg); &#125;&#125; SpringBoot整合依赖配置 添加pom依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 添加配置文件 1234567891011121314spring.rabbitmq.host&#x3D;192.168.8.233spring.rabbitmq.port&#x3D;5672spring.rabbitmq.virtual-host&#x3D;virtualHostspring.rabbitmq.username&#x3D;adminspring.rabbitmq.password&#x3D;admin#开启消息确认模式spring.rabbitmq.publisher-confirms&#x3D;true#开启消息可达监听spring.rabbitmq.publisher-returns&#x3D;true#开启不可达消息删除spring.rabbitmq.template.mandatory&#x3D;true#设置连接超时spring.rabbitmq.connection-timeout&#x3D;10000 producer生产者 配置类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Configurationpublic class RabbitmqConfig &#123; //direct交换机 @Bean public DirectExchange testBootDirectExchange() &#123; DirectExchange directExchange = new DirectExchange(&quot;springboot.direct.exchange&quot;, true, false); return directExchange; &#125; //延迟交换机 @Bean public CustomExchange delayExchange() &#123; Map&lt;String, Object&gt; args = new HashMap&lt;&gt;(); args.put(&quot;x-delayed-type&quot;, &quot;direct&quot;); return new CustomExchange(&quot;delayExchange&quot;, &quot;x-delayed-message&quot;, true, false, args); &#125; //测试队列 @Bean public Queue testBootQueue() &#123; Queue queue = new Queue(&quot;testBootQueue&quot;, true, false, false); return queue; &#125; //测试延迟队列 @Bean public Queue testBootDelayQueue() &#123; Queue queue = new Queue(&quot;testBootDelayQueue&quot;, true, false, false); return queue; &#125; //绑定路由（此处可换成topic交换机） @Bean public Binding testBootBinder1() &#123; return BindingBuilder.bind(testBootQueue()).to(testBootDirectExchange()).with(&quot;springboot.key1&quot;); &#125; //绑定路由（此处可换成topic交换机） @Bean public Binding testBootBinder2() &#123; return BindingBuilder.bind(testBootQueue()).to(testBootDirectExchange()).with(&quot;springboot.key2&quot;); &#125; //绑定路由（此处可换成topic交换机） @Bean public Binding testBootBinder3() &#123; return BindingBuilder.bind(testBootQueue()).to(testBootDirectExchange()).with(&quot;springboot.key3&quot;); &#125; //绑定路由（此处可换成topic交换机） @Bean public Binding testBootBinder4() &#123; return BindingBuilder.bind(testBootQueue()).to(testBootDirectExchange()).with(&quot;springboot.key4&quot;); &#125; //绑定延迟路由 @Bean public Binding binding() &#123; return BindingBuilder.bind(testBootDelayQueue()).to(delayExchange()).with(&quot;springboot.delay.key&quot;).noargs(); &#125;&#125; 消息发送组件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@Componentpublic class TestMsgSender &#123; @Autowired private RabbitTemplate rabbitTemplate; //测试发送消息 public void sendMsg() throws JsonProcessingException &#123; //map参数 Map&lt;String, Object&gt; msgProp = new HashMap&lt;&gt;(); msgProp.put(&quot;key1&quot;, &quot;value1&quot;); msgProp.put(&quot;key2&quot;, &quot;value2&quot;); //实体对象 Order order = new Order(); order.setOrderNo(UUID.randomUUID().toString()); order.setUserName(&quot;admin&quot;); order.setPayMoney(10000.00); order.setCreateDt(new Date()); MessageHeaders messageHeaders = new MessageHeaders(msgProp); //构建消息对象 Message message = MessageBuilder.createMessage(msgProp, messageHeaders); //构建correlationData 用于做可靠性投递得,ID:必须为全局唯一的 根据业务规则 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); //开启确认模式 rabbitTemplate.setConfirmCallback(new TestConfirmCallBack()); //开启消息可达监听 rabbitTemplate.setReturnCallback(new TestRetrunCallBack()); //测试发送构建message对象 rabbitTemplate.convertAndSend(&quot;springboot.direct.exchange&quot;, &quot;springboot.key1&quot;, message, new CorrelationData(&quot;key1&quot;)); //测试消息 不可达监控 rabbitTemplate.convertAndSend(&quot;springboot.direct.exchange&quot;, &quot;error.key&quot;, message, new CorrelationData(&quot;key3&quot;)); //测试发送实体对象 rabbitTemplate.convertAndSend(&quot;springboot.direct.exchange&quot;, &quot;springboot.key2&quot;, order, new CorrelationData(&quot;key2&quot;)); //测试发送core下的message对象 ObjectMapper objectMapper = new ObjectMapper(); String orderJson = objectMapper.writeValueAsString(order); org.springframework.amqp.core.MessageProperties messageProperties = new MessageProperties(); org.springframework.amqp.core.Message ampqMessage = new org.springframework.amqp.core.Message(orderJson.getBytes(), messageProperties); rabbitTemplate.convertAndSend(&quot;springboot.direct.exchange&quot;, &quot;springboot.key3&quot;, ampqMessage, new CorrelationData(&quot;key3&quot;)); //测试发送Messaging包下的message对象 Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;key&quot;, &quot;value&quot;); MessageHeaders messageHeaders1 = new MessageHeaders(map); String orderJson1 = objectMapper.writeValueAsString(order); Message message1 = MessageBuilder.createMessage(orderJson1, messageHeaders1); rabbitTemplate.convertAndSend(&quot;springboot.direct.exchange&quot;, &quot;springboot.key4&quot;, message1, new CorrelationData(&quot;key4&quot;)); &#125; public void sendDelayMessage() &#123; //实体对象 Order order = new Order(); order.setOrderNo(UUID.randomUUID().toString()); order.setUserName(&quot;admin&quot;); order.setPayMoney(10000.00); order.setCreateDt(new Date()); //构建correlationData 用于做可靠性投递得,ID:必须为全局唯一的 根据业务规则 CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); //开启确认模式 rabbitTemplate.setConfirmCallback(new TestConfirmCallBack()); //开启消息可达监听 rabbitTemplate.setReturnCallback(new TestRetrunCallBack()); rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter()); //先发送一条消息 rabbitTemplate.convertAndSend(&quot;delayExchange&quot;, &quot;springboot.delay.key&quot;, order, correlationData); //十秒后再发送一条消息 rabbitTemplate.convertAndSend(&quot;delayExchange&quot;, &quot;springboot.delay.key&quot;, order, new MessagePostProcessor() &#123; @Override public org.springframework.amqp.core.Message postProcessMessage(org.springframework.amqp.core.Message message) throws AmqpException &#123; message.getMessageProperties().setHeader(&quot;x-delay&quot;, 10000);//设置延迟时间 return message; &#125; &#125;, correlationData); &#125; &#125; 消息确认回调 1234567@Slf4jpublic class TestConfirmCallBack implements RabbitTemplate.ConfirmCallback &#123; @Override public void confirm(CorrelationData correlationData, boolean ack, String cause) &#123; log.info(&quot;confirm收到了，ack为:&#123;&#125; ,correlationData为:&#123;&#125;,cause为:&#123;&#125;&quot;, ack, correlationData, cause); &#125;&#125; 消息不可达回调 1234567@Slf4jpublic class TestRetrunCallBack implements RabbitTemplate.ReturnCallback &#123; @Override public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) &#123; log.info(&quot;RetrunCall收到了，replyCode:&#123;&#125; ,correlationId:&#123;&#125;,replyText:&#123;&#125;,exchange:&#123;&#125;,routingKey:&#123;&#125;&quot;, replyCode, message.getMessageProperties().getCorrelationId(), replyText, exchange, routingKey); &#125;&#125; 测试生产者发送消息 consumer消费者123456789101112131415161718192021222324252627282930@Component@Slf4jpublic class TulingMsgReceiver &#123; //测试普通消息接收 @RabbitListener(queues = &#123;&quot;testBootQueue&quot;&#125;) @RabbitHandler public void consumerMsg(Message message, Channel channel) throws IOException &#123; log.info(&quot;消费消息:&#123;&#125;&quot;, message.getPayload()); //手工签收 Long deliveryTag = (Long) message.getHeaders().get(AmqpHeaders.DELIVERY_TAG); log.info(&quot;接受deliveryTag:&#123;&#125;&quot;, deliveryTag); channel.basicAck(deliveryTag,false); &#125; //测试延迟消息接收 @RabbitListener(queues = &#123;&quot;testBootDelayQueue&quot;&#125;) @RabbitHandler public void consumerDelayMsg(org.springframework.amqp.core.Message message, Channel channel) throws IOException &#123; SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;); ObjectMapper objectMapper = new ObjectMapper(); Order order = objectMapper.readValue(message.getBody(), Order.class); log.info(&quot;在&#123;&#125;,签收:&#123;&#125;&quot;, sdf.format(new Date()), order); log.info(&quot;接受时间和订单生成时间相差&#123;&#125;秒&quot;, DateUtil.formatBetween(order.getCreateDt(),new Date())); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); &#125;&#125; 测试延迟消息","categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://tj-ever.github.io/tags/rabbitmq/"}]},{"title":"Zookeeper 源码构建 阅读","slug":"zookeeper leader","date":"2021-10-20T16:00:00.000Z","updated":"2021-10-27T04:31:47.358Z","comments":true,"path":"2021/10/21/zookeeper leader/","link":"","permalink":"https://tj-ever.github.io/2021/10/21/zookeeper%20leader/","excerpt":"","text":"源码构建拉取源码1https:&#x2F;&#x2F;github.com&#x2F;apache&#x2F;zookeeper&#x2F;tree&#x2F;branch-3.5.8 用idea导入后，使用maven下载所有模块依赖，然后在下面这个包下创建Info类。 1234567891011package org.apache.zookeeper.version;public interface Info &#123; int MAJOR = 1; int MINOR = 0; int MICRO = 0; String QUALIFIER = null; int REVISION = -1; String REVISION_HASH = &quot;1&quot;; String BUILD_DATE = &quot;2021‐10‐21&quot;;&#125; 编译在根目录执行命令 1mvn clean install ‐DskipTests 此时会报错，如下 需要修改pom文件 注释162行 修改222，和223行改为固定值 最后编译成功 寻找入口开源项目找入口类一般都是从启动脚本去找，可以从bin目录下的zkServer.sh或zkServer.cmd里找到启动主类运行即可 1org.apache.zookeeper.server.quorum.QuorumPeerMain 启动服务端将conf文件夹里的zoo_sample.cfg文件复制一份改名为zoo.cfg，将zoo.cfg文件位置配置到启动参数里 启动之前需要先将zookeeper-server项目里pom.xml文件里依赖的包(除了jline)的scope为provided这一行全部注释掉 将conf文件夹里的log4j.properties文件复制一份到zookeeper-server项目的 \\target\\classes 目录下，这样项目启动时才会打印日志 启动成功 启动客户端从源码里运行客户端(org.apache.zookeeper.ZooKeeperMain)，注意需要加入启动参数 启动成功 伪集群启动复制3个zoo.cfg文件，修改对应集群配置，并在data目录里分别建各自的myid文件填入机器id，并创建三个不同配置的启动节点 Zoo1.cfg (另外两个配置文件只需修改clientPort为2182，2183，dataDir为./zk2/data，./zk3/data) 123456789101112131415161718192021222324252627282930313233# The number of milliseconds of each ticktickTime&#x3D;2000# The number of ticks that the initial # synchronization phase can takeinitLimit&#x3D;10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit&#x3D;5# the directory where the snapshot is stored.# do not use &#x2F;tmp for storage, &#x2F;tmp here is just # example sakes.dataDir&#x3D;.&#x2F;zk1&#x2F;data# the port at which the clients will connectclientPort&#x3D;2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns&#x3D;60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http:&#x2F;&#x2F;zookeeper.apache.org&#x2F;doc&#x2F;current&#x2F;zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount&#x3D;3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval&#x3D;1server.1&#x3D;localhost:2287:3387server.2&#x3D;localhost:2288:3388server.3&#x3D;localhost:2289:3389 分别运行每个节点，启动成功 选举leader流程启动或者宕机会流程选举 leader选举多层队列架构整个zookeeper选举底层可以分为选举应用层和消息传输层，应用层有自己的队列统一接收和发送选票，传输层也设计了自己的队列，但是按发送的机器分了队列，避免给每台机器发送消息时相互影响，比如某台机器如果出问题发送不成功则不会影响对正常机器的消息发送。 Leader选举源码流程图","categories":[],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://tj-ever.github.io/tags/Zookeeper/"}]},{"title":"Zookeeper 客户端使用及集群","slug":"Zookeeper 客户端使用及集群","date":"2021-10-06T16:00:00.000Z","updated":"2021-10-21T06:24:06.110Z","comments":true,"path":"2021/10/07/Zookeeper 客户端使用及集群/","link":"","permalink":"https://tj-ever.github.io/2021/10/07/Zookeeper%20%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E5%8F%8A%E9%9B%86%E7%BE%A4/","excerpt":"","text":"Zookeeper Java 客户端项目构建zookeeper 官方的客户端没有和服务端代码分离，为同一个jar 文件，所以直接引入 zookeeper的maven即可， 这里版本需要保持与服务端版本一致，不然会有兼容性的问题 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.8&lt;/version&gt;&lt;/dependency&gt; 创建客户端实例为了便于测试，直接在初始化方法中创建zookeeper实例 1234567891011121314151617181920@Slf4jpublic class ZookeeperClientTest&#123; private static final String ZK_ADDRESS=&quot;192.168.109.200:2181&quot;; private static final int SESSION_TIMEOUT = 5000; private static ZooKeeper zooKeeper; private static final String ZK_NODE=&quot;/zk‐node&quot;; @Before public void init() throws IOException, InterruptedException &#123; final CountDownLatch countDownLatch = new CountDownLatch(1); zooKeeper=new ZooKeeper(ZK_ADDRESS, SESSION_TIMEOUT, event ‐&gt; &#123; if (event.getState()== Watcher.Event.KeeperState.SyncConnected &amp;&amp; event.getType() == Watcher.Event.EventType.None)&#123; countDownLatch.countDown(); log.info(&quot;连接成功!&quot;); &#125; &#125;); log.info(&quot;连接中....&quot;); countDownLatch.await(); &#125;&#125; 构造方法 参数名称 含义 connectString ZooKeeper服务器列表，由英文逗号分开的host:port字符串组成， 每一个都代表一台ZooKeeper机器，host1:port1,host2:port2,host3:port3另外，也可以在connectString中设 置客户端连接上ZooKeeper 后的根目录，方法是在host:port字符串之后添加上这个根目录，例如,host1:port1,host2:port2,host3:port3/zk-base，这样就指定了该客户端连接上ZooKeeper服务器之后，所有对ZooKeeper 的操作，都会基于这个根目录。例如，客户端对/sub-node 的操作，最终创建 /zk-node/sub-node, 这个目录也叫Chroot，即客户端隔离命名空间。 sessionTimeout 会话的超时时间，是一个以“毫秒”为单位的整型值。在ZooKeeper中有会话的概念，在一个会话周期内，ZooKeeper客户端和服务器之间会通过心跳检测机制来维持会话的有效性，一旦在sessionTimeout时间内没有进行有效的心跳检测，会话就会失效。 watcher ZooKeeper允许客户端在构造方法中传入一个接口 watcher (org.apache. zookeeper. Watcher)的实现类对象来作为默认的 Watcher事件通知处理器。当然，该参数可以设置为null 以表明不需要设置默认的 Watcher处理器。 canBeReadOnly 这是一个boolean类型的参数，用于标识当前会话是否支持“read-only(只读)”模式。默认情况下，在ZooKeeper集群中，一个机器如果和集群中过半及以上机器失去了网络连接，那么这个机器将不再处理客户端请求(包括读写请求)。但是在某些使用场景下，当ZooKeeper服务器发生此类故障的时候，还是希望ZooKeeper服务器能够提供读服务(当然写服务肯定无法提供)—— 这就是 ZooKeeper的“read-only”模式。 sessionId和 ses sionPasswd 分别代表会话ID和会话秘钥。这两个参数能够唯一确定一个会话，同时客户端使用这两个参数可以实现客户端会话复用，从而达到恢复会话的效果。具体使用方法是，第一次连接上ZooKeeper服务器时，通过调用ZooKeeper对象实例的以下两个接口，即可获得当前会话的ID和秘钥: long getSessionId();byte[]getSessionPasswd( ); 获取到这两个参数值之后，就可以在下次创建ZooKeeper对象实例的时候传入构造方法了 同步创建节点12345@Testpublic void createTest()throws KeeperException,InterruptedException&#123; String path = zooKeeper.create(ZK_NODE, &quot;data&quot;.getBytes(), ZooDefs.Ids.OPEN_ CL_UNSAFE,CreateMode.PERSISTENT); log.info(&quot;created path: &#123;&#125;&quot;,path);&#125; 异步创建节点123456@Test public void createAsycTest()throws InterruptedException&#123; zooKeeper.create(ZK_NODE, &quot;data&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT, (rc, path, ctx, name) ‐&gt; log.info(&quot;rc &#123;&#125;,path &#123;&#125;,ctx &#123;&#125;,name &#123;&#125;&quot;,rc,path,ctx,name),&quot;context&quot;); TimeUnit.SECONDS.sleep(Integer.MAX_VALUE);&#125; 修改节点数据123456789@Testpublic void setTest()throwsKeeperException,InterruptedException&#123; Stat stat = new Stat(); byte[] data = zooKeeper.getData(ZK_NODE, false, stat); log.info(&quot;修改前: &#123;&#125;&quot;,new String(data)); zooKeeper.setData(ZK_NODE, &quot;changed!&quot;.getBytes(), stat.getVersion()); byte[] dataAfter = zooKeeper.getData(ZK_NODE, false, stat); log.info(&quot;修改后: &#123;&#125;&quot;,new String(dataAfter));&#125; CuratorCurator 是一套由netflix 公司开源的，Java 语言编程的 ZooKeeper 客户端框架，Curator项目是现在ZooKeeper 客户端中使用最多，对ZooKeeper 版本支持最好的第三方客户端，并推荐使用，Curator 把我们平时常用的很多 ZooKeeper 服务开发功能做了封装，例如 Leader 选举、 分布式计数器、分布式锁。这就减少了技术人员在使用 ZooKeeper 时的大部分底层细节开发工作。 在会话重新连接、Watch 反复注册、多种异常处理等使用场景中，用原生的 ZooKeeper 处理比较复杂。而在使用 Curator 时，由于其对这些功能都做了高度的封装，使用起来更加简单，不但减少了开发时间，而且增强了程序的可靠性。 Curator 实战这里以 Maven 工程为例，首先要引入Curator 框架相关的开发包，这里为了方便测试引入 了junit ，lombok，由于Zookeeper本身以来了 log4j 日志框架，所以这里可以创建对应的 log4j配置文件后直接使用。 如下面的代码所示，我们通过将 Curator 相关的引用包配置到 Maven 工程的 pom 文件中，将 Curaotr 框架引用到工程项目里，在配置文件中分别引用了两 个 Curator 相关的包 第一个是 curator-framework 包，该包是对 ZooKeeper 底层 API 的一些封装。 另一个是 curator-recipes 包，该包封装了一些 ZooKeeper 服务的高级特性，如: Cache 事件监听、选举、分布式锁、分布式 Barrier。 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator‐recipes&lt;/artifactId&gt; &lt;version&gt;5.0.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.12&lt;/version&gt;&lt;/dependency&gt; 会话创建要进行客户端服务器交互，第一步就要创建会话 Curator 提供了多种方式创建会话 静态工厂方式 1234// 重试策略RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000,3)CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperConnectionString, retryPolicy);client.start(); fluent 风格 123456789RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000,3);CuratorFramework client = CuratorFrameworkFactory.builder().connectString(&quot;192.168.128.129:2181&quot;).sessionTimeoutMs(5000) // 会话超时时间.connectionTimeoutMs(5000) // 连接超时时间.retryPolicy(retryPolicy).namespace(&quot;base&quot;) // 包含隔离名称.build();client.start(); 这段代码的编码风格采用了流式方式，最核心的类是 CuratorFramework 类，该类的作用是定 义一个 ZooKeeper 客户端对象，并在之后的上下文中使用。在定义 CuratorFramework 对象实例的时候，使用了 CuratorFrameworkFactory 工厂方法，并指定了 connectionString 服务器地址列表、retryPolicy 重试策略 、sessionTimeoutMs 会话超时时间、 connectionTimeoutMs 会话创建超时时间。 connectionString:服务器地址列表 如果是多个地址，那么每个服务器地址列表用逗号分隔， 如 host1:port1,host2:port2,host3;port3 。 retryPolicy:重试策略 当客户端异常退出或者与服务端失去连接的时候，可以通过设置客户端重新连接 ZooKeeper 服务端。而 Curator 提供了 一次重试、多次重试等不同种类的实现方式。 在 Curator 内部，可以通过判断服务器返回的 keeperException 的状态代码来判断是否进行重试处理，如果返回的是 OK 表示一切操作都没有问题，而 SYSTEMERROR 表示系统或服务端错误。 策略名称 描述 ExponentialBackoffRetry 重试一组次数，重试之间的睡眠时间增加 RetryNTimes 重试最大次数 RetryOneTime 只重试一次 RetryUntilElapsed 在给定的时间结束之前重试 超时时间:Curator 客户端创建过程中，有两个超时时间的设置。一个是 sessionTimeoutMs 会话超时时间，用来设置该条会话在 ZooKeeper 服务端的失效时间。另一个是 connectionTimeoutMs 客户端创建会话的超时时间，用来限制客户端发起一个会话连接到接收 ZooKeeper 服务端应答的时间。sessionTimeoutMs 作用在服务端，而 connectionTimeoutMs 作用在客户端。 创建节点创建节点的方式如下面的代码所示，回顾我们之前课程中讲到的内容，描述一个节点要包括节点的类型，即临时节点还是持久节点、节点的数据信息、节点是否是有序节点等属性和性质。 123456@Testpublic void testCreate() throwsException&#123; String path = curatorFramework.create().forPath(&quot;/curator‐node&quot;); // curatorFramework.create().withMode(CreateMode.PERSISTENT).forPath(&quot;/curatr‐node&quot;,&quot;some‐data&quot;.getBytes()) log.info(&quot;curator create node :&#123;&#125; successfully.&quot;,path); &#125; 在 Curator 中，可以使用 create 函数创建数据节点，并通过 withMode 函数指定节点类型 (持久化节点，临时节点，顺序节点，临时顺序节点，持久化顺序节点等)，默认是持久化节点，之后调用 forPath 函数来指定节点的路径和数据信息。 一次性创建带层级结构的节点123456@Testpublic void testCreateWithParent() throws Exception&#123; String pathWithParent=&quot;/node‐parent/sub‐node‐1&quot;; String path = curatorFramework.create().creatingParentsIfNeeded().forPath(pathWithParent); log.info(&quot;curator create node :&#123;&#125; successfully.&quot;,path); &#125; 获取数据12345@Testpublic void testGetData() throws Exception&#123; byte[] bytes = curatorFramework.getData().forPath(&quot;/curator‐node&quot;); log.info(&quot;get data from node :&#123;&#125; successfully.&quot;,new String(bytes));&#125; 更新节点我们通过客户端实例的 setData() 方法更新 ZooKeeper 服务上的数据节点，在setData 方法的后边，通过 forPath 函数来指定更新的数据节点路径以及要更新的数据。 123456@Test public void testSetData() throws Exception&#123; curatorFramework.setData().forPath(&quot;/curator‐node&quot;,&quot;changed!&quot;.getBytes()); byte[] bytes = curatorFramework.getData().forPath(&quot;/curator‐node&quot;); log.info(&quot;get data from node /curator‐node :&#123;&#125; successfully.&quot;,new String(bytes));&#125; 删除节点12345@Testpublic void testDelete() throws Exception&#123; String pathWithParent=&quot;/node‐parent&quot;; curatorFramework.delete().guaranteed().deletingChildrenIfNeeded().forPath(pathWithParent);&#125; guaranteed:该函数的功能如字面意思一样，主要起到一个保障删除成功的作用，底层工作方式是:只要该客户端的会话有效，就会在后台持续发起删除请求，直到该数据节点在 ZooKeeper 服务端被删除。 deletingChildrenIfNeeded:指定了该函数后，系统在删除该数据节点的时候会以递归的方式直接删除其子节点，以及子节点的子节点。 异步接口Curator 引入了BackgroundCallback 接口，用来处理服务器端返回来的信息，这个处理过程是在异步线程中调用，默认在 EventThread 中调用，也可以自定义线程池。 123public interface BackgroundCallback&#123; public void processResult(CuratorFramework client, CuratorEvent event) throws Exception;&#125; 如上接口，主要参数为 client 客户端，和服务端事件 event inBackground 异步处理默认在EventThread中执行 1234567@Testpublic void test() throws Exception&#123; curatorFramework.getData().inBackground((item1, item2) ‐&gt; &#123; log.info(&quot; background: &#123;&#125;&quot;, item2); &#125;).forPath(ZK_NODE); TimeUnit.SECONDS.sleep(Integer.MAX_VALUE);&#125; 指定线程池123456789@Testpublic void test() throws Exception&#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); curatorFramework.getData().inBackground((item1, item2) ‐&gt; &#123; log.info(&quot; background: &#123;&#125;&quot;, item2); &#125;,executorService).forPath(ZK_NODE); TimeUnit.SECONDS.sleep(Integer.MAX_VALUE);&#125; Curator 监听器123public interface CuratorListener&#123; public void eventReceived(CuratorFramework client, CuratorEvent event) throws Exception; &#125; 针对 background 通知和错误通知。使用此监听器之后，调用inBackground 方法会异步获得监听 Curator CachesCurator 引入了 Cache 来实现对 Zookeeper 服务端事件监听，Cache 事件监听可以理解为一个本地缓存视图与远程 Zookeeper 视图的对比过程。Cache 提供了反复注册的功能。Cache 分为两类注册类型:节点监听和子节点监听。 node cacheNodeCache 对某一个节点进行监听 1public NodeCache(CuratorFrameworkclient, String path) 可以通过注册监听器来实现，对当前节点数据变化的处理 1public void addListener(NodeCacheListenerlistener) 12345678910111213141516171819202122232425@Slf4jpublic class NodeCacheTest extends AbstractCuratorTest&#123; public static final String NODE_CACHE=&quot;/node‐cache&quot;; @Test public void testNodeCacheTest() throws Exception &#123; createIfNeed(NODE_CACHE); NodeCache nodeCache = new NodeCache(curatorFramework, NODE_CACHE); nodeCache.getListenable().addListener(new NodeCacheListener() &#123; @Override public void nodeChanged() throws Exception &#123; log.info(&quot;&#123;&#125; path nodeChanged: &quot;,NODE_CACHE); printNodeData(); &#125; &#125;); nodeCache.start(); &#125; public void printNodeData() throws Exception &#123; byte[] bytes = curatorFramework.getData().forPath(NODE_CACHE); log.info(&quot;data: &#123;&#125;&quot;,new String(bytes)); &#125;&#125; path cachePathChildrenCache 会对子节点进行监听，但是不会对二级子节点进行监听 1public PathChildrenCache(CuratorFrameworkclient, String path, boolean cacheData) 可以通过注册监听器来实现，对当前节点的子节点数据变化的处理 1public void addListener(PathChildrenCacheListener listener) 1234567891011121314151617181920@Slf4jpublic class PathCacheTest extends AbstractCuratorTest&#123; public static final String PATH=&quot;/path‐cache&quot;; @Test public void testPathCache() throws Exception &#123; createIfNeed(PATH); PathChildrenCache pathChildrenCache = new PathChildrenCache(curatorFramework, PATH, true); pathChildrenCache.getListenable().addListener(new PathChildrenCacheListener() &#123; @Override public void childEvent(CuratorFramework client, PathChildrenCacheEvent event) throws Exception &#123; log.info(&quot;event: &#123;&#125;&quot;,event); &#125; &#125;); // 如果设置为true则在首次启动时就会缓存节点内容到Cache中 pathChildrenCache.start(true); &#125;&#125; tree cacheTreeCache 使用一个内部类TreeNode来维护这个一个树结构。并将这个树结构与ZK节点进行映射。所以TreeCache 可以监听当前节点下所有节点的事件。 1public TreeCache(CuratorFrameworkclient, String path, boolean cacheData) 可以通过注册监听器来实现，对当前节点的子节点，及递归子节点数据变化的处理 1public void addListener(TreeCacheListener listener) 123456789101112131415161718@Slf4jpublic class TreeCacheTest extends AbstractCuratorTest&#123; public static final String TREE_CACHE=&quot;/tree‐path&quot;; @Test public void testTreeCache() throws Exception &#123; createIfNeed(TREE_CACHE); TreeCache treeCache = new TreeCache(curatorFramework, TREE_CACHE); treeCache.getListenable().addListener(new TreeCacheListener() &#123; @Override public void childEvent(CuratorFramework client, TreeCacheEvent event) throw Exception &#123; log.info(&quot; tree cache: &#123;&#125;&quot;,event); &#125; &#125;); treeCache.start(); &#125;&#125; Zookeeper 集群模式Zookeeper 集群模式一共有三种类型的角色 Leader: 处理所有的事务请求(写请求)，可以处理读请求，集群中只能有一个Leader Follower:只能处理读请求，同时作为 Leader的候选节点，即如果Leader宕机，Follower节点 要参与到新的Leader选举中，有可能成为新的Leader节点。 Observer:只能处理读请求。不能参与选举 集群部署本例搭建的是伪集群模式，即一台机器上启动四个zookeeper实例组成集群，真正的集群模式无非就是实例IP地址不同，搭建方法没有区别 配置JAVA环境，检验环境:保证是jdk7 及以上即可 1java ‐version 下载并解压zookeeper 123wget https:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;zookeeper&#x2F;zookeeper‐3.5.8&#x2F;apache‐zookeeper‐3.5.8‐bin.tar.gztar ‐zxvf apache‐zookeeper‐3.5.8‐bin.tar.gz cd apache‐zookeeper‐3.5.8‐bin 重命名 zoo_sample.cfg文件 1cp conf&#x2F;zoo_sample.cfg conf&#x2F;zoo‐1.cfg 修改配置文件zoo-1.cfg，原配置文件里有的，修改成下面的值，没有的则加上 1234567#vim conf&#x2F;zoo‐1.cfgdataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper‐1clientPort&#x3D;2181server.1&#x3D;127.0.0.1:2001:3001:participant &#x2F;&#x2F; participant 可以不用写，默认就是participantserver.2&#x3D;127.0.0.1:2002:3002:participantserver.3&#x3D;127.0.0.1:2003:3003:participantserver.4&#x3D;127.0.0.1:2004:3004:observer 配置说明 tickTime:用于配置Zookeeper中最小时间单位的长度，很多运行时的时间间隔都是使用tickTime的倍数来表示的。 initLimit:该参数用于配置Leader服务器等待Follower启动，并完成数据同步的时间。Follower服务器再启动过程中，会与Leader建立连接并完成数据的同步，从而确定自己对外提供服务的起始状态。Leader服务器允许Follower再initLimit 时间内完成这个工作。 syncLimit:Leader 与Follower心跳检测的最大延时时间 dataDir:顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将 写数据的日志文件也保存在这个目录里。 clientPort:这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。 server.A=B:C:D:E 其中 A 是一个数字，表示这个是第几号服务器;B 是这个服务器的 ip 地址;C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口;D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。如果需要通过添加不参与集群选举以及事务请求的过半机制的 Observer节点，可以在E的位置，添加observer标识。 再从zoo-1.cfg复制三个配置文件zoo-2.cfg，zoo-3.cfg和zoo-4.cfg，只需修改 dataDir和clientPort不同即可 123456789101112131415cp conf&#x2F;zoo1.cfg conf&#x2F;zoo2.cfgcp conf&#x2F;zoo1.cfg conf&#x2F;zoo3.cfgcp conf&#x2F;zoo1.cfg conf&#x2F;zoo4.cfgvim conf&#x2F;zoo2.cfgdataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper2clientPort&#x3D;2182vim conf&#x2F;zoo3.cfgdataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper3 clientPort&#x3D;2183vim conf&#x2F;zoo4.cfgdataDir&#x3D;&#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper4 clientPort&#x3D;2184 标识Server ID 创建四个文件夹/usr/local/data/zookeeper-1，/usr/local/data/zookeeper- 2，/usr/local/data/zookeeper-3，/usr/local/data/zookeeper-4，在每个目录中创建文件 myid 文件，写入当前实例的server id，即1，2，3，4 123456789101112131415cd &#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper‐1vim myid1cd &#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper‐2vim myid2cd &#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper‐3vim myid3cd&#x2F;usr&#x2F;local&#x2F;data&#x2F;zookeeper‐4vim myid4 启动三个zookeeper实例 123bin&#x2F;zkServer.sh start conf&#x2F;zoo1.cfg bin&#x2F;zkServer.sh start conf&#x2F;zoo2.cfg bin&#x2F;zkServer.sh start conf&#x2F;zoo3.cfg 检测集群状态，也可以直接用命令 zkServer.sh status conf/zoo1.cfg 进行每台服务的状态查询 1bin&#x2F;zkCli.sh ‐server ip1:port1,ip2:port2,ip3:port3 可以通过查看/zookeeper/config 节点数据来查看集群配置 集群动态配置Zookeeper 3.5.0 以前，Zookeeper集群角色要发生改变的话，只能通过停掉所有的 Zookeeper服务，修改集群配置，重启服务来完成，这样集群服务将有一段不可用的状态，为了应对高可用需求，Zookeeper 3.5.0 提供了支持动态扩容/缩容的 新特性。但是通过客户端API 可以变更服务端集群状态是件很危险的事情，所以在zookeeper 3.5.3 版本要用动态配置，需要 开启超级管理员身份验证模式 ACLs。如果是在一个安全的环境也可以通过配置 系统参数 - Dzookeeper.skipACL=yes 来避免配置维护acl 权限配置。 先配置一个超级管理员(如果不配管理员，也可以设置系统参数 - Dzookeeper.skipACL=yes) 123456#在zookeeper启动脚本中添加 超级管理员授权模式:echo ‐n gj:123 | openssl dgst ‐binary ‐sha1 | openssl base64&#x2F;&#x2F;RRCKWv2U2e99M6UmsFaJiQ2xStw&#x3D;‐Dzookeeper.DigestAuthenticationProvider.superDigest&#x3D;gj:RRCKWv2U2e99M6UmsFaJiQ2xStw&#x3D; 配置动态文件 修改配置 zoo1.cfg注意这里去除了端口号，添加了 reconfigEnabled : 设置为true 开启动态配置dynamicConfigFile : 指定动态配置文件的路径 创建文件 zoo_replicated1.cfg.dynamic 12345678910111213动态配置文件,加入集群信息 server.A&#x3D;B.C.D.E;FA: 服务的唯一标识B: 服务对应的IP地址C: 集群通信端口D: 集群选举端口E: 角色，默认是 participant,即参与过半机制的角色，选举，事务请求过半提交 还有一个是 observer, 观察者，不参与选举以及过半机制。之后是一个分号，一定是分号F:服务IP:端口server.1&#x3D;192.168.109.200:2001:3001:participant;192.168.109.200:2181server.2&#x3D;192.168.109.200:2002:3002:participant;192.168.109.200:2182server.3&#x3D;192.168.109.200:2003:3003:participant;192.168.109.200:2183 依次配置其他服务 zoo2.cfg ,zoo3.cfg注意数据文件的路径 12345依次启动所有服务.&#x2F;bin&#x2F;zkServer.sh start conf&#x2F;zoo1.cfg 查看集群状态.&#x2F;bin&#x2F;zkServer.sh status conf&#x2F;zoo1.cfg 连上任意一台服务器 12345678910查看集群配置config &#x2F;&#x2F; 将会把动态配置打印出来 也可以直接查看目录 &#x2F;zookeeper&#x2F;config 该节点存储了集群信息如果要修改集群状态，需要授权登录addauth digest gj:123reconfig ‐remove 3 &#x2F;&#x2F; 移除serverId为 3 的机器&#x2F;&#x2F; 把对应的机器加进来reconfig ‐add server.3&#x3D;192.168.109.200:2003:3003:participant;192.168.109.200:2183 如果要变更/或者添加新的服务需要将服务加到配置文件 zoo_replicated1.cfg.dynamic 中，启动服务然后通过reconfig 命令进行添加或者变更服务角色，但是需要保证服务列表中 participant 角色能够形成集群(过半机制) 客户端可以通过监听 /zookeeper/confg 节点，来感知集群的变化，从而实现集群的动态变更. Zookeeper 类提供了对应的API 用来更新服务列表 : updateServerList 12345678910111213141516171819202122232425262728293031Watcher watcher = new Watcher() &#123; @Override public void process(WatchedEvent event) &#123; if (event.getType() == Event.EventType.None &amp;&amp; event.getState() == Event.KeeperState.SyncConnected)&#123; countDownLatch.countDown(); log.info(&quot; 连接建立&quot;); // start to watch config try&#123; log.info(&quot; 开始监听:&#123;&#125;&quot;,ZooDefs.CONFIG_NODE); zookeeper.getConfig(true,null); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;else if( event.getPath() !=null &amp;&amp; event.getPath().equals(ZooDefs.CONFIG_NONE))&#123; try&#123; byte[] config = zookeeper.getConfig(this, null); String clientConfigStr = ConfigUtils.getClientConfigStr(new String(config)) log.info(&quot; 配置发生变更: &#123;&#125;&quot;,clientConfigStr); zookeeper.updateServerList(clientConfigStr.split(&quot; &quot;)[1]); &#125; catch (KeeperException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;; Curator 也自带了动态配置的监听，不需要额外的配置和代码实现监听更新; Zookeeper分布式锁非公平锁 如上实现方式在并发问题比较严重的情况下，性能会下降的比较厉害，主要原因是，所有的连接都在对同一个节点进行监听，当服务器检测到删除事件时，要通知所有的连接，所有的连接同时收到事件，再次并发竞争，这就是羊群效应。 公平锁 实战创建表，并且插入一条库存数据 12345678910111213141516171819DROP TABLE IF EXISTS `order`;CREATE TABLE `order` ( `id` int(11) NOT NULL AUTO_INCREMENT, `pid` int(11) DEFAULT NULL, `user_id` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;DROP TABLE IF EXISTS `product`;CREATE TABLE `product` ( `id` int(11) NOT NULL AUTO_INCREMENT, `product_name` varchar(255) DEFAULT NULL, `stock` int(11) DEFAULT NULL, `version` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;INSERT INTO `product` VALUES (&#x27;1&#x27;, &#x27;苹果手机&#x27;, &#x27;5&#x27;, &#x27;0&#x27;); 不加分布式锁代码，注释掉CuratorFramework相关代码 加分布式锁代码，打开注释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546// controller @Autowired private CuratorFramework curatorFramework; @GetMapping(&quot;/stock/deduct/&#123;id&#125;&quot;) public Object reduceStock(@PathVariable Integer id) throws Exception &#123;// InterProcessMutex lock = new InterProcessMutex(curatorFramework, &quot;/product_&quot; + id); try &#123;// lock.acquire(); orderService.reduceStock(id); &#125; catch (Exception e) &#123; if (e instanceof RuntimeException) &#123; throw e; &#125; &#125; // finally &#123;// lock.release();// &#125; return &quot;ok:&quot; + port; &#125; // service @Transactional(rollbackFor = Exception.class) public void reduceStock(Integer id) &#123; // 1. 获取库存 Product product = productMapper.getProduct(id); // 模拟耗时业务处理 sleep(500); if (product.getStock() &lt;= 0) &#123; throw new RuntimeException(&quot;out of stock&quot;); &#125; // 2. 减库存 int i = productMapper.deductStock(id); if (i == 1) &#123; Order order = new Order(); order.setUserId(UUID.randomUUID().toString()); order.setPid(id); orderMapper.insert(order); &#125; else &#123; throw new RuntimeException(&quot;deduct stock fail, retry.&quot;); &#125; &#125; 不加锁，请求有可能全部成功，库存出现负数的情况 加锁，只有五个请求成功（因为只有五个库存），操作完库存为0","categories":[],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://tj-ever.github.io/tags/Zookeeper/"}]},{"title":"Zookeeper 特性及节点数据","slug":"Zookeeper 特性及节点数据","date":"2021-10-05T16:00:00.000Z","updated":"2021-10-05T14:31:53.914Z","comments":true,"path":"2021/10/06/Zookeeper 特性及节点数据/","link":"","permalink":"https://tj-ever.github.io/2021/10/06/Zookeeper%20%E7%89%B9%E6%80%A7%E5%8F%8A%E8%8A%82%E7%82%B9%E6%95%B0%E6%8D%AE/","excerpt":"","text":"在了解Zookeeper之前，需要对分布式相关知识有一定了解，什么是分布式系统? 通常情况 下，单个物理节点很容易达到性能，计算或者容量的瓶颈，所以这个时候就需要多个物理节点来 共同完成某项任务，一个分布式系统的本质是分布在不同网络或计算机上的程序组件，彼此通过信息传递来协同工作的系统，而Zookeeper正是一个分布式应用协调框架，在分布式系统架构中有广泛的应用场景。 Zookeeper官方文档上这么解释zookeeper，它是一个分布式协调框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如:统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。 核心概念上面的解释有点抽象，我们暂时可以理解为 Zookeeper 是一个用于存储少量数据的基于内存的数据库 主要有如下两个核心的概念:文件系统数据结构+监听通知机制。 文件系统数据结构Zookeeper维护一个类似文件系统的数据结构 每个子目录项都被称作为 znode(目录节点)，和文件系统类似，我们能够自由的增加、删除 znode，在一个znode下增加、删除子znode。有四种类型的znode: PERSISTENT­ 持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只要不手动删除该节点，将永远存在 PERSISTENT_SEQUENTIAL­ 持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号 EPHEMERAL­ 临时目录节点 客户端与zookeeper断开连接后，该节点被删除 EPHEMERAL_SEQUENTIAL­ 临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号 Container 节点(3.5.3 版本新增，如果Container节点下面没有子节点，则Container节点在未来会被Zookeeper自动清除,定时任务默认60s 检查一次) TTL 节点( 默认禁用，只能通过系统配置 zookeeper.extendedTypesEnabled=true 开启，不稳定) 监听通知机制客户端注册监听它关心的任意节点，或者目录节点及递归子目录节点 如果注册的是对某个节点的监听，则当这个节点被删除，或者被修改时，对应的客户端将被通知 如果注册的是对某个目录的监听，则当这个目录有子节点被创建，或者有子节点被删除，对应的客户端将被通知 如果注册的是对某个目录的递归子节点进行监听，则当这个目录下面的任意子节点有目录结构的变化(有子节点被创建，或被删除)或者根节点有数据变化时，对应的客户端将被通知。 注意：所有的通知都是一次性的，及无论是对节点还是对目录进行的监听，一旦触发，对应的监听即被移除。递归子节点，监听是对所有子节点的，所以，每个子节点下面的事件同样只会被触发一次。 经典的应用场景 分布式配置中心 分布式注册中心 分布式锁 分布式队列 集群选举 分布式屏障 发布/订阅 Zookeeper 实战zookeeper安装 配置JAVA环境，检验环境 1java ‐version 下载解压 zookeeper 123wget https://mirror.bit.edu.cn/apache/zookeeper/zookeeper‐3.5.8/apache‐zookeep r‐3.5.8‐bin.tar.gztar ‐zxvf apache‐zookeeper‐3.5.8‐bin.tar.gzcd apache‐zookeeper‐3.5.8‐bin 重命名配置文件 zoo_sample.cfg 1cp zoo_sample.cfg zoo.cfg 启动zookeeper 12# 可以通过 bin/zkServer.sh 来查看都支持哪些参数 bin/zkServer.sh start conf/zoo.cfg 检测是否启动成功 123echo stat | nc 192.168.109.200 // 前提是配置文件中中将 stat 四字命令设置了白名单4lw.commands.whitelist=stat 连接服务器 1bin/zkCli.sh ‐server ip:port 使用命令行操作zookeeper输入命令 help 查看zookeeper所支持的所有命令 节点操作操作根据上方的help命令 stat cZxid:创建znode的事务ID(Zxid的值)。 mZxid:最后修改znode的事务ID。 pZxid:最后添加或删除子节点的事务ID(子节点列表发生变化才会发生改变)。 ctime:znode创建时间。 mtime:znode最近修改时间。 dataVersion:znode的当前数据版本。 cversion:znode的子节点结果集版本(一个节点的子节点增加、删除都会影响这个版本)。 aclVersion:表示对此znode的acl版本。 ephemeralOwner:znode是临时znode时，表示znode所有者的 session ID。 如果znode不是临时znode，则该字段设置为零。 dataLength:znode数据字段的长度。 numChildren:znode的子znode的数量。 乐观锁修改 其他类型节点操作类似，此处不再赘述 事件监听机制针对节点的监听一定事件触发，对应的注册立刻被移除，所以事件监听是一次性的 12345&#x2F;&#x2F; 注册监听的同时获取数据get ‐w &#x2F;path&#x2F;&#x2F;对节点进行监听，且获取元数据信息stat ‐w &#x2F;path 针对目录的监听，如下图，目录的变化，会触发事件，且一旦触发，对应的监听也会被移除，后续对节点的创建没有触发监听事件 针对递归子目录的监听1ls ‐R ‐w &#x2F;path : ‐R 区分大小写，一定用大写 如下对/test 节点进行递归监听，但是每个目录下的目录监听也是一次性的 如第一次在/test 目录下创建节点时，触发监听事件，第二次则没有 同样，在/test/sub1下进行节点创建时，触发事件，但是再次创建/test/sub1/sub-2节点时，没有触发事件。 Zookeeper事件类型 None: 连接建立事件 NodeCreated: 节点创建 NodeDeleted: 节点删除 NodeDataChanged:节点数据变化 NodeChildrenChanged:子节点列表变化 DataWatchRemoved:节点监听被移除 ChildWatchRemoved:子节点监听被移除 ACL 权限控制Zookeeper 的ACL( Access Control List ) 权限控制，可以控制节点的读写操作，保证数据的安全性。 Zookeeper ACL 权 限设置分为 3 部分组成，分别是 权限模式(Scheme) 用来设置 ZooKeeper 服务器进行权限验证的方式。 ZooKeeper 的权限验证方式大体分为两种类型 范围验证 ZooKeeper 可以针对一个 IP 或者一段 IP 地址授予某种权限。比如我们可以让一个 IP 地址为“ip:192.168.0.110”的机器对服务器上的某个数据节点具有写入的权限。或者也可以通过“ip:192.168.0.1/24”给一段 IP 地址的机器赋权。 口令验证 即用户名密码的方式。在 ZooKeeper 中这种验证方式是 Digest 认证，而 Digest 这种认证方式首先在客户端传送“username:password”这种形式的权限表示符后，ZooKeeper 服务端会对密码部分使用 SHA-1 和 BASE64 算法进行加密， 以保证安全性。 Super权限模式 Super可以认为是一种特殊的 Digest 认证。具有 Super 权限的客户端可以对 ZooKeeper 上的任意数据节点进行任意操作。 授权对象(ID) 授权对象就是说我们要把权限赋予谁，而对应于 4 种不同的权限模式来说， 如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段;而如果使用 Digest 或 Super 方式，则对应于一个用户名。 如果是 World 模式，是授权系统中所有的用户。 权限信息 (Permission)。 权限就是指我们可以在数据节点上执行的操作种类，在 ZooKeeper 中已经定义好的权限有 5 种: 数据节点(c: create)创建权限 授予权限的对象可以在数据节点下创建子节点; 数据节点(w: wirte)更新权限 授予权限的对象可以更新该数据节点 数据节点(r: read)读取权限 授予权限的对象可以读取该节点的内容以及子节点的列表信息 数据节点(d: delete)删除权限 授予权限的对象可以删除该数据节点的子节点 数据节点(a: admin)管理者权限 授予权限的对象可以对该数据节点体进行 ACL 权限设置 命令: getAcl:获取某个节点的acl权限信息 setAcl:设置某个节点的acl权限信息 addauth: 输入认证授权信息，相当于注册用户信息，注册时输入明文密码，zk将以密文的形式存储 可以通过系统参数zookeeper.skipACL=yes进行配置，默认是no,可以配置为true, 则配置过的 ACL将不再进行权限检测 生成授权ID代码生成ID12345@Testpublic void generateSuperDigest() throws NoSuchAlgorithmException&#123; String sId = DigestAuthenticationProvider.generateDigest(&quot;gj:test&quot;); System.out.println(sId);// gj:X/NSthOB0fD/OT6iilJ55WJVado=&#125; xshell 中生成1echo ‐n &lt;user&gt;:&lt;password&gt; | openssl dgst ‐binary ‐sha1 | openssl base64 设置ACL节点创建的同时设置ACL12create [-s] [-e] [-c] path [data] [acl]create &#x2F;zk‐node data digest:gj:X&#x2F;NSthOB0fD&#x2F;OT6iilJ55WJVado&#x3D;:cdrwa setAcl 设置1setAcl &#x2F;zk‐node digest:gj:X&#x2F;NSthOB0fD&#x2F;OT6iilJ55WJVado&#x3D;:cdrwa 添加授权信息后，不能直接访问，直接访问将报如下异常 123get &#x2F;zk‐node&#x2F;&#x2F; 异常信息:org.apache.zookeeper.KeeperException$NoAuthException:KeeperErrorCode&#x3D;NoAuth for &#x2F;zk‐node 授权访问前需要添加授权信息 12345addauth digest gj:testget &#x2F;zk‐node&#x2F;&#x2F; 输出datatest auth 明文授权使用之前需要先 addauth digest username:password 注册用户信息，后续可以直接用明文授权 1234567addauth digest u100:p100create &#x2F;node‐1 node1data auth:u100:p100:cdwra&#x2F;&#x2F; 这是u100用户授权信息会被zk保存，可以认为当前的授权用户为u100 get &#x2F;node‐1&#x2F;&#x2F; 输出node1data IP授权模式12345setAcl &#x2F;node-ip ip:192.168.0.102:cdrwacreate &#x2F;node-ip ip:192.168.0.102:cdrwa&#x2F;&#x2F; 多个指定IP可以通过逗号分隔setAcl &#x2F;node-ip ip:IP1:rw,ip:IP2:a Super 超级管理员模式这是一种特殊的Digest模式， 在Super模式下超级管理员用户可以对Zookeeper上的节点进行任何的操作。需要在启动了上通过JVM 系统参数开启 12DigestAuthenticationProvider中定义‐Dzookeeper.DigestAuthenticationProvider.superDigest&#x3D;super: &lt;base64encoded(SHA1(password)) 内存数据和持久化Zookeeper数据的组织形式为一个类似文件系统的数据结构，而这些数据都是存储在内存中的， 所以我们可以认为，Zookeeper是一个基于内存的小型数据库 内存中的数据12345public class DataTree&#123; private final ConcurrentHashMap&lt;String, DataNode&gt; nodes = new ConcurrentHashMap&lt;String, DataNode&gt;(); private final WatchManager dataWatches = new WatchManager(); private final WatchManager childWatches = new WatchManager();&#125; DataNode 是Zookeeper存储节点数据的最小单位 123456public class DataNodeimplementsRecord&#123; byte data[]; Long acl; public StatPersisted stat; private Set&lt;String&gt; children = null;&#125; 事务日志针对每一次客户端的事务操作，Zookeeper都会将他们记录到事务日志中，Zookeeper也会将数据变更应用到内存数据库中。 我们可以在zookeeper的主配置文件zoo.cfg 中配置内存中的数据持久化目录，也就是事务日志的存储路径 dataLogDir. 如果没有配置dataLogDir(非必填)，事务日志将存储到dataDir (必填项)目录 zookeeper提供了格式化工具可以进行数据查看事务日志数据 org.apache.zookeeper.server.LogFormatter 1java ‐classpath .:slf4j‐api‐1.7.25.jar:zookeeper‐3.5.8.jar:zookeeper‐jute‐3.5.8.jar org.apache.zookeeper.server.LogFormatter &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;apache‐zookeeper‐3.5.8‐bin&#x2F;data&#x2F;version‐2&#x2F;log.1 如下是我本地的日志文件格式化效果 从左到右分别记录了操作时间，客户端会话ID，CXID,ZXID,操作类型，节点路径，节点数据(用 #+ascii 码表示)，节点版本。 Zookeeper进行事务日志文件操作的时候会频繁进行磁盘IO操作，事务日志的不断追加写操作会触发底层磁盘IO为文件开辟新的磁盘块，即磁盘Seek。为了提升磁盘IO的效率， Zookeeper在创建事务日志文件的时候就进行文件空间的预分配，即在创建文件的时候，就向操 作系统申请一块大一点的磁盘块。这个预分配的磁盘大小可以通过系统参数 zookeeper.preAllocSize 进行配置。 事务日志文件名为: log.&lt;当时最大事务ID&gt;，因为为日志文件时顺序写入的，所以这个最大事务 ID也将是整个事务日志文件中，最小的事务ID，日志满了即进行下一次事务日志文件的创建 数据快照数据快照用于记录Zookeeper服务器上某一时刻的全量数据，并将其写入到指定的磁盘文件中。 可以通过配置snapCount配置每间隔事务请求个数，生成快照，数据存储在dataDir 指定的目录中。 可以通过如下方式进行查看快照数据，为了避免集群中所有机器在同一时间进行快照，实际的快照生成时机为事务数达到 [snapCount/2 + 随机数(随机数范围为1 ~ snapCount/2 )] 个数时开始快照 1java ‐classpath .:slf4j‐api‐1.7.25.jar:zookeeper‐3.5.8.jar:zookeeper‐jute‐3.5.8.jar org.apache.zookeeper.server.SnapshotFormatter &#x2F;usr&#x2F;local&#x2F;zookeeper&#x2F;apache‐zookeeper‐3.5.8‐bin&#x2F;data‐dir&#x2F;version‐2&#x2F;snapshot.0 快照事务日志文件名为: snapshot.&lt;当时最大事务ID&gt;，日志满了即进行下一次事务日志文件的创建 有了事务日志，为啥还要快照数据？快照数据主要时为了快速恢复， 事务日志文件是每次事务请求都会进行追加的操作，而快照是达到某种设定条件下的内存全量数据。所以通常快照数据是反应当时内存数据的状态。事务日志是更全面的数据，所以恢复数据的时候，可以先恢复快照数据，再通过增量恢复事务日志中的数据即可。","categories":[],"tags":[{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://tj-ever.github.io/tags/Zookeeper/"}]},{"title":"MySQL MVCC及BufferPool机制","slug":"MySQL MVCC及BufferPool机制","date":"2021-10-04T16:00:00.000Z","updated":"2021-10-05T03:10:47.097Z","comments":true,"path":"2021/10/05/MySQL MVCC及BufferPool机制/","link":"","permalink":"https://tj-ever.github.io/2021/10/05/MySQL%20MVCC%E5%8F%8ABufferPool%E6%9C%BA%E5%88%B6/","excerpt":"","text":"MVCC多版本并发控制机制Mysql在可重复读隔离级别下，同样的sql查询语句在一个事务里多次执行查询结果相同，就算其它事务对数据有修改也不会影响当前事务sql语句的查询结果。 这个隔离性就是靠MVCC(Multi-Version Concurrency Control)机制来保证的，对一行数据的读和写两个操作默认是不会通过加锁互斥来保证隔离性，避免了频繁加锁互斥，而在串行化隔离级别为了保证较高的隔离性是通过将所有操作加锁互斥来实现的。 Mysql在读已提交和可重复读隔离级别下都实现了MVCC机制。 undo日志版本链与read view机制undo日志版本链是指一行数据被多个事务依次修改过后，在每个事务修改完后，Mysql会保留修改前的数据undo回滚日志，并且用两个隐藏字段trx_id和roll_pointer把这些undo日志串联起来形成一个历史记录版本链 在可重复读隔离级别，当事务开启，执行任何查询sql时会生成当前事务的一致性视图read-view，该视图在事务结束之前都不会变化(如果是读已提交隔离级别在每次执行查询sql时都会重新生成). 这个视图由执行查询时所有未提交事务id数组(数组里最小的id为min_id)和已创建的最大事务id(max_id)组成，事务里的任何sql查询结果需要从对应版本链里的最新数据开始逐条跟read-view做比对从而得到最终的快照结果。 版本链比对规则: 如果 row 的 trx_id 落在绿色部分( trx_id&lt;min_id )，表示这个版本是已提交的事务生成的，这个数据是可见的; 如果 row 的 trx_id 落在红色部分( trx_id&gt;max_id )，表示这个版本是由将来启动的事务生成的，是不可见的(若 row 的 trx_id 就是当前自己的事务是可见的); 如果 row 的 trx_id 落在黄色部分(min_id &lt;=trx_id&lt;= max_id)，那就包括两种情况 若 row 的 trx_id 在视图数组中，表示这个版本是由还没提交的事务生成的，不可见(若 row 的 trx_id 就是当前自己的事务是可见的) 若 row 的 trx_id 不在视图数组中，表示这个版本是已经提交了的事务生成的，可见。 对于删除的情况可以认为是update的特殊情况，会将版本链上最新的数据复制一份，然后将trx_id修改成删除操作的 trx_id，同时在该条记录的头信息(record header)里的(deleted_flag)标记位写上true，来表示当前记录已经被删除，在查询时按照上面的规则查到对应的记录如果delete_flag标记位为true，意味着记录已被删除，则不返回数据。 注意：begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个修改操作InnoDB表的语句， 事务才真正启动，才会向mysql申请事务id，mysql内部是严格按照事务的启动顺序来分配事务id的。 总结： MVCC机制的实现就是通过read-view机制与undo版本链比对机制，使得不同的事务会根据数据版本链对比规则读取同一条数据在版本链上的不同版本数据。 Innodb引擎SQL执行的BufferPool缓存机制 为什么Mysql不能直接更新磁盘上的数据而且设置这么一套复杂的机制来执行SQL了? 因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据性能可能相当差。 因为磁盘随机读写的性能是非常差的，所以直接更新磁盘文件是不能让数据库抗住很高并发的。 Mysql这套机制看起来复杂，但它可以保证每个更新请求都是更新内存BufferPool，然后顺序写日志文件，同时还能保证各种异常情况下的数据一致性。 更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是非常高的，要远高于随机读写磁盘文件。 正是通过这套机制，才能让MySQL数据库在较高配置的机器上每秒可以抗下几干的读写请求。","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tj-ever.github.io/tags/MySQL/"}]},{"title":"MySQL 事务及锁机制","slug":"MySQL 事务及锁机制","date":"2021-10-03T16:00:00.000Z","updated":"2021-10-04T13:57:54.221Z","comments":true,"path":"2021/10/04/MySQL 事务及锁机制/","link":"","permalink":"https://tj-ever.github.io/2021/10/04/MySQL%20%E4%BA%8B%E5%8A%A1%E5%8F%8A%E9%94%81%E6%9C%BA%E5%88%B6/","excerpt":"","text":"概述数据库一般都会并发执行多个事务，多个事务可能会并发的对相同的一批数据进行增删改查操作，可能就会导致脏写、脏读、不可重复读、幻读这些问题。 这些问题的本质都是数据库的多事务并发问题，为了解决多事务并发问题，数据库设计了事务隔离机制、锁机制、MVCC多版本并发控制隔离机制，用一整套机制来解决多事务并发问题。 事务及其ACID属性事务是由一组SQL语句组成的逻辑处理单元,事务具有以下4个属性,通常简称为事务的ACID属性。 原子性(Atomicity) 事务是一个原子操作单元，其对数据的修改,要么全都执行,要么全都不执行。 一致性(Consistent) 在事务开始和完成时,数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性。 隔离性(Isolation) 数据库系统提供一定的隔离机制,保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。 持久性(Durable) 事务完成之后,它对于数据的修改是永久性的,即使出现系统故障也能够保持。 并发事务处理带来的问题更新丢失(Lost Update)或脏写当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题–最后的更新覆盖了由其他事务所做的更新。 脏读(Dirty Reads)一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致的状态；这时另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此作进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象的叫做“脏读”。 一句话：事务A读取到了事务B已经修改但尚未提交的数据，还在这个数据基础上做了操作。此时，如果B事务回滚，A读取的数据无效，不符合一致性要求。 不可重读(Non-Repeatable Reads)一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了。这种现象就叫做“不可重复读”。 一句话：事务A内部的相同查询语句在不同时刻读出的结果不一致，不符合隔离性 幻读(Phantom Reads)一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。 一句话:事务A读取到了事务B提交的新增数据，不符合隔离性 事务隔离级别“脏读”、“不可重复读”和“幻读”，其实都是数据库读一致性问题，必须由数据库提供一定的事务隔离机制来解决。 数据库的事务隔离越严格，并发副作用越小，但付出的代价也就越大，因为事务隔离实质上就是使事务在一定程度上“串行化”进行，这显然与“并发”是矛盾的。 同时不同的应用对读一致性和事务隔离程度的要求也是不同的，比如许多应用对“不可重复读”和“幻读”并不敏感，可能更关心数据并发访问的能力。 12345# 常看当前数据库的事务隔离级别show variables like &#x27;tx_isolation&#x27;;# 设置事务隔离级别set tx_isolation=&#x27;REPEATABLE-READ&#x27;; Mysql默认的事务隔离级别是可重复读，用Spring开发程序时，如果不设置隔离级别默认用Mysql设置的隔离级别，如果Spring设置了就用已经设置的隔离级别 锁详解锁是计算机协调多个进程或线程并发访问某一资源的机制。 在数据库中，除了传统的计算资源(如CPU、RAM、I/O等)的争用以外，数据也是一种供需要用户共享的资 源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。 锁分类 从性能上分为乐观锁(用版本对比来实现) **和 **悲观锁 从对数据库操作的类型分，分为读锁和写锁(都属于悲观锁) 读锁(共享锁，S锁(Shared)) 针对同一份数据，多个读操作可以同时进行而不会互相影响 写锁(排它锁，X锁(eXclusive)) 当前写操作没有完成前，它会阻断其他写锁和读锁 从对数据操作的粒度分，分为表锁和行锁 表锁每次操作锁住整张表。开销小，加锁快，不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；一般用在整表数据迁移的场景。 123456789101112131415# 建表SQLCREATE TABLE `mylock` ( `id` INT ( 11 ) NOT NULL AUTO_INCREMENT, `NAME` VARCHAR ( 20 ) DEFAULT NULL, PRIMARY KEY ( `id` ) ) ENGINE = MyISAM DEFAULT CHARSET = utf8;#插入数据INSERT INTO `test`.`mylock` ( `id`, `NAME` )VALUES ( &#x27;1&#x27;, &#x27;a&#x27; );INSERT INTO `test`.`mylock` ( `id`, `NAME` )VALUES ( &#x27;2&#x27;, &#x27;b&#x27; );INSERT INTO `test`.`mylock` ( `id`, `NAME` )VALUES ( &#x27;3&#x27;, &#x27;c&#x27; );INSERT INTO `test`.`mylock` ( `id`, `NAME` )VALUES ( &#x27;4&#x27;, &#x27;d&#x27; ); 手动增加表锁 lock table 表名称 read(write),表名称2 read(write); 查看表上加过的锁 show open tables; 删除表锁 unlock tables; 加读锁(MyISAM) 当前session和其他session都可以读该表 当前session中插入或者更新锁定的表都会报错，其他session插入或更新则会等待 加写锁(MyISAM) 当前session对该表的增删改查都没有问题，其他session对该表的所有操作被阻塞 案例结论对MyISAM表的读操作(加读锁) ，不会阻寒其他进程对同一表的读请求，但会阻赛对同一表的写请求。只有当读锁释放后才会执行其它进程的写操作。对MylSAM表的写操作(加写锁) ，会阻塞其他进程对同一表的读和写操作，只有当写锁释放后才会执行其它进程的读写操作 行锁每次操作锁住一行数据。开销大，加锁慢，会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度最高。 InnoDB与MYISAM的最大不同有两点: InnoDB支持事务(TRANSACTION) InnoDB支持行级锁 行锁演示一个session开启事务更新不提交，另一个session更新同一条记录会阻塞，更新不同记录不会阻塞 总结: MyISAM在执行查询语句SELECT前，会自动给涉及的所有表加读锁。在执行update、insert、delete操作会自动给涉及的表加写锁。 InnoDB在执行查询语句SELECT时(非串行隔离级别)，不会加锁。但是update、insert、delete操作会加行锁。 简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁则会把读和写都阻塞。 行锁与事务隔离级别案例分析12345678910CREATE TABLE `account` ( `id` INT ( 11 ) NOT NULL AUTO_INCREMENT, `name` VARCHAR ( 255 ) DEFAULT NULL, `balance` INT ( 11 ) DEFAULT NULL, PRIMARY KEY ( `id` ) ) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO `test`.`account` ( `name`, `balance` )VALUES ( &#x27;lilei&#x27;, &#x27;450&#x27; );INSERT INTO `test`.`account` ( `name`, `balance` )VALUES ( &#x27;hanmei&#x27;, &#x27;16000&#x27; );INSERT INTO `test`.`account` ( `name`, `balance` )VALUES ( &#x27;lucy&#x27;, &#x27;2400&#x27; ); 读未提交 (客户端A)打开一个客户端A，并设置当前事务模式为read uncommitted(读未提交)，查询表account的初始值 1set tx_isolation=&#x27;read-uncommitted&#x27;; (客户端B)在客户端A的事务提交之前，打开另一个客户端B，更新表account: (客户端A)这时，虽然客户端B的事务还没提交，但是客户端A就可以查询到B已经更新的数据 (客户端B)一旦客户端B的事务因为某种原因回滚，所有的操作都将会被撤销，那客户端A查询到的数据其实就是脏数据 (客户端A)此时在客户端A查询，会发现实际值已经改变。 但是，实际java程序中，此时我们拿到的值并不会实时更新，拿到的值还是回滚之前的值，这是就产生了脏数据。 但是我们继续在A客户端执行如下语句 12update account set balance = balance - 50 where id =1;SELECT * from account; 数据没有变成350是因为我们的sql语句是用当前的balance值去操作的，所以操作的是最新的值。 但如果是用java代码去操作，操作之前拿到的值还是400，并不能感知到其他事务的改变，所以操作后可能会变成350 要想解决这个问题可以采用读已提交的隔离级别 读已提交 (客户端A)打开一个客户端A，并设置当前事务模式为read committed(未提交读)，查询表account的所有记录 1set tx_isolation=&#x27;read-committed&#x27;; (客户端B)在客户端A的事务提交之前，打开另一个客户端B，更新表account (客户端A)这时，客户端B的事务还没提交，客户端A不能查询到B已经更新的数据，解决了脏读问题 与读未提交不同，数据还是450 (客户端B)客户端B的事务提交 (客户端A)客户端A执行与上一步相同的查询，结果与上一步不一致，即产生了不可重复读的问题 可重复读 (客户端A)打开一个客户端A，并设置当前事务模式为read committed(未提交读)，查询表account的所有记录 1set tx_isolation=&#x27;repeatable-read&#x27;; (客户端B)在客户端A的事务提交之前，打开另一个客户端B，更新表account并提交 (客户端A)在客户端A查询表account的所有记录，与步骤1查询结果一致，没有出现不可重复读的问题 (客户端A)在客户端A，接着执行如下语句 1update account set balance = balance - 50 where id = 1 balance没有变成 400-50=350，lilei的balance值用的是步骤2中的350来算的，所以是300，数据的一致性倒是没有被破坏。 可重复读的隔离级别下使用了MVCC(multi-version concurrency control)机制 select操作不会更新版本号， 是快照读(历史版本)； insert、update和delete会更新版本号，是当前读(当前版本)。 (客户端B)重新打开客户端B，插入一条新数据后提交 (客户端A)在客户端A查询表account的所有记录，没有查出新增数据，所以没有出现幻读 (客户端A)验证幻读，在客户端A执行如下语句 1update account set balance=888 where id = 4; 能更新成功，再次查询能查到客户端B新增的数据 串行化 (客户端A)打开一个客户端A，并设置当前事务模式为serializable，查询表account的初始值 1set tx_isolation=&#x27;serializable&#x27;; (客户端B)打开一个客户端B，并设置当前事务模式为serializable. 更新相同的id为1的记录会被阻塞等待，更新id 为2的记录可以成功，说明在串行模式下innodb的查询也会被加上行锁。 如果客户端A执行的是一个范围查询，那么该范围内的所有行，包括每行记录所在的间隙区间范围(就算该行数据还未被插入也会加锁，这种是间隙锁)都会被加锁。 此时如果客户端B在该范围内插入数据都会被阻塞，所以就避免了幻读。 这种隔离级别并发性极低，开发中很少会用到。 间隙锁(Gap Lock)间隙锁，锁的就是两个值之间的空隙。Mysql默认级别是repeatable-read，有办法解决幻读问题吗? 间隙锁 在某些情况下可以解决幻读问题。假设account表里数据如下: 那么间隙就有 id 为 (3,10)，(10,20)，(20,正无穷) 这三个区间，在Session_1下面执行 1update account set name = &#x27;zhangsan&#x27; where id &gt; 8 and id &lt;18; 则其他Session没法在这个范围所包含的所有行记录(包括间隙行记录)以及行记录所在的间隙里插入或修改任何数据，即id在 (3,20]区间都无法修改数据，注意最后那个20也是包含在内的。间隙锁是在可重复读隔离级别下才会生效。 临键锁(Next-key Locks)Next-Key Locks是行锁与间隙锁的组合。 像上面那个例子里的这个(3,20]的整个区间可以叫做临键锁。 无索引行锁会升级为表锁锁主要是加在索引上，如果对非索引字段更新，行锁可能会变表锁 session1 执行 1update account set balance = 800 where name = &#x27;lilei&#x27;; session2 对该表任一行操作都会阻塞住。 InnoDB的行锁是针对索引加的锁，不是针对记录加的锁。并且该索引不能失效，否则都会从行锁升级为表锁。 锁定某一行还可以用lock in share mode(共享锁) 和for update(排它锁) 例如 1select * from test_innodb_lock where a = 2 for update; 这样其他session只能读这行数据，修改则会被阻塞，直到锁定行的session提交 结论 Innodb存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更 高一下，但是在整体并发处理能力方面要远远优于MYISAM的表级锁定的。当系统并发量高的时候，Innodb 的整体性能和MYISAM相比就会有比较明显的优势了。 但是，Innodb的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让Innodb的整体性能表现不仅不能比MYISAM高，甚至可能会更差。 行锁分析通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况 1show status like&#x27;innodb_row_lock%&#x27;; 对各个状态量的说明如下: Innodb_row_lock_current_waits: 当前正在等待锁定的数量 Innodb_row_lock_time: 从系统启动到现在锁定总时间长度 Innodb_row_lock_time_avg: 每次等待所花平均时间 Innodb_row_lock_time_max:从系统启动到现在等待最长的一次所花时间 Innodb_row_lock_waits:系统启动后到现在总共等待的次数 对于这5个状态变量，比较重要的主要是: Innodb_row_lock_time_avg (等待平均时长) Innodb_row_lock_waits (等待总次数) Innodb_row_lock_time(等待总时长) 尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化计划。 查看INFORMATION_SCHEMA系统库锁相关数据表123456789101112#查看事务select*fromINFORMATION_SCHEMA.INNODB_TRX;#查看锁select*fromINFORMATION_SCHEMA.INNODB_LOCKS;#查看锁等待select*fromINFORMATION_SCHEMA.INNODB_LOCK_WAITS;#释放锁，trx_mysql_thread_id可以从INNODB_TRX表里查看到kill trx_mysql_thread_id#查看锁等待详细信息show engine innodb status\\G; 死锁123456789101112set tx_isolation=&#x27;repeatable-read&#x27;;#Session_1执行select * from account where id=1 for update;#Session_2执行select * from account where id=2 for update;#Session_1执行select * from account where id=2 for update;#Session_2执行select * from account where id=1 for update;#查看近期死锁日志信息show engine innodb status\\G; 大多数情况mysql可以自动检测死锁并回滚产生死锁的那个事务，但是有些情况mysql没法自动检测死锁 锁优化建议尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁合理设计索引，尽量缩小锁的范围尽可能减少检索条件范围，避免间隙锁尽量，控制事务大小，减少锁定资源量和时间长度，涉及事务加锁的sql尽量放在事务最后执行尽可能低级别事务隔离","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tj-ever.github.io/tags/MySQL/"}]},{"title":"MySQL 索引优化","slug":"MySQL 索引优化","date":"2021-10-02T16:00:00.000Z","updated":"2021-10-04T13:56:19.742Z","comments":true,"path":"2021/10/03/MySQL 索引优化/","link":"","permalink":"https://tj-ever.github.io/2021/10/03/MySQL%20%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96/","excerpt":"","text":"示例表12345678910111213141516171819202122232425262728CREATE TABLE `employees` (`id` int(11) NOT NULL AUTO_INCREMENT,`name` varchar(24) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;,`age` int(11) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;,`position` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;,`hire_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;,PRIMARY KEY (`id`),KEY `idx_name_age_position` (`name`,`age`,`position`) USING BTREE) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8 COMMENT=&#x27;员工记录表&#x27;;INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;LiLei&#x27;,22,&#x27;manager&#x27;,NOW());INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;HanMeimei&#x27;, 23,&#x27;dev&#x27;,NOW());INSERT INTO employees(name,age,position,hire_time) VALUES(&#x27;Lucy&#x27;,23,&#x27;dev&#x27;,NOW());‐‐ 插入一些示例数据drop procedure if exists insert_emp;delimiter ;;create procedure insert_emp()begindeclare i int;set i=1;while(i&lt;=100000)doinsert into employees(name,age,position) values(CONCAT(&#x27;zhuge&#x27;,i),i,&#x27;dev&#x27;);set i=i+1;end while;end;;delimiter ;call insert_emp(); 例子 联合索引第一个字段用范围不会走索引 结论:联合索引第一个字段就用范围查找不会走索引，mysql内部可能觉得第一个字段就用范围，结果集应该很大，回表效率不高，还不如就全表扫描 强制走索引 结论:虽然使用了强制走索引让联合索引第一个字段范围查找也走索引，扫描的行rows看上去也少了点，但是最终查找效率不一定比全表扫描高，因为回表效率不高 做个小实验 首先关闭查询缓存 12set global query_cache_size=0;set global query_cache_type=0; 使用mysql自行优化，耗时0.165s 使用强制索引，耗时0.294s 覆盖索引优化 扫描的字段都在覆盖索引上，此时范围查找可能会走索引 in和or在表数据量比较大的情况会走索引，在表记录不多的情况下会选择全表扫描 复制employees到另一张表，只留三条记录，查询类型将会是全表扫描 like KK% 一般情况都会走索引 这里给大家补充一个概念，索引下推(Index Condition Pushdown，ICP) like KK%其实就是用到了索引下推优化 对于辅助的联合索引(name,age,position)，正常情况按照最左前缀原则， 1SELECT * FROM employees WHERE name like &#x27;LiLei%&#x27; AND age = 22 AND position =&#x27;manager&#x27; 这种情况只会走name字段索引，因为根据name字段过滤完，得到的索引行里的age和 position是无序的，无法很好的利用索引。 在MySQL5.6之前的版本，这个查询只能在联合索引里匹配到名字是 ‘LiLei’ 开头的索引，然后拿这些索引对应的主键逐个回表，到主键索引上找出相应的记录，再比对age和position这两个字段的值是否符合。 MySQL 5.6引入了索引下推优化，可以在索引遍历过程中，对索引中包含的所有字段先做判断，过滤掉不符合条件的记录之后再回表，可以有效的减少回表次数。使用了索引下推优化后，上面那个查询在联合索引里匹配到名字是 ‘LiLei’ 开头的索引之后，同时还会在索引里过滤age和position这两个字段，拿着过滤完剩下的索引对应的主键id再回表查整行数据。 索引下推会减少回表次数，对于innodb引擎的表索引下推只能用于二级索引，innodb的主键索引(聚簇索引)树叶子节点上保存的是全行数据，所以这个时候索引下推并不会起到减少查询全行数据的效果。 为什么范围查找Mysql没有用索引下推优化? 估计应该是Mysql认为范围查找过滤的结果集过大，like KK% 在绝大多数情况来看，过滤后的结果集比较小，所以这里Mysql选择给 like KK% 用了索引下推优化，当然这也不是绝对的，有时like KK% 也不一定就会走索引下推。 Mysql索引选择 如果用name索引需要遍历name字段联合索引树，然后还需要根据遍历出来的主键值去主键索引树里再去查出最终数据，成本比全表扫描还高，可以用覆盖索引优化，这样只需要遍历name字段的联合索引树就能拿到所有结果，如下: 但是，下面这个sql却走了索引 对于上面这两种 name&gt;’a’ 和 name&gt;’zzz’ 的执行结果，mysql最终是否选择走索引或者一张表涉及多个索引，mysql最终如何选择索引，我们可以用trace工具来一查究竟。 开启trace工具会影响mysql性能，所以只能临时分析sql使用，用完之后立即关闭 此处略过trace工具使用（我踏🐎觉得面试官也不会） 常见sql深入优化Order by与Group by优化 case1 利用最左前缀法则:中间字段不能断，因此查询用到了name索引，从key_len=74也能看出，age索引列用在排序过程中，因为Extra字段里没有using filesort case2 从explain的执行结果来看:key_len=74，查询使用了name索引，由于用了position进行排序，跳过了 age，出现了Using filesort。 case3 查找只用到索引name，age和position用于排序，无Using filesort。 case4 和Case 3中explain的执行结果一样，但是出现了Using filesort，因为索引的创建顺序为 name,age,position，但是排序的时候age和position颠倒位置了。 case5 与Case 4对比，在Extra中并未出现Using filesort，因为age为常量，在排序中被优化，所以索引未颠倒， 不会出现Using filesort。 case6 虽然排序的字段列与索引顺序一样，且order by默认升序，这里position desc变成了降序，导致与索引的排序方式不同，从而产生Using filesort。 Mysql8以上版本有降序索引可以支持该种查询方式。 case7 对于排序来说，多个相等条件也是范围查询 case8 这种情况可以用覆盖索引优化 优化总结 MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。 order by满足两种情况会使用Using index。 order by语句使用索引最左前列。 使用where子句与order by子句条件列组合满足索引最左前列。 尽量在索引列上完成排序，遵循索引建立(索引创建的顺序)时的最左前缀法则。 如果order by的条件不在索引列上，就会产生Using filesort。 能用覆盖索引尽量用覆盖索引 group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最左前缀法则。对于group by的优化如果不需要排序的可以加上order by null禁止排序。注意，where高于having，能写在where中的限定条件就不要去having限定了。 Using filesort文件排序filesort文件排序方式 单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序；用trace工具可以看到sort_mode信息里显示 &lt; sort_key, additional_fields &gt;或者&lt; sort_key, packed_additional_fields &gt; 双路排序(又叫回表排序模式)：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行 ID，然后在 sort buffer 中进行排序，排序完后需要再次取回其它需要的字段;用trace工具 可以看到sort_mode信息里显示&lt; sort_key, rowid &gt; MySQL 通过比较系统变量 max_length_for_sort_data(默认1024字节) 的大小和需要查询的字段总大小来判断使用哪种排序模式。 如果字段的总长度小于max_length_for_sort_data ，那么使用 单路排序模式; 如果字段的总长度大于max_length_for_sort_data ，那么使用双路排序模式。 单路排序过程 从索引name找到第一个满足 name = ‘LiLei’ 条件的主键 id 根据主键 id 取出整行，取出所有字段的值，存入 sort_buffer 中 从索引name找到下一个满足 name = ‘LiLei’ 条件的主键 id 重复步骤 2、3 直到不满足 name = ‘LiLei’ 对 sort_buffer 中的数据按照字段 position 进行排序 返回结果给客户端 双路排序过程: 从索引 name 找到第一个满足 name = ‘LiLei’ 的主键id 根据主键 id 取出整行，把排序字段 position 和主键 id 这两个字段放到 sort buffer 中 从索引 name 取下一个满足 name = ‘LiLei’ 记录的主键 id 重复 3、4 直到不满足 name = ‘LiLei’ 对 sort_buffer 中的字段 position 和主键 id 按照字段 position 进行排序 遍历排序好的 id 和字段 position，按照 id 的值回到原表中取出所有字段的值返回给客户端 其实对比两个排序模式，单路排序会把所有需要查询的字段都放到 sort buffer 中，而双路排序只会把主键和需要排序的字段放到 sort buffer 中进行排序，然后再通过主键回到原表查询需要的字段。 如果 MySQL 排序内存 sort_buffer 配置的比较小并且没有条件继续增加了，可以适当把 max_length_for_sort_data 配置小点，让优化器选择使用双路排序算法，可以在sort_buffer 中一次排序更多的行，只是需要再根据主键回到原表取数据。 如果 MySQL 排序内存有条件可以配置比较大，可以适当增大 max_length_for_sort_data 的值，让优化器优先选择全字段排序(单路排序)，把需要的字段放到 sort_buffer 中，这样排序后就会直接从内存里返回查询结果了。 所以，MySQL通过 max_length_for_sort_data 这个参数来控制排序，在不同场景使用不同的排序模式， 从而提升排序效率。 注意，如果全部使用sort_buffer内存排序一般情况下效率会高于磁盘文件排序，但不能因为这个就随便增大sort_buffer(默认1M)，mysql很多参数设置都是做过优化的，不要轻易调整。 索引设计原则 代码先行，索引后上 一般等到主体业务功能开发完毕，把涉及到该表相关sql都要拿出来分析之后再建立索引。 联合索引尽量覆盖条件 比如可以设计一个或者两三个联合索引(尽量少建单值索引)，让每一个联合索引都尽量去包含sql语句里的 where、order by、group by的字段，还要确保这些联合索引的字段顺序尽量满足sql查询的最左前缀原则 不要在小基数字段上建立索引 索引基数是指这个字段在表里总共有多少个不同的值，比如一张表总共100万行记录，其中有个性别字段， 其值不是男就是女，那么该字段的基数就是2。 如果对这种小基数字段建立索引的话，还不如全表扫描了，因为你的索引树里就包含男和女两种值，根本没法进行快速的二分查找，那用索引就没有太大的意义了。 一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，那么才能发挥出B+树快速二分查找的优势来 长字符串我们可以采用前缀索引 尽量对字段类型较小的列设计索引，比如说什么tinyint之类的，因为字段类型较小的话，占用磁盘空间也会比较小，此时你在搜索的时候性能也会比较好一点。 当然，这个所谓的字段类型小一点的列，也不是绝对的，很多时候你就是要针对varchar(255)这种字段建立索引，哪怕多占用一些磁盘空间也是有必要的。 对于这种varchar(255)的大字段可能会比较占用磁盘空间，可以稍微优化下，比如针对这个字段的前20个字符建立索引，类似于 KEY index(name(20),age,position) 此时你在where条件里搜索的时候，如果是根据name字段来搜索，那么此时就会先到索引树里根据name 字段的前20个字符去搜索，定位到之后前20个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的name字段值进行比对。但是假如你要是order by name，那么此时你的name因为在索引树里仅仅包含了前20个字符，所以这个排序是没法用上索引的， group by也是同理。所以这里大家要对前缀索引有一个了解。 where与order by冲突时优先where 一般这种时候往往都是让where条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序。 因为大多数情况基于索引进行where筛选往往可以最快速度筛选出你要的少部分数据，然后做排序的成本可能会小很多。 基于慢sql查询做优化 可以根据监控后台的一些慢sql，针对这些慢sql查询做特定的索引优化。 关于慢sql查询不清楚的可以参考这篇文章:https://blog.csdn.net/qq_40884473/article/details/89455740 索引设计实战以社交场景APP来举例，我们一般会去搜索一些好友，这里面就涉及到对用户信息的筛选，这里肯定就是对用户user表搜索了. 这个表一般来说数据量会比较大，我们先不考虑分库分表的情况，比如，我们一般会筛选地区(省市)，性别，年龄，身高，爱好之类的，有的APP可能用户还有评分，比如用户的受欢迎程度评分，我们可能还会根据评分来排序等等。 对于后台程序来说除了过滤用户的各种条件，还需要分页之类的处理，可能会生成类似sql语句执行: 1select xx from user where xx=xx and xx=xx order by xx limit xx,xx 对于这种情况如何合理设计索引了，比如用户可能经常会根据省市优先筛选同城的用户，还有根据性别去筛选，那我们是否应该设计一个联合索引 (province,city,sex) 。这些字段好像基数都不大，其实是应该的， 因为这些字段查询太频繁了。 假设又有用户根据年龄范围去筛选了，比如 1where province=xx and city=xx and age&gt;=xx and age&lt;=xx 我们尝试着把age字段加入联合索引 (province,city,sex,age)，注意，一般这种范围查找的条件都要放在最后，之前讲过联合索引范围之后条件的是不能用索引的，但是对于当前这种情况依然用不到age 这个索引字段，因为用户没有筛选sex字段，那怎么优化了? 其实我们可以这么来优化下sql的写法 1where province=xx and city=xx and sex in (&#x27;female&#x27;,&#x27;male&#x27;) and age&gt;=xx and age&lt;=xx 对于爱好之类的字段也可以类似sex字段处理，所以可以把爱好字段也加入索引 (province,city,sex,hobby,age) 假设可能还有一个筛选条件，比如要筛选最近一周登录过的用户，一般大家肯定希望跟活跃用户交友了，这样能尽快收到反馈，对应后台sql可能是这样: 1where province=xx and city=xx and sex in (&#x27;female&#x27;,&#x27;male&#x27;) and age&gt;=xx and age&lt;=xx and latest_login_time&gt;= xx 那我们是否能把 latest_login_time 字段也加入索引了?比如 (province,city,sex,hobby,age,latest_login_time) ，显然是不行的，那怎么来优化这种情况了? 其实我们可以试着再设计一个字段is_login_in_latest_7_days，用户如果一周内有登录值就为1，否则为0，那么我们就可以把索引设计成 (province,city,sex,hobby,is_login_in_latest_7_days,age) 来满足上面那种场景了 一般来说，通过这么一个多字段的索引是能够过滤掉绝大部分数据的，就保留小部分数据下来基于磁盘文件进行order by语句的排序，最后基于limit进行分页，那么一般性能还是比较高的。 不过有时可能用户会这么来查询，就查下受欢迎度较高的女性，比如 1where sex = &#x27;female&#x27; order by score limit xx,xx 那么上面那个索引是很难用上的，不能把太多的字段以及太多的值都用 in 语句拼接 到sql里的，那怎么办了? 其实我们可以再设计一个辅助的联合索引，比如 (sex,score)，这样就能满足查询要求了。 以上就是一些索引设计的思路，核心思想就是，尽量利用一两个复杂的多字段联合索引，抗下80%以上的查询，然后用一两个辅助索引尽量抗下剩余的一些非典型查询，保证这种大数据量表的查询尽 可能多的都能充分利用索引，这样就能保证查询速度和性能. 分页查询优化很多时候我们业务系统实现分页功能可能会用如下sql实现 1select * from employees limit 10000,10; 表示从表 employees 中取出从 10001 行开始的 10 行记录。看似只查询了 10 条记录，实际这条 SQL 是先读取 10010 条记录，然后抛弃前 10000 条记录，然后读到后面 10 条想要的数据。因此要查询一张大表比较靠后的数据，执行效率是非常低的。 根据自增且连续的主键排序的分页查询 该 SQL 表示查询从第 90001开始的五行数据，没添加单独 order by，表示通过主键排序。我们再看表 employees ，因 为主键是自增 并且连续的，所以可以改写成按照主键去查询从第 90001开始的五行数据，如下: 显然改写后的 SQL 走了索引，而且扫描的行数大大减少，执行效率更高。 但是，这条改写的SQL 在很多场景并不实用，因为表中可能某些记录被删后，主键空缺，导致结果不一致 这种改写得满 足以下两个条件: 主键自增且连续 结果是按照主键排序的 根据非主键字段排序的分页查询 发现并没有使用 name 字段的索引(key 字段对应的值为 null)， 具体原因：扫描整个索引并查找到没索引的行(可能要遍历多个索引树)的成本比扫描全表的成本更高，所以优化器放弃使用索引。 优化：让排序时返回的字段尽可能少，所以可以让排序和分页操作先查出主键，然后根据主键查到对应的记录， SQL 改写如下 1select * from employees e inner join (select id from employees order by name limit 90000,5) ed on e.id = ed.id; 原 SQL 使用的是 filesort 排序，而优化后的 SQL 使用的是索引排序。 Join关联查询优化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 示例表:CREATE TABLE `t1` ( `id` INT ( 11 ) NOT NULL AUTO_INCREMENT, `a` INT ( 11 ) DEFAULT NULL, `b` INT ( 11 ) DEFAULT NULL, PRIMARY KEY ( `id` ), KEY `idx_a` ( `a` ) ) ENGINE = INNODB DEFAULT CHARSET = utf8;CREATE TABLE t2 LIKE t1;# 往t1表插入1万行记录DROP PROCEDUREIF EXISTS insert_t1; delimiter;;CREATE PROCEDURE insert_t1 () BEGIN DECLARE i INT; SET i = 1; WHILE ( i &lt;= 10000 ) DO INSERT INTO t1 ( a, b ) VALUES ( i, i ); SET i = i + 1; END WHILE;END;;delimiter;CALL insert_t1 ();# 往 t2表插入 100行记录DROP PROCEDUREIF EXISTS insert_t2;delimiter;;CREATE PROCEDURE insert_t2 () BEGIN DECLARE i INT; SET i = 1; WHILE ( i &lt;= 100 ) DO INSERT INTO t2 ( a, b ) VALUES ( i, i ); SET i = i + 1; END WHILE;END;;delimiter;CALL insert_t2 (); mysql的表关联常见有两种算法 Nested-Loop Join 算法 Block Nested-Loop Join 算法 嵌套循环连接 Nested-Loop Join(NLJ)一次一行循环地从第一张表(称为驱动表)中读取行，在这行数据中取到关联字段，根据关联字段在另一张表(被驱动表)里取出满足条件的行，然后取出两张表的结果合集。 从执行计划中可以看到这些信息: 驱动表是 t2，被驱动表是 t1。先执行的就是驱动表(执行计划结果的id如果一样则按从上到下顺序执行sql);优化器一般会优先选择小表做驱动表。所以使用 inner join 时，排在前面的表并不一定就是驱动表。 当使用left join时，左表是驱动表，右表是被驱动表，当使用right join时，右表时驱动表，左表是被驱动表， 当使用join时，mysql会选择数据量比较小的表作为驱动表，大表作为被驱动表。 使用了 NLJ算法。一般 join 语句中，如果执行计划 Extra 中未出现 Using join buffer 则表示使用的 join 算法是 NLJ。 上面sql的大致流程如下: 从表 t2 中读取一行数据(如果t2表有查询过滤条件的，会从过滤结果里取出一行数据); 从第 1 步的数据中，取出关联字段 a，到表 t1 中查找; 取出表 t1 中满足条件的行，跟 t2 中获取到的结果合并，作为结果返回给客户端; 重复上面 3 步。 整个过程会读取 t2 表的所有数据(扫描100行)，然后遍历这每行数据中字段 a 的值，根据 t2 表中 a 的值索引扫描 t1 表 中的对应行(扫描100次 t1 表的索引，1次扫描可以认为最终只扫描 t1 表一行完整数据，也就是总共 t1 表也扫描了100 行)。因此整个过程扫描了 200 行。 如果被驱动表的关联字段没索引，使用NLJ算法性能会比较低，mysql会选择Block Nested-Loop Join 算法。 基于块的嵌套循环连接 Block Nested-Loop Join(BNL)把驱动表的数据读入到 join_buffer 中，然后扫描被驱动表，把被驱动表每一行取出来跟 join_buffer 中的数据做对比。 Extra 中 的Using join buffer (Block Nested Loop)说明该关联查询使用的是 BNL 算法。 上面sql的大致流程如下: 把 t2 的所有数据放入到 join_buffer 中 把表 t1 中每一行取出来，跟 join_buffer 中的数据做对比 返回满足 join 条件的数据 整个过程对表 t1 和 t2 都做了一次全表扫描，因此扫描的总行数为10000(表 t1 的数据总量) + 100(表 t2 的数据总量) = 10100。并且 join_buffer 里的数据是无序的，因此对表 t1 中的每一行，都要做 100 次判断，所以内存中的判断次数是 100 * 10000= 100 万次。这个例子里表 t2 才 100 行，要是表 t2 是一个大表，join_buffer 放不下怎么办呢? join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t2 的所有数据话，策略很简单， 就是分段放。比如 t2 表有1000行记录， join_buffer 一次只能放800行数据，那么执行过程就是先往 join_buffer 里放800行记录，然 后从 t1 表里取数据跟 join_buffer 中数据对比得到部分结果，然后清空 join_buffer ，再放入 t2 表剩余200行记录，再从 t1 表里取数据跟 join_buffer 中数据对比。所以就多扫了一次 t1 表。 被驱动表的关联字段没索引为什么要选择使用 BNL 算法而不使用 Nested-Loop Join 呢?如果上面第二条sql使用 Nested-Loop Join，那么扫描行数为 100 * 10000 = 100万次，这个是磁盘扫描。 很显然，用BNL磁盘扫描次数少很多，相比于磁盘扫描，BNL的内存计算会快得多。 因此MySQL对于被驱动表的关联字段没索引的关联查询，一般都会使用 BNL 算法。如果有索引一般选择 NLJ 算法，有 索引的情况下 NLJ 算法比 BNL算法性能更高 关联sql优化 关联字段加索引，让mysql做join操作时尽量选择NLJ算法 小表驱动大表，写多表连接sql时如果明确知道哪张表是小表可以用straight_join写法固定连接驱动方式，省去mysql优化器自己判断的时间 straight_join功能同join类似，但能让左边的表来驱动右边的表，能改表优化器对于联表查询的执行顺序。比如:select * from t2 straight_join t1 on t2.a = t1.a; 代表指定mysql选 t2 表作为驱动表。 straight_join只适用于inner join，并不适用于left join，right join。(因为left join，right join已经代表指 定了表的执行顺序) 尽可能让优化器去判断，因为大部分情况下mysql优化器是比人要聪明的。使用straight_join一定要慎重，因为部分情况下人为指定的执行顺序并不一定会比优化引擎要靠谱。 对于小表定义的明确在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。 in和exsits优化原则:小表驱动大表，即小的数据集驱动大的数据集 in当B表的数据集小于A表的数据集时，in优于exists 123456select * from A where id in (select id from B)#等价于:for (select id from B)&#123; select * from A where A.id = B.id&#125; exists当A表的数据集小于B表的数据集时，exists优于in 将主查询A的数据，放到子查询B中做条件验证，根据验证结果(true或false)来决定主查询的数据是否保留 12345678select * from A where exists (select 1 from B where B.id = A.id) #等价于:for(select * from A)&#123; select * from B where B.id = A.id&#125;#A表与B表的ID字段应建立索引 EXISTS (subquery)只返回TRUE或FALSE,因此子查询中的SELECT * 也可以用SELECT 1替换,官方说法是实际执行时会忽略SELECT清单,因此没有区别 EXISTS子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比 EXISTS子查询往往也可以用JOIN来代替，何种最优需要具体问题具体分析 count(*)查询优化12345678‐‐ 临时关闭mysql查询缓存，为了查看sql多次执行的真实时间set global query_cache_size=0;set global query_cache_type=0;EXPLAIN select count(1) from employees;EXPLAIN select count(id) from employees;EXPLAIN select count(name) from employees;EXPLAIN select count(*) from employees; 注意:以上4条sql只有根据某个字段count不会统计字段为null值的数据行 四个sql的执行计划一样，说明这四个sql执行效率应该差不多 字段有索引 count(*)≈count(1 ) &gt; count(字段) &gt; count(主键 id) 字段有索引，count(字段)统计走二级索引，二级索引存储数据比主键索引少，所以count(字段)&gt;count(主键 id) 字段无索引 count(*)≈count(1) &gt; count(主键 id) &gt; count(字段) 字段没有索引count(字段)统计走不了索引， count(主键 id)还可以走主键索引，所以count(主键 id) &gt; count(字段) count(1)跟count(字段)执行过程类似，不过count(1)不需要取出字段统计，就用常量1做统计，count(字段)还需要取出字段，所以理论上count(1)比count(字段)会快一点。 count() 是例外，mysql并不会把全部字段取出来，而是专门做了优化，不取值，按行累加，效率很高，所以不需要用 count(列名)或count(常量)来替代 count()。 为什么对于count(id)，mysql最终选择辅助索引而不是主键聚集索引?因为二级索引相对主键索引存储数据更少，检索性能应该更高，mysql内部做了点优化(应该是在5.7版本才优化)。","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tj-ever.github.io/tags/MySQL/"}]},{"title":"MySQL 内部结构 BinLog","slug":"MySQL 内部结构 BinLog","date":"2021-09-28T16:00:00.000Z","updated":"2021-10-03T12:15:10.173Z","comments":true,"path":"2021/09/29/MySQL 内部结构 BinLog/","link":"","permalink":"https://tj-ever.github.io/2021/09/29/MySQL%20%E5%86%85%E9%83%A8%E7%BB%93%E6%9E%84%20BinLog/","excerpt":"","text":"MySQL的内部组件结构 MySQL 可以分为 Server 层和存储引擎层两部分。 Server层主要包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数 (如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 Store层存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。也就是说如果我们在create table时不指定表的存储引擎类型,默认会给你设置存储引擎为InnoDB。 示例库12345CREATE TABLE `test` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8; 连接器MySQL是开源的，有非常多种类的客户端:navicat,mysql front,jdbc,SQLyog等。这些客户端要向mysql发起通信都必须先跟Server端建立通信连接，而建立连接的工作就是有连接器完成的。 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。 连接命令一般是这么写的: 1[root@192 ~]# mysql ‐h host[数据库地址] ‐u root[用户] ‐p root[密码] ‐P 3306 连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份， 这个时候用的就是你输入的用户名和密码。 1、如果用户名或密码不对，你就会收到一个”Access denied for user”的错误，然后客户端程序结束执行。 2、如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。 这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。用户的权限表在系统表空间的mysql的user表中。 修改user密码 12345678910//创建新用户CREATE USER &#x27;username&#x27;@&#x27;host&#x27; IDENTIFIED BY &#x27;password&#x27;;//赋权限,%表示所有hostgrant all privileges on *.* to &#x27;username&#x27;@&#x27;%&#x27;; //刷新数据库flush privileges //设置用户名密码update user set password=password(”123456′′) where user=’root’;//查看当前用户的权限show grants for root@&quot;%&quot;; 连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。 文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。 客户端如果长时间不发送command到Server端，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。 查看wait_timeout 12show global variables like &quot;wait_timeout&quot;;set global wait_timeout=28800; 设置全局服务器关闭非交互连接之前等待活动的秒数 如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒: Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。 数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。 开发当中我们大多数时候用的都是长连接,把连接放在Pool内进行管理，但是长连接有些时候会导致 MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉(OOM)，从现象看就是 MySQL 异常重启了。 怎么解决这类问题呢? 1、定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。 2、如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。 查询缓存常用的一些操作 1234show databases; 显示所有数据库use dbname; 打开数据库:show tables; 显示数据库mysql中所有的表;describe user; 显示表mysql数据库中user表的列信息); 连接建立完成后，就可以执行 select 语句了。 执行逻辑就会来到第二步:查询缓存。 MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。 如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。 大多数情况查询缓存就是个鸡肋，为什么呢? 查询缓存往往弊大于利。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。 一般建议在静态表(极少更新的表)里使用查询缓存 比如一个系统配置表、字典表，那这张表上的查询才适合使用查询缓存。好在 MySQL 也提供了这种“按需使用”的方式。你可以将my.cnf参数 query_cache_type 设置成 DEMAND。 123my.cnf#query_cache_type有3个值 0代表关闭查询缓存OFF，1代表开启ON，2(DEMAND)代表当sql语句中有SQL_CACHE关键词时才缓存query_cache_type=2 这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定 1select SQL_CACHE * from test where ID=5; 查看当前mysql实例是否开启缓存机制 1show global variables like &quot;%query_cache_type%&quot;; 监控查询缓存的命中率 1show status like&#x27;%Qcache%&#x27;; Qcache_free_blocks:表示查询缓存中目前还有多少剩余的blocks，如果该值显示较大，则说明查询缓存中的内存碎片 过多了，可能在一定的时间进行整理。 Qcache_free_memory:查询缓存的内存大小，通过这个参数可以很清晰的知道当前系统的查询内存是否够用，是多 了，还是不够用，DBA可以根据实际情况做出调整。 Qcache_hits:表示有多少次命中缓存。我们主要可以通过该值来验证我们的查询缓存的效果。数字越大，缓存效果越理想。 Qcache_inserts: 表示多少次未命中然后插入，意思是新来的SQL请求在缓存中未找到，不得不执行查询处理，执行查询处理后把结果insert到查询缓存中。这样的情况的次数，次数越多，表示查询缓存应用到的比较少，效果也就不理 想。当然系统刚启动后，查询缓存是空的，这很正常。 Qcache_lowmem_prunes:该参数记录有多少条查询因为内存不足而被移除出查询缓存。通过这个值，用户可以适当的调整缓存大小。 Qcache_not_cached: 表示因为query_cache_type的设置而没有被缓存的查询数量。 Qcache_queries_in_cache:当前缓存中缓存的查询数量。 Qcache_total_blocks:当前缓存的block数量。 mysql8.0已经移除了查询缓存功能 分析器如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。 分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是 什么，代表什么。MySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符 串“ID”识别成“列 ID”。 做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。 如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 from 写成了 “rom”。 词法分析器原理词法分析器分成6个主要步骤完成对sql语句的分析 1、词法分析 2、语法分析 3、语义分析 4、构造执行树 5、生成执行计划 6、计划的执行 下图是SQL词法分析的过程步骤: SQL语句的分析分为词法分析与语法分析，mysql的词法分析由MySQLLex[MySQL自己实现的]完成，语法分析由Bison生成。 关于语法树大家如果想要深入研究可以参考这篇wiki文章:https://en.wikipedia.org/wiki/LR_parser。 那么除了Bison 外，Java当中也有开源的词法结构分析工具例如Antlr4，ANTLR从语法生成一个解析器，可以构建和遍历解析树，可以在IDEA 工具当中安装插件:antlr v4 grammar plugin。 经过bison语法分析之后，会生成一个这样的语法树 至此分析器的工作任务也基本圆满了。 优化器经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。 优化器是在表里面有多个索引的时候，决定使用哪个索引;或者在一个语句有多表关联(join)的时候，决定各个表的连接 顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join: 1select * from test1 join test2 using(ID) where test1.name=yangguo and test2.name=xiaolongnv; 既可以先从表 test1 里面取出 name=yangguo的记录的 ID 值，再根据 ID 值关联到表 test2，再判断 test2 里面 name的 值是否等于 yangguo。 也可以先从表 test2 里面取出 name=xiaolongnv 的记录的 ID 值，再根据 ID 值关联到 test1，再判断 test1 里面 name 的值是否等于 yangguo。 这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。 执行器开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在 工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权 限)。 1select * from test where id=1; 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。 比如我们这个例子中的表 test 中，ID 字段没有索引，那么执行器的执行流程是这样的: 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 1，如果不是则跳过，如果是则将这行存在结果集中; 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。 至此，这个语句就执行完成了。对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加 的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。 bin-log归档SQL执行时，会将sql语句的执行逻辑记录在我们的bin-log当中。 binlog是Server层实现的二进制日志,他会记录我们的cud操作。Binlog有以下几个特点: Binlog在MySQL的Server层实现(引擎共用) Binlog为逻辑日志,记录的是一条语句的原始逻辑 Binlog不限大小,追加写入,不会覆盖以前的日志 如果，我们误删了数据库,可以使用binlog进行归档!要使用binlog归档，首先我们得记录binlog，因此需要先开启MySQL的 binlog功能。 配置my.cnf 1234567891011#配置开启binloglog‐bin=/usr/local/mysql/data/binlog/mysql‐bin#注意5.7以及更高版本需要配置本项，(自定义,保证唯一性);server‐id=123454#binlog格式，有3种statement,row,mixedbinlog‐format=ROW#表示每1次执行写入就与硬盘同步，会影响性能，为0时表示，事务提交时mysql不做刷盘操作，由系统决定sync‐binlog=1 binlog命令 12345678# 查看bin‐log是否开启 show variables like &#x27;%log_bin%&#x27;;# 会多一个最新的bin‐log日志flush logs; # 查看最后一个bin‐log日志的相关信息show master status; # 清空所有的bin‐log日志reset master; 查看binlog内容 12# 查看binlog内容/usr/local/mysql/bin/mysqlbinlog ‐‐no‐defaults /usr/local/mysql/data/binlog/mysql‐bin.000001 binlog里的内容不具备可读性，所以需要我们自己去判断恢复的逻辑点位. 看重点信息，比如begin,commit这种 关键词信息，只要在binlog当中看到了，你就可以理解为begin-commit之间的信息是一个完整的事务逻辑，然后再根据位置 position判断恢复即可。 binlog内容如下: 数据归档操作 1234567891011# 从bin‐log恢复数据# 恢复全部数据/usr/local/mysql/bin/mysqlbinlog ‐‐no‐defaults /usr/local/mysql/data/binlog/mysql‐bin.000001 |mysql ‐uroot ‐p password (数据库名)# 恢复指定位置数据/usr/local/mysql/bin/mysqlbinlog ‐‐no‐defaults ‐‐start‐position=&quot;408&quot; ‐‐stop‐position=&quot;731&quot;/usr/local/mysql/data/binlog/mysql‐bin.000001 |mysql ‐uroot ‐p password(数据库)# 恢复指定时间段数据/usr/local/mysql/bin/mysqlbinlog ‐‐no‐defaults /usr/local/mysql/data/binlog/mysql‐bin.000001 ‐‐stop‐date= &quot;2018‐03‐02 12:00:00&quot; ‐‐start‐date= &quot;2019‐03‐02 11:55:00&quot;|mysql ‐uroot ‐p test(数据库) 归档测试准备 定义一个存储过程，写入数据 1234567891011121314drop procedure if exists tproc;delimiter $$create procedure tproc(i int)begin declare s int default 1; declare c char(50) default repeat(&#x27;a&#x27;,50); while s&lt;=i do start transaction; insert into test values(null,c); commit; set s=s+1; end while; end$$ delimiter ; 删除数据 1truncate test; 利用binlog归档 1/usr/local/mysql/bin/mysqlbinlog ‐‐no‐defaults /usr/local/mysql/data/binlog/mysql‐bin.000001 |mysql ‐uroot ‐p password(数据库名)","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tj-ever.github.io/tags/MySQL/"}]},{"title":"MySQL 索引和Explain执行计划","slug":"MySQL 索引及Explain","date":"2021-09-22T16:00:00.000Z","updated":"2021-10-04T14:01:09.971Z","comments":true,"path":"2021/09/23/MySQL 索引及Explain/","link":"","permalink":"https://tj-ever.github.io/2021/09/23/MySQL%20%E7%B4%A2%E5%BC%95%E5%8F%8AExplain/","excerpt":"","text":"索引索引是帮助MySQL高效获取数据的排好序的数据结构 索引数据结构 二叉树 红黑树 Hash表 B-Tree B-Tree 叶节点具有相同的深度，叶节点的指针为空 所有索引元素不重复 节点中的数据索引从左到右递增排列 B+Tree(B-Tree变种)非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引 叶子节点包含所有索引字段 叶子节点用指针连接，提高区间访问的性能 Hash对索引的key进行一次hash计算就可以定位出数据存储的位置 很多时候Hash索引要比B+ 树索引更高效 仅能满足 “=”，“IN”，不支持范围查询 hash冲突问题 MyISAM索引MyISAM索引文件和数据文件是分离的(非聚集) InnoDB索引InnoDB索引实现(聚集) 表数据文件本身就是按B+Tree组织的一个索引结构文件 聚集索引-叶节点包含了完整的数据记录 为什么建议InnoDB表必须建主键，并且推荐使用整型的自增主键？ 为什么非主键索引结构叶子节点存储的是主键值？(一致性和节省存储空间) 联合索引 Explain执行计划使用EXPLAIN关键字可以模拟优化器执行SQL语句，分析你的查询语句或是结构的性能瓶颈 在 select 语句之前增加 explain 关键字，MySQL 会在查询上设置一个标记，执行查询会返回执行计划的信息，而不是执行这条SQL注意:如果 from 中包含子查询，仍会执行该子查询，将结果放入临时表中 分析示例参考官方文档:https://dev.mysql.com/doc/refman/5.7/en/explain-output.html 1234567891011121314151617181920212223242526272829303132333435-- 演员表DROP TABLE IF EXISTS `actor`;CREATE TABLE `actor` ( `id` int(11) NOT NULL, `name` varchar(45) DEFAULT NULL, `update_time` datetime DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8;-- 如果日期插不进去 可以执行 SET SESSION sql_mode = &#x27;ALLOW_INVALID_DATES&#x27;; INSERT INTO `actor` (`id`, `name`, `update_time`) VALUES (1,&#x27;a&#x27;,&#x27;2017‐12‐22 15:27:18&#x27;), (2,&#x27;b&#x27;,&#x27;2017‐12‐22 15:27:18&#x27;), (3,&#x27;c&#x27;,&#x27;2017‐12‐22 15:27:18&#x27;);-- 电影表DROP TABLE IF EXISTS `film`;CREATE TABLE `film` (`id` int(11) NOT NULL AUTO_INCREMENT,`name` varchar(10) DEFAULT NULL,PRIMARY KEY (`id`),KEY `idx_name` (`name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `film` (`id`, `name`) VALUES (1,&#x27;film1&#x27;),(2,&#x27;film2&#x27;),(3,&#x27;film3&#x27;);-- 关联表DROP TABLE IF EXISTS `film_actor`;CREATE TABLE `film_actor` (`id` int(11) NOT NULL,`film_id` int(11) NOT NULL,`actor_id` int(11) NOT NULL,`remark` varchar(255) DEFAULT NULL,PRIMARY KEY (`id`),KEY `idx_film_actor_id` (`film_id`,`actor_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO `film_actor` (`id`, `film_id`, `actor_id`) VALUES (1,1,1),(2,1,2),(3,2,1) actor数据 film数据 film-actor数据 1explain select * from actor; 在查询中的每个表会输出一行，如果有两个表通过 join 连接查询，那么会输出两行 explain 两个变种explain extended会在 explain 的基础上额外提供一些查询优化的信息。紧随其后通过 show warnings 命令可 以得到优化后的查询语句，从而看出优化器优化了什么。额外还有 filtered 列，是一个半分比的值，rows * filtered/100 可以估算出将要和 explain 中前一个表进行连接的行数(前一个表指 explain 中的id值比当前表id值小的表)。 12explain extended select * from film where id = 1;show WARNINGS; explain 结果 show warings 结果 explain partitions相比 explain 多了个 partitions 字段，如果查询是基于分区表的话，会显示查询将访问的分区。 explain中的列id列id列的编号是 select 的序列号，有几个 select 就有几个id，并且id的顺序是按 select 出现的顺序增长的。 id列越大执行优先级越高，id相同则从上往下执行，id为NULL最后执行。 select_type列select_type 表示对应行是简单还是复杂的查询。 simple:简单查询。查询不包含子查询和union primary:复杂查询中最外层的 select subquery:包含在 select 中的子查询(不在 from 子句中) derived:包含在 from 子句中的子查询。MySQL会将结果存放在一个临时表中，也称为派生表(derived的英文含义) union:在 union 中的第二个和随后的 select table列这一列表示 explain 的一行正在访问哪个表。当 from 子句中有子查询时，table列是 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查 询。当有 union 时，UNION RESULT 的 table 列的值为&lt;union1,2&gt;，1和2表示参与 union 的 select 行id。 type列这一列表示关联类型或访问类型，即MySQL决定如何查找表中的行，查找数据行记录的大概范围。 依次从最优到最差分别为:system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL 一般来说，得保证查询达到range级别，最好达到ref NULL mysql能够在优化阶段分解查询语句，在执行阶段用不着再访问表或索引。 例如:在索引列中选取最小值，可 以单独查找索引来完成，不需要在执行时访问表 const, system mysql能对查询的某部分进行优化并将其转化成一个常量(可以看show warnings 的结果)。 用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。 system是 const的特例，表里只有一条元组匹配时为system “ eq_ref primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。 这可能是在 const 之外最好的联接类型了，简单的 select 查询不会出现这种 type。 ref 相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行 简单 select 查询，name是普通索引(非唯一索引) 关联表查询，idx_film_actor_id是film_id和actor_id的联合索引，这里使用到了film_actor的左边前缀film_id部分。 range 范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;= 等操作中。使用一个索引来检索给定范围的行。 index 扫描全索引就能拿到结果，一般是扫描某个二级索引，这种扫描不会从索引树根节点开始快速查找，而是直接对二级索引的叶子节点遍历和扫描，速度还是比较慢的，这种查询一般为使用覆盖索引，二级索引一般比较小，所以这种通常比ALL快一些。 ALL 即全表扫描，扫描你的聚簇索引的所有叶子节点。通常情况下这需要增加索引来进行优化了。 possible_keys列这一列显示查询可能使用哪些索引来查找。explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引 对此查询帮助不大，选择了全表查询。如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。 key列这一列显示mysql实际采用哪个索引来优化对该表的访问。如果没有使用索引，则该列是 NULL。 如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。 key_len列这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 举例来说，film_actor的联合索引 idx_film_actor_id 由 film_id 和 actor_id 两个int列组成，并且每个int是4字节。通过结果中的key_len=4可推断出查询使用了第一个列:film_id列来执行索引查找。 key_len计算规则如下: 字符串 char(n) 和 varchar(n)，5.0.3以后版本中，n均代表字符数，而不是字节数，如果是utf-8，一个数字或字母占1个字节，一个汉字占3个字节 char(n):如果存汉字长度就是 3n 字节 varchar(n):如果存汉字则长度是 3n + 2 字节，加的2字节用来存储字符串长度，因为 varchar是变长字符串 数值类型 tinyint:1字节 smallint:2字节 int:4字节 bigint:8字节 时间类型 date:3字节 timestamp:4字节 datetime:8字节 如果字段允许为 NULL，需要1字节记录是否为 NULL 索引最大长度是768字节，当字符串过长时，mysql会做一个类似左前缀索引的处理，将前半部分的字符提取出来做索引。 ref列这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有:const(常量)，字段名(例:film.id) rows列这一列是mysql估计要读取并检测的行数，注意这个不是结果集里的行数。 extra列这一列展示的是额外信息。常见的重要值如下: Using index:使用覆盖索引 覆盖索引定义:mysql执行计划explain结果里的key有使用索引，如果select后面查询的字段都可以从这个索引的树中获取，这种情况一般可以说是用到了覆盖索引，extra里一般都有using index; 覆盖索引一般针对的是辅助索引，整个查询结果只通过辅助索引就能拿到结果，不需要通过辅助索引树找到主键，再通过主键去主键索引树里获取其它字段值 Using where:使用 where 语句来处理结果，并且查询的列未被索引覆盖 Using index condition:查询的列不完全被索引覆盖，where条件中是一个前导列的范围; Using temporary:mysql需要创建一张临时表来处理查询。出现这种情况一般是要进行优化的，首先是想到用索引来优化。 actor.name没有索引，此时创建了张临时表来distinct film.name建立了idx_name索引，此时查询时extra是using index,没有用临时表 Using filesort:将用外部排序而不是索引排序，数据较小时从内存排序，否则需要在磁盘完成排序。这种情况下一般也是要考虑使用索引来优化的。 actor.name未创建索引，会浏览actor整个表，保存排序关键字name和对应的id，然后排序name并检索行记录 film.name建立了idx_name索引,此时查询时extra是using index Select tables optimized away:使用某些聚合函数(比如 max、min)来访问存在索引的某个字段 索引最佳实践123456789101112131415161718192021222324252627282930CREATE TABLE `employees` ( `id` INT ( 11 ) NOT NULL AUTO_INCREMENT, `name` VARCHAR ( 24 ) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;姓名&#x27;, `age` INT ( 11 ) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;年龄&#x27;, `position` VARCHAR ( 20 ) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;职位&#x27;, `hire_time` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;入职时间&#x27;, PRIMARY KEY ( `id` ), KEY `idx_name_age_position` ( `name`, `age`, `position` ) USING BTREE ) ENGINE = INNODB AUTO_INCREMENT = 4 DEFAULT CHARSET = utf8 COMMENT = &#x27;员工记录表&#x27;;INSERT INTO employees ( NAME, age, position, hire_time )VALUES ( &#x27;LiLei&#x27;, 22, &#x27;manager&#x27;, NOW());INSERT INTO employees ( NAME, age, position, hire_time )VALUES ( &#x27;HanMeimei&#x27;, 23, &#x27;dev&#x27;, NOW());INSERT INTO employees ( NAME, age, position, hire_time )VALUES ( &#x27;Lucy&#x27;, 23, &#x27;dev&#x27;, NOW()); 全值匹配 最左前缀法则如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。 不在索引列上做任何操作计算、函数、(自动or手动)类型转换，会导致索引失效而转向全表扫描 给hire_time增加一个普通索引 转化为日期范围查询，有可能会走索引 还原最初索引状态 存储引擎不能使用索引中范围条件右边的列 尽量使用覆盖索引只访问索引的查询，因为索引列包含查询列，减少 select * 语句 尽量不使用范围查询mysql在使用不等于(!=或者&lt;&gt;)，not in ，not exists 的时候无法使用索引会导致全表扫描； &lt; 小于、 &gt; 大于、 &lt;=、&gt;= 这些，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引 尽量不使用空值判断is null,is not null 一般情况下也无法使用索引 尽量不使用like通配符开头like以通配符开头(‘$abc…’)mysql索引失效会变成全表扫描操作 解决like’%字符串%’索引不被使用a)使用覆盖索引，查询字段必须是建立覆盖索引字段 b)如果不能使用覆盖索引则可能需要借助搜索引擎 字符串不加单引号索引失效 少用or或in用它查询时，mysql不一定使用索引，mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引 范围查询优化给年龄添加单值索引 没走索引原因:mysql内部优化器会根据检索比例、表大小等多个因素整体评估是否使用索引。比如这个例子，可能是由于单次数据量查询过大导致优化器最终选择不走索引 优化方法:可以将大的范围拆分成多个小范围 还原最初索引状态 索引使用总结 **like **查询 KK%相当于常量 %KK和%KK% 相当于范围","categories":[],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://tj-ever.github.io/tags/MySQL/"}]},{"title":"JVM Arthas使用及字符串常量池","slug":"JVM Arthas使用及字符串常量池","date":"2021-09-15T16:00:00.000Z","updated":"2021-09-16T07:45:07.366Z","comments":true,"path":"2021/09/16/JVM Arthas使用及字符串常量池/","link":"","permalink":"https://tj-ever.github.io/2021/09/16/JVM%20Arthas%E4%BD%BF%E7%94%A8%E5%8F%8A%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/","excerpt":"","text":"阿里巴巴ArthasArthas 是 Alibaba 在 2018 年 9 月开源的 Java 诊断工具。支持 JDK6+， 采用命令行交互模式，可以方便的定位和诊断 线上程序运行问题。Arthas 官方文档十分详细，详见:https://alibaba.github.io/arthas/ Arthas使用1234#github下载arthaswge thttps://alibaba.github.io/arthas/arthas‐boot.jar 3 # 或者 Gitee 下载wget https://arthas.gitee.io/arthas‐boot.jar 用java -jar运行即可，可以识别机器上所有Java进程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283public class Arthas&#123; private static HashSet hashSet = new HashSet(); 8 public static void main(String[] args) &#123; //模拟CPU过高 cpuHigh(); // 模拟线程死锁 deadThread(); // 不断的向 hashSet 集合增加数据 addHashSetThread(); &#125; /* * 不断的向 hashSet 集合添加数据 */ public static void addHashSetThread() &#123; // 初始化常量 new Thread(() ‐&gt; &#123; int count = 0; while (true) &#123; try&#123; hashSet.add(&quot;count&quot; + count); Thread.sleep(1000); count++; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125; public static void cpuHigh() &#123; new Thread(() ‐&gt; &#123; while (true) &#123; &#125; &#125;).start(); &#125; /** *死锁 */ private static void deadThread() &#123; /** 创建资源 */ Object resourceA = new Object(); Object resourceB = new Object(); // 创建线程 Thread threadA = new Thread(() ‐&gt; &#123; synchronized (resourceA) &#123; System.out.println(Thread.currentThread() + &quot; get ResourceA&quot;); try&#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;waiting get resourceB&quot;); synchronized (resourceB) &#123; System.out.println(Thread.currentThread() + &quot; get resourceB&quot;); &#125; &#125; &#125;); Thread threadB = new Thread(() ‐&gt; &#123; synchronized (resourceB) &#123; System.out.println(Thread.currentThread() + &quot; get ResourceB&quot;); try&#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread() + &quot;waiting get resourceA&quot;); synchronized (resourceA) &#123; System.out.println(Thread.currentThread() + &quot; get resourceA&quot;); &#125; &#125; &#125;); threadA.start(); threadB.start(); &#125;&#125; 选择进程序号1，进入进程信息操作 dashboard输入dashboard可以查看整个进程的运行情况，线程、内存、GC、运行环境信息: thread输入thread可以查看线程详细情况 输入 thread加上线程ID 可以查看线程堆栈 输入 thread -b 可以查看线程死锁 jad输入 jad加类的全名 可以反编译，这样可以方便我们查看线上代码是否是正确的版本 ognl使用 ognl 命令可以查看线上系统变量的值，甚至可以修改变量的值 更多命令使用可以用help命令查看，或查看文档:https://alibaba.github.io/arthas/commands.html#arthas GC日志详解对于java应用我们可以通过一些配置把程序运行过程中的gc日志全部打印出来，然后分析gc日志得到关键性指标，分析 GC原因，调优JVM参数。打印GC日志方法，在JVM参数里增加参数，%t 代表时间 1‐Xloggc:./gc‐%t.log ‐XX:+PrintGCDetails ‐XX:+PrintGCDateStamps ‐XX:+PrintGCTimeStamps ‐XX:+PrintGCCause ‐XX:+UseGCLogFileRotation ‐XX:NumberOfGCLogFiles=10 ‐XX:GCLogFileSize=100M Tomcat则直接加在JAVA_OPTS变量里。 分析GC日志运行程序加上对应gc日志 1java ‐jar ‐Xloggc:./gc‐%t.log ‐XX:+PrintGCDetails ‐XX:+PrintGCDateStamps ‐XX:+PrintGCTimeStamps ‐XX:+PrintGCCause ‐XX:+UseGCLogFileRotation ‐XX:NumberOfGCLogFiles=10 ‐XX:GCLogFileSize=100M microservice‐eureka‐server.jar 我们可以看到图中第一行红框，是项目的配置参数。这里不仅配置了打印GC日志，还有相关的VM内存参数。 第二行红框中的是在这个GC时间点发生GC之后相关GC情况。 对于2.909: 这是从jvm启动开始计算到这次GC经过的时间，前面还有具体的发生时间日期。 Full GC(Metadata GC Threshold)指这是一次full gc，括号里是gc的原因， PSYoungGen是年轻代的GC， ParOldGen是老年代的GC，Metaspace是元空间的GC 6160K-&gt;0K(141824K)，这三个数字分别对应GC之前占用年轻代的大小，GC之后年轻代占用，以及整个年轻代的大 小。 112K-&gt;6056K(95744K)，这三个数字分别对应GC之前占用老年代的大小，GC之后老年代占用，以及整个老年代的 大小。 6272K-&gt;6056K(237568K)，这三个数字分别对应GC之前占用堆内存的大小，GC之后堆内存占用，以及整个堆内存 的大小。 20516K-&gt;20516K(1069056K)，这三个数字分别对应GC之前占用元空间内存的大小，GC之后元空间内存占用，以及整个元空间内存的大小。 0.0209707是该时间点GC总耗费时间。 从日志可以发现几次fullgc都是由于元空间不够导致的，所以我们可以将元空间调大点 1java ‐jar ‐Xloggc:./gc‐adjust‐%t.log ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M ‐XX:+PrintGCDetails ‐XX:+Print GCDateStamps ‐XX:+PrintGCTimeStamps ‐XX:+PrintGCCause ‐XX:+UseGCLogFileRotation ‐XX:NumberOfGCLogFiles=10 ‐XX:GCLogFileSize=100M microservice‐eureka‐server.jar 调整完我们再看下gc日志发现已经没有因为元空间不够导致的fullgc了 对于CMS和G1收集器的日志会有一点不一样，也可以试着打印下对应的gc日志分析下，可以发现gc日志是类似的： 1234567891011public class HeapTest&#123; byte[] a = new byte[1024 * 100]; //100KB public static void main(String[] args) throws InterruptedException &#123; ArrayList&lt;HeapTest&gt; heapTests = new ArrayList&lt;&gt;(); while (true) &#123; heapTests.add(new HeapTest()); Thread.sleep(10); &#125; &#125; &#125; cms 1‐Xloggc:d:/gc‐cms‐%t.log ‐Xms50M ‐Xmx50M ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M ‐XX:+PrintGCDetails ‐XX:+PrintGCDateStamps ‐XX:+PrintGCTimeStamps ‐XX:+PrintGCCause ‐XX:+UseGCLogFileRotation ‐XX:NumberOfGCLogFiles=10 ‐XX:GCLogFileSize=100M ‐XX:+UseParNewGC ‐XX:+UseConcMarkSweepGC G1 1‐Xloggc:d:/gc‐g1‐%t.log ‐Xms50M ‐Xmx50M ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M ‐XX:+PrintGCDetails ‐XX:+PrintGCDateStamps ‐XX:+PrintGCTimeStamps ‐XX:+PrintGCCause ‐XX:+UseGCLogFileRotation ‐XX:NumberOfGCLogFiles=10 ‐XX:GCLogFileSize=100M ‐XX:+UseG1GC 上面的这些参数，能够帮我们查看分析GC的垃圾收集情况。但是如果GC日志很多很多，成千上万行。就算你一目十行， 看完了，脑子也是一片空白。所以我们可以借助一些功能来帮助我们分析，这里推荐一个gceasy(https://gceasy.io)，可以 上传gc文件，然后他会利用可视化的界面来展现GC情况。 具体下图所示 上图我们可以看到年轻代，老年代，以及永久代的内存分配，和最大使用情况。 上图我们可以看到堆内存在GC之前和之后的变化，以及其他信息。 这个工具还提供基于机器学习的JVM智能优化建议，当然现在这个功能需要付费 JVM参数汇总查看命令12java -XX:+PrintFlagsInitial 表示打印出所有参数选项的默认值java -XX:+PrintFlagsFinal 表示打印出所有参数选项在运行程序时生效的值 Class常量池与运行时常量池Class常量池可以理解为是Class文件中的资源仓库。 Class文件中除了包含类的版本、字段、方法、接口等描述信息外， 还有一项信息就是常量池(constant pool table)，用于存放编译期生成的各种字面量(Literal)和符号引用(Symbolic References)。 一个class文件的16进制大体结构如下图: 对应的含义如下，细节可以查下oracle官方文档 当然我们一般不会去人工解析这种16进制的字节码文件，我们一般可以通过javap命令生成更可读的JVM字节码指令文件: 红框标出的就是class常量池信息，常量池中主要存放两大类常量:字面量和符号引用。 字面量字面量就是指由字母、数字等构成的字符串或者数值常量 字面量只可以右值出现，所谓右值是指等号右边的值，如:int a=1 这里的a为左值，1为右值。在这个例子中1就是字面量。 1234int a=1;int b=2;int c=&quot;abcdefg&quot;; int d=&quot;abcdefg&quot;; 符号引用符号引用是编译原理中的概念，是相对于直接引用来说的。主要包括了以下三类常量: 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 上面的a，b就是字段名称，就是一种符号引用，还有Math类常量池里的 Lcom/tuling/jvm/Math 是类的全限定名， main和compute是方法名称，()是一种UTF8格式的描述符，这些都是符号引用。 这些常量池现在是静态信息，只有到运行时被加载到内存后，这些符号才有对应的内存地址信息，这些常量池一旦被装 入内存就变成运行时常量池，对应的符号引用在程序加载或运行时会被转变为被加载到内存区域的代码的直接引用，也 就是我们说的动态链接了。例如，compute()这个符号引用在运行时就会被转变为compute()方法具体代码在内存中的地址，主要通过对象头里的类型指针去转换直接引用。 字符串常量池字符串常量池的设计思想 字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能 JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化 为字符串开辟一个字符串常量池，类似于缓存区 创建字符串常量时，首先查询字符串常量池是否存在该字符串 存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中 三种字符串操作(Jdk1.7 及以上版本) 直接赋值字符串 1String s = &quot;zhuge&quot;; //s指向常量池中的引用 这种方式创建的字符串对象，只会在常量池中。 因为有”zhuge”这个字面量，创建对象s的时候，JVM会先去常量池中通过 equals(key) 方法，判断是否有相同的对象 如果有，则直接返回该对象在常量池中的引用； 如果没有，则会在常量池中创建一个新对象，再返回引用。 new String(); 1String s1 = new String(&quot;zhuge&quot;); //s1指向内存中的对象引用 这种方式会保证字符串常量池和堆中都有这个对象，没有就创建，最后返回堆内存中的对象引用。 步骤大致如下: 因为有”zhuge”这个字面量，所以会先检查字符串常量池中是否存在字符串”zhuge” 不存在，先在字符串常量池里创建一个字符串对象；再去内存中创建一个字符串对象”zhuge”; 存在的话，就直接去堆内存中创建一个字符串对象”zhuge”;最后，将内存中的引用返回。 intern方法 123String s1 = new String(&quot;zhuge&quot;);String s2 = s1.intern();System.out.println(s1==s2); //false String中的intern方法是一个 native 的方法，当调用 intern方法时，如果池已经包含一个等于此String对象的字符串 (用equals(oject)方法确定)，则返回池中的字符串。否则，将intern返回的引用指向当前字符串 s1(jdk1.6版本需要将 s1 复制到字符串常量池里)。 字符串常量池位置Jdk1.6及之前: 有永久代, 运行时常量池在永久代，运行时常量池包含字符串常量池 Jdk1.7:有永久代，但已经逐步“去永久代”，字符串常量池从永久代里的运行时常量池分离到堆里 Jdk1.8及之后: 无永久代，运行时常量池在元空间，字符串常量池里依然在堆里 用一个程序证明下字符串常量池在哪里: 1234567891011121314151617/*** jdk6:‐Xms6M ‐Xmx6M ‐XX:PermSize=6M ‐XX:MaxPermSize=6M* jdk8:‐Xms6M ‐Xmx6M ‐XX:MetaspaceSize=6M ‐XX:MaxMetaspaceSize=6M*/public class RuntimeConstantPoolOOM&#123; public static void main(String[] args) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); for(inti=0;i&lt;10000000;i++)&#123; String str = String.valueOf(i).intern(); list.add(str); &#125; &#125;&#125;运行结果:jdk7及以上:Exceptioninthread&quot;main&quot;java.lang.OutOfMemoryError:Javaheapspace jdk6:Exceptioninthread&quot;main&quot;java.lang.OutOfMemoryError:PermGenspace 字符串常量池设计原理字符串常量池底层是hotspot的C++实现的，底层类似一个 HashTable， 保存的本质上是字符串对象的引用。 看一道比较常见的面试题，下面的代码创建了多少个 String 对象? 1234567String s1 = new String(&quot;he&quot;) + new String(&quot;llo&quot;);String s2 = s1.intern();System.out.println(s1==s2);// 在 JDK 1.6 下输出是 false，创建了 6 个对象// 在 JDK 1.7 及以上的版本输出是 true，创建了 5 个对象// 当然我们这里没有考虑GC，但这些对象确实存在或存在过 为什么输出会有这些变化呢?主要还是字符串池从永久代中脱离、移入堆区的原因， intern() 方法也相应发生了变 化: 1、在 JDK 1.6 中，调用 intern() 首先会在字符串池中寻找 equal() 相等的字符串，假如字符串存在就返回该字符串在字符串池中的引用;假如字符串不存在，虚拟机会重新在永久代上创建一个实例，将 StringTable 的一个表项指向这个新创建的实例。 2、在 JDK 1.7 (及以上版本)中，由于字符串池不在永久代了，intern() 做了一些修改，更方便地利用堆中的对象。字符串存在时和 JDK 1.6一样，但是字符串不存在时不再需要重新创建实例，可以直接指向堆上的实例。 由上面两个图，也不难理解为什么 JDK 1.6 字符串池溢出会抛出 OutOfMemoryError: PermGen space ，而在 JDK 1.7 及以上版本抛出 OutOfMemoryError: Java heap space 。 String常量池问题的几个例子 示例1: 12345String s0 = &quot;zhuge&quot;;String s1 = &quot;zhuge&quot;;String s2 = &quot;zhu&quot; + &quot;ge&quot;;System.out.println(s0 == s1); //trueSystem.out.println(s0 == s2); //true 分析: 因为例子中的 s0和s1中的”zhuge”都是字符串常量，它们在编译期就被确定了，所以s0==s1为true; 而”zhu”和”ge”也都是字符串常量，当一个字符串由多个字符串常量连接而成时，它自己肯定也是字符串常量，所 以s2也同样在编译期就被优化为一个字符串常量”zhuge”，所以s2也是常量池中” zhuge”的一个引用。所以我们得出 s0==s1==s2; 示例2: 123456String s0 = &quot;zhuge&quot;;String s1 = new String(&quot;zhuge&quot;);String s2 = &quot;zhu&quot;+new String(&quot;ge&quot;);System.out.println( s0==s1 ); // falseSystem.out.println( s0==s2 ); // falseSystem.out.println( s1==s2 ); // false 分析: 用new String() 创建的字符串不是常量，不能在编译期就确定，所以new String() 创建的字符串不放入常量池中，它们有自己的地址空间。s0还是常量池中”zhuge”的引用，s1因为无法在编译期确定，所以是运行时创建的新对象”zhuge”的引用，s2因为有后半部分 new String(”ge”)所以也无法在编译期确定，所以也是一个新创建对象”zhuge”的引用;明白了这些也就知道为何得出此结果了。 示例3: 1234567891011String a = &quot;a1&quot;;String b= &quot;a&quot; + 1;System.out.println(a == b); // trueString a = &quot;atrue&quot;;String b = &quot;a&quot; + &quot;true&quot;;System.out.println(a == b); // trueString a = &quot;a3.4&quot;;String b = &quot;a&quot; + 3.4;System.out.println(a == b); // true 分析:JVM对于字符串常量的”+”号连接，将在程序编译期，JVM就将常量字符串的”+”连接优化为连接后的值，拿”a” + 1来说，经编译器优化后在class中就已经是a1。在编译期其字符串常量的值就确定下来，故上面程序最终的结果都为 true。 示例4: 12345String a =&quot;ab&quot;;String bb =&quot;b&quot;;String b =&quot;a&quot;+bb;System.out.println(a == b);//false 分析:JVM对于字符串引用，由于在字符串的”+”连接中，有字符串引用存在，而引用的值在程序编译期是无法确定的， 即”a” + bb无法被编译器优化，只有在程序运行期来动态分配并将连接后的新地址赋给b。所以上面程序的结果也就为 false。 示例5: 12345String a =&quot;ab&quot;;final String bb=&quot;b&quot;;String b = &quot;a&quot;+bb;System.out.println(a==b);//true 分析:和示例4中唯一不同的是bb字符串加了final修饰，对于final修饰的变量，它在编译时被解析为常量值的一个本地拷贝存储到自己的常量池中或嵌入到它的字节码流中。所以此时的”a” + bb和”a” + “b”效果是一样的。故上面程序的结果为true。 示例6: 12345678String a = &quot;ab&quot;;final String bb = getBB();String b = &quot;a&quot; + bb;System.out.println(a==b);//false private static String getBB()&#123; return &quot;b&quot;;&#125; 分析:JVM对于字符串引用bb，它的值在编译期无法确定，只有在程序运行期调用方法后，将方法的返回值和”a”来动态 连接并分配地址为b，故上面程序的结果为false。 String是不可变的通过上面例子可以得出得知: 12345String s = &quot;a&quot; + &quot;b&quot; + &quot;c&quot;; //就等价于String s = &quot;abc&quot;; String a = &quot;a&quot;;String b = &quot;b&quot;;String c = &quot;c&quot;;String s1 = a+b+c; s1 这个就不一样了，可以通过观察其JVM指令码发现s1的”+”操作会变成如下操作: 123StringBuilder temp = new StringBuilder();temp.append(a).append(b).append(c);String s = temp.toString(); 一个例子: 12345678910111213141516171819202122//字符串常量池:&quot;计算机&quot;和&quot;技术&quot; 堆内存 :str1引用的对象&quot;计算机技术&quot;//堆内存中还有个StringBuilder的对象，但是会被gc回收，StringBuilder的toString方法会newString()，这个String才是真正返回的对象引用String str2 = new StringBuilder(&quot;计算机&quot;).append(&quot;技术&quot;).toString();//没有出现&quot;计算机技术&quot;字面量，所以不会在常量池里生成&quot;计算机技术&quot;对象System.out.println(str2==str2.intern());//true//&quot;计算机技术&quot; 在池中没有，但是在heap中存在，则intern时，会直接返回该heap中的引用//字符串常量池:&quot;ja&quot;和&quot;va&quot; 堆内存:str1引用的对象&quot;java&quot;//堆内存中还有个StringBuilder的对象，但是会被gc回收，StringBuilder的toString方法会newString()，这个String才是真正返回的对象引用String str1 = new StringBuilder(&quot;ja&quot;).append(&quot;va&quot;).toString();//没有出现&quot;java&quot;字面量，所以不会在常量池里生成&quot;java&quot;对象System.out.println(str1==str1.intern());//false//java是关键字，在JVM初始化的相关类里肯定早就放进字符串常量池了String s1 = new String(&quot;test&quot;);System.out.println(s1==s1.intern());//false//&quot;test&quot;作为字面量，放入了池中，而new时s1指向的是heap中新生成的string对象，s1.intern()指向的是&quot;test&quot;字面量之前在池中生成的字符串对象String s2 = new StringBuilder(&quot;abc&quot;).toString();System.out.println(s2==s2.intern());//false //同上 八种基本类型的包装类和对象池java中基本类型的包装类的大部分都实现了常量池技术(严格来说应该叫对象池，在堆上)，这些类是Byte,Short,Integer,Long,Character,Boolean,另外两种浮点数类型的包装类则没有实现。另外 Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值小于等于127时才可使用对象池，也即对象不负责创建和管理大于127的这些类的对象。因为一般这种比较小的数用到的概率相对较大。 123456789101112131415161718public class Test&#123; public static void main(String[] args) &#123; //5种整形的包装类Byte,Short,Integer,Long,Character的对象， //在值小于127时可以使用对象池 Integer i1 = 127; //这种调用底层实际是执行的Integer.valueOf(127)，里面用到了IntegerCache对象池 Integer i2 = 127; System.out.println(i1 == i2);//输出true //值大于127时，不会从对象池中取对象 Integer i3 = 128; Integer i4 = 128; System.out.println(i3 == i4);//输出false //用new关键词新生成对象不会使用对象池 Integer i5 = new Integer(127); Integer i6 = new Integer(127); System.out.println(i5 == i6);//输出false //Boolean类也实现了对象池技术 Boolean bool1 = true; Boolean bool2 = true; System.out.println(bool1 == bool2);//输出true //浮点类型的包装类没有实现对象池技术 Double d1 = 1.0; Double d2 = 1.0; System.out.println(d1 == d2);//输出false &#125;&#125;","categories":[],"tags":[{"name":"JVM Arthas","slug":"JVM-Arthas","permalink":"https://tj-ever.github.io/tags/JVM-Arthas/"}]},{"title":"JVM 调优相关","slug":"JVM 调优相关","date":"2021-09-02T16:00:00.000Z","updated":"2021-09-16T03:45:08.342Z","comments":true,"path":"2021/09/03/JVM 调优相关/","link":"","permalink":"https://tj-ever.github.io/2021/09/03/JVM%20%E8%B0%83%E4%BC%98%E7%9B%B8%E5%85%B3/","excerpt":"","text":"JVM自带命令jmap此命令可以用来查看内存信息，实例个数以及占用内存大小 jps查看进程 打开log.txt，文件内容如下: num:序号 instances:实例数量 bytes:占用空间大小 class name:类名称，[C is a char[]，[S is a short[]，[I is a int[]，[B is a byte[]，[[I is a int[][] 堆信息 堆内存dump1jmap‐dump:format=b,file=eureka.hprof 14660 也可以设置内存溢出自动导出dump文件(内存很大的时候，可能会导不出来) -XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=./ (路径) 1234567891011121314public class OOMTest&#123; public static List&lt;Object&gt; list = new ArrayList&lt;&gt;(); // JVM设置 // ‐Xms10M ‐Xmx10M ‐XX:+PrintGCDetails ‐XX:+HeapDumpOnOutOfMemoryError ‐XX:HeapDumpPath=D:\\jvm.dump public static void main(String[] args) &#123; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); int i=0; int j=0; while (true) &#123; list.add(new User(i++, UUID.randomUUID().toString())); new User(j‐‐, UUID.randomUUID().toString()); &#125; &#125;&#125; 可以用jvisualvm命令工具导入该dump文件分析 jstack12345678910111213141516171819202122232425262728293031323334353637package ever.demo;public class DeadLockTest &#123; private static Object lock1 = new Object(); private static Object lock2 = new Object(); public static void main(String[] args) &#123; new Thread(() -&gt; &#123; synchronized (lock1) &#123; try &#123; System.out.println(&quot;thread1 begin&quot;); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; // todo &#125; synchronized (lock2) &#123; System.out.println(&quot;thread1 end&quot;); &#125; &#125; &#125;).start(); new Thread(() -&gt; &#123; synchronized (lock2) &#123; try &#123; System.out.println(&quot;thread2 begin&quot;); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; // todo &#125; synchronized (lock1) &#123; System.out.println(&quot;thread2 end&quot;); &#125; &#125; &#125;).start(); &#125;&#125; 首先jps查询进程 用jstack加进程id查找死锁，见如下示例 1jstack 21190 也可以用jvisualvm自动检测死锁 远程连接jvisualvm 启动普通的jar程序JMX端口配置: 1java ‐Dcom.sun.management.jmxremote.port=8888 ‐Djava.rmi.server.hostname=192.168.0.130 ‐Dcom.sun.management.jmxremote.ssl=false ‐Dcom.sun.management.jmxremote.authenticate=false ‐jar demo.jar -Dcom.sun.management.jmxremote.port 为远程机器的JMX端口 -Djava.rmi.server.hostname 为远程机器IP tomcat的JMX配置 在catalina.sh文件里的最后一个JAVA_OPTS的赋值语句下一行增加如下配置行 1JAVA_OPTS=&quot;$JAVA_OPTS ‐Dcom.sun.management.jmxremote.port=8888 ‐Djava.rmi.server.hostname=192.168.0.130 ‐Dcom.sun.ma nagement.jmxremote.ssl=false ‐Dcom.sun.management.jmxremote.authenticate=false&quot; jstack找出占用cpu最高的线程堆栈信息1.首先使用jps查出进程id 查出进程id为19663 2.使用命令top -p ，显示你的java进程的内存情况，pid是你的java进程号，比如19663 3，按H，获取每个线程的内存情况 4，找到内存和cpu占用最高的线程tid，比如19664 5，用printf ‘%x\\n’ pid 转为十六进制得到 0x4cd0，此为线程id的十六进制表示 6，执行 jstack 19663|grep -A 10 4cd0，得到线程堆栈信息中 4cd0 这个线程所在行的后面10行，从堆栈中可以发现导致cpu飙高的调 、用方法 7，查看对应的堆栈信息找出可能存在问题的代码 jinfo查看正在运行的Java应用程序的扩展参数 查看jvm的参数 查看java系统参数 jstatjstat命令可以查看堆内存各部分的使用量，以及加载类的数量。 命令的格式如下: jstat [-命令选项] [vmid] [间隔时间(毫秒)] [查询次数] 注意:使用的jdk版本是jdk8 垃圾回收统计jstat -gc pid 最常用，可以评估程序内存使用及GC压力整体情况 S0C:第一个幸存区的大小，单位KB S1C:第二个幸存区的大小 S0U:第一个幸存区的使用大小 S1U:第二个幸存区的使用大小 EC:伊甸园区的大小 EU:伊甸园区的使用大小 OC:老年代大小 OU:老年代使用大小 MC:方法区大小(元空间) MU:方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC:年轻代垃圾回收次数 YGCT:年轻代垃圾回收消耗时间，单位s FGC:老年代垃圾回收次数 FGCT:老年代垃圾回收消耗时间，单位s GCT:垃圾回收消耗总时间，单位s 堆内存统计 NGCMN:新生代最小容量 NGCMX:新生代最大容量 NGC:当前新生代容量 S0C:第一个幸存区大小 S1C:第二个幸存区的大小 EC:伊甸园区的大小 OGCMN:老年代最小容量 OGCMX:老年代最大容量 OGC:当前老年代大小 OC:当前老年代大小 MCMN:最小元数据容量 MCMX:最大元数据容量 MC:当前元数据空间大小 CCSMN:最小压缩类空间大小 CCSMX:最大压缩类空间大小 CCSC:当前压缩类空间大小 YGC:年轻代gc次数 FGC:老年代GC次数 新生代垃圾回收统计 S0C:第一个幸存区的大小 S1C:第二个幸存区的大小 S0U:第一个幸存区的使用大小 S1U:第二个幸存区的使用大小 TT:对象在新生代存活的次数 MTT:对象在新生代存活的最大次数 DSS:期望的幸存区大小 EC:伊甸园区的大小 EU:伊甸园区的使用大小 YGC:年轻代垃圾回收次数 YGCT:年轻代垃圾回收消耗时间 新生代内存统计 NGCMN:新生代最小容量 NGCMX:新生代最大容量 NGC:当前新生代容量 S0CMX:最大幸存1区大小 S0C:当前幸存1区大小 S1CMX:最大幸存2区大小 S1C:当前幸存2区大小 ECMX:最大伊甸园区大小 EC:当前伊甸园区大小 YGC:年轻代垃圾回收次数 FGC:老年代回收次数 老年代垃圾回收统计 MC:方法区大小 MU:方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 OC:老年代大小 OU:老年代使用大小 YGC:年轻代垃圾回收次数 FGC:老年代垃圾回收次数 FGCT:老年代垃圾回收消耗时间 GCT:垃圾回收消耗总时间 老年代内存统计 OGCMN:老年代最小容量 OGCMX:老年代最大容量 OGC:当前老年代大小 OC:老年代大小 YGC:年轻代垃圾回收次数 FGC:老年代垃圾回收次数 FGCT:老年代垃圾回收消耗时间 GCT:垃圾回收消耗总时间 元数据空间统计 MCMN:最小元数据容量 MCMX:最大元数据容量 MC:当前元数据空间大小 CCSMN:最小压缩类空间大小 CCSMX:最大压缩类空间大小 CCSC:当前压缩类空间大小 YGC:年轻代垃圾回收次数 FGC:老年代垃圾回收次数 FGCT:老年代垃圾回收消耗时间 GCT:垃圾回收消耗总时间 GC情况统计 S0:幸存1区当前使用比例 S1:幸存2区当前使用比例 E:伊甸园区使用比例 O:老年代使用比例 M:元数据区使用比例 CCS:压缩使用比例 YGC:年轻代垃圾回收次数 FGC:老年代垃圾回收次数 FGCT:老年代垃圾回收消耗时间 GCT:垃圾回收消耗总时间 JVM运行情况预估 用 jstat gc -pid 命令可以计算出如下一些关键数据，有了这些数据就可以采用之前介绍过的优化思路，先给自己的系统设置一些初始性的 JVM参数，比如堆内存大小，年轻代大小，Eden和Survivor的比例，老年代的大小，大对象的阈值，大龄对象进入老年代的阈值等。 年轻代对象增长的速率可以执行命令 jstat -gc pid 1000 10 (每隔1秒执行1次命令，共执行10次)，通过观察EU(eden区的使用)来估算每秒eden大概新增多少对 象，如果系统负载不高，可以把频率1秒换成1分钟，甚至10分钟来观察整体情况。 注意，一般系统可能有高峰期和日常期，所以需要在不同的时间分别估算不同情况下对象增长速率。 Young GC的触发频率和每次耗时知道年轻代对象增长速率我们就能推根据eden区的大小推算出Young GC大概多久触发一次，Young GC的平均耗时可以通过 YGCT/YGC 公式算出，根据结果我们大概就能知道系统大概多久会因为Young GC的执行而卡顿多久。 每次Young GC后有多少对象存活和进入老年代这个因为之前已经大概知道Young GC的频率，假设是每5分钟一次，那么可以执行命令 jstat -gc pid 300000 10 ，观察每次结果eden， survivor和老年代使用的变化情况，在每次gc后eden区使用一般会大幅减少，survivor和老年代都有可能增长，这些增长的对象就是每次 Young GC后存活的对象，同时还可以看出每次Young GC后进去老年代大概多少对象，从而可以推算出老年代对象增长速率。 Full GC的触发频率和每次耗时知道了老年代对象的增长速率就可以推算出Full GC的触发频率了，Full GC的每次耗时可以用公式 FGCT/FGC 计算得出。 优化思路其实简单来说就是尽量让每次Young GC后的存活对象小于Survivor区域的50%，都留存在年轻代里。尽量别让对象进入老年 代。尽量减少Full GC的频率，避免频繁Full GC对JVM性能的影响。 系统频繁Full GC导致系统卡顿 机器配置:2核4G JVM内存大小:2G 系统运行时间:7天 期间发生的Full GC次数和耗时:500多次，200多秒 期间发生的Young GC次数和耗时:1万多次，500多秒 大致算下来每天会发生70多次Full GC，平均每小时3次，每次Full GC在400毫秒左右; 每天会发生1000多次Young GC，每分钟会发生1次，每次Young GC在50毫秒左右。 JVM参数设置如下: 12‐Xms1536M ‐Xmx1536M ‐Xmn512M ‐Xss256K ‐XX:SurvivorRatio=6 ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M‐XX:+UseParNewGC ‐XX:+UseConcMarkSweepGC ‐XX:CMSInitiatingOccupancyFraction=75 ‐XX:+UseCMSInitiatingOccupancyOnly 可以结合对象挪动到老年代那些规则推理下我们这个程序可能存在的一些问题 经过分析感觉可能会由于对象动态年龄判断机制导致full gc较为频繁 此处模拟一个工程，打印state结果如下 1jstat ‐gc 13456 2000 10000 对于对象动态年龄判断机制导致的full gc较为频繁可以先试着优化下JVM参数，把年轻代适当调大点: l12‐Xms1536M ‐Xmx1536M ‐Xmn1024M ‐Xss256K ‐XX:SurvivorRatio=6 ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M‐XX:+UseParNewGC ‐XX:+UseConcMarkSweepGC ‐XX:CMSInitiatingOccupancyFraction=92 ‐XX:+UseCMSInitiatingOccupancyOnly 再次查看state，优化完发现没什么变化，full gc的次数比minor gc的次数还多了 我们可以推测下full gc比minor gc还多的原因有哪些? 1、元空间不够导致的多余full gc 2、显示调用System.gc()造成多余的full gc，这种一般线上尽量通过­XX:+DisableExplicitGC参数禁用，如果加上了这个JVM启动参数，那 么代码中调用System.gc()没有任何效果 3、老年代空间分配担保机制 最快速度分析完这些我们推测的原因以及优化后，我们发现young gc和full gc依然很频繁了，而且看到有大量的对象频繁的被挪动到老年 代，这种情况我们可以借助jmap命令大概看下是什么对象 查到了有大量User对象产生，这个可能是问题所在，但不确定，还必须找到对应的代码确认，如何去找对应的代码了? 1、代码里全文搜索生成User对象的地方(适合只有少数几处地方的情况) 2、如果生成User对象的地方太多，无法定位具体代码，我们可以同时分析下占用cpu较高的线程，一般有大量对象不断产生，对应的方法 代码肯定会被频繁调用，占用的cpu必然较高 可以用上面讲过的jstack或jvisualvm来定位cpu使用较高的代码，最终定位到的代码如下: 12345678910111213141516171819202122232425import java.util.ArrayList; @RestControllerpublic class IndexController&#123; @RequestMapping(&quot;/user/process&quot;) public String processUserData() throws InterruptedException &#123; ArrayList&lt;User&gt; users = queryUsers(); for (User user: users) &#123; //TODO 业务处理 System.out.println(&quot;user:&quot; + user.toString()); &#125; return &quot;end&quot;; &#125; /** * 模拟批量查询用户场景 * @return */ private ArrayList&lt;User&gt; queryUsers() &#123; ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;(); for(inti=0;i&lt;5000;i++)&#123; users.add(new User(i,&quot;zhuge&quot;)); &#125; return users; &#125;&#125; 同时，java的代码也是需要优化的，一次查询出500M的对象出来，明显不合适，要根据之前说的各种原则尽量优化到合适的值，尽量消 除这种朝生夕死的对象导致的full gc 内存泄露一般电商架构可能会使用多级缓存架构，就是redis加上JVM级缓存，大多数可能为了图方便对于JVM级缓存就简单使用一个hashmap，于是不断往里面放缓存数据，但是很少考虑这个map的容量问题，结果这个缓存map越来越大，一直占用着老年代的很多空间，时间长了就会导致full gc非常频繁，这就是一种内存泄漏，对于一些老旧数据没有及时清理导致一直占用着宝贵的内存资源，时间长了除了导致full gc，还有可能导致OOM。 这种情况完全可以考虑采用一些成熟的JVM级缓存框架来解决，比如ehcache等自带一些LRU数据淘汰算法的框架来作为JVM级的缓存。","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tj-ever.github.io/tags/JVM/"}]},{"title":"JVM 垃圾收集","slug":"JVM 垃圾收集","date":"2021-09-02T16:00:00.000Z","updated":"2021-09-03T08:33:40.568Z","comments":true,"path":"2021/09/03/JVM 垃圾收集/","link":"","permalink":"https://tj-ever.github.io/2021/09/03/JVM%20%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86/","excerpt":"","text":"垃圾收集算法 分代收集理论 当前虚拟机的垃圾收集都采用分代收集算法，这种算法根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样可以根据各个年代的特点选择合适的垃圾收集算法。 在新生代中，每次收集都会有大量对象(近99%)死去，所以可以选择复制算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。 老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选 择“标记-清除”或“标记-整理”算法进行垃圾收集。注意，“标记-清除”或“标记-整理”算法会比复制算法慢10倍以上。 标记-复制算法 为了解决效率问题，“复制”收集算法出现了。它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 标记-清除算法 算法分为“标记”和“清除”阶段。标记存活的对象， 统一回收所有未被标记的对象(一般选择这种);也可以反过来，标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象 。 它是最基础的收集算法，比较简单，但是会带来两个明显的问题: 效率问题 (如果需要标记的对象太多，效率不高) 空间问题(标记清除后会产生大量不连续的碎片) 标记-整理算法 根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 垃圾收集器 Serial收集器-XX:+UseSerialGC -XX:+UseSerialOldGC Serial(串行)收集器是最基本、历史最悠久的垃圾收集器了。大家看名字就知道这个收集器是一个单线程收集器了。它的 “单线程” 的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工 作的时候必须暂停其他所有的工作线程( “Stop The World” )，直到它收集结束。 新生代采用复制算法，老年代采用标记-整理算法。 虚拟机的设计者们当然知道Stop The World带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短 (仍然还有停顿，寻找最优秀的垃圾收集器的过程仍然在继续)。 但是Serial收集器有没有优于其他垃圾收集器的地方呢?当然有，它简单而高效(与其他收集器的单线程相比)。 Serial 收集器由于没有线程交互的开销，自然可以获得很高的单线程收集效率。 Serial Old收集器是Serial收集器的老年代版本，它同样是一个单线程收集器。 它主要有两大用途:一种是在JDK1.5 以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种是作为CMS收集器的后备方案。 Parallel Scavenge收集器-XX:+UseParallelGC(年轻代),-XX:+UseParallelOldGC(老年代) Parallel收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为(控制参数、收集算法、回收策略等等)和Serial收集器类似。默认的收集线程数跟cpu核数相同，当然也可以用参数-XX:ParallelGCThreads指定收集线程数，但是一般不推荐修改。 Parallel Scavenge收集器关注点是吞吐量(高效率的利用CPU)，所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。 。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间(提高用户体验)。 Parallel Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。 新生代采用复制算法，老年代采用标记-整理算法。 Parallel Old收集器是Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。 在注重吞吐量以及 CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器(JDK8默认的新生代和老年代收集 器)。 ParNew收集器-XX:+UseParNewGC ParNew收集器其实跟Parallel收集器很类似，区别主要在于它可以和CMS收集器配合使用。 新生代采用复制算法，老年代采用标记-整理算法。 它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，只有它能与CMS收集器(真正意义上的并发收集器)配合工作。 CMS收集器-XX:+UseConcMarkSweepGC(老年代) CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程 (基本上)同时工作。 从名字中的Mark Sweep这两个词可以看出，CMS收集器是一种 “标记-清除”算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤: 初始标记: 暂停所有的其他线程(STW)，并记录下gc roots直接能引用的对象，速度很快。 并发标记: 并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程， 这个过程耗时较长但是不需要停顿用户线程， 可以与垃圾收集线程一起并发运行。因为用户程序继续运行，可能会有导致已经标记过的对象状态发生改变。 重新标记: 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。主要用到三色标记里的增量更新算法做重新标记。 并发清理: 开启用户线程，同时GC线程开始对未标记的区域做清扫。这个阶段如果有新增对象会被标记为黑色不做任何处理 并发重置:重置本次GC过程中的标记数据。 从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点:并发收集、低停顿。 但是它有下面几个明显的缺点: 对CPU资源敏感(会和服务抢资源); 无法处理浮动垃圾(在并发标记和并发清理阶段又产生垃圾，这种浮动垃圾只能等到下一次gc再清理了); 使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生，当然通过参数-XX:+UseCMSCompactAtFullCollection可以让jvm在执行完标记清除后再做整理。 执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况，特别是在并发标记和并发清理阶段会出现，一边回收，系统一边运行，也许没回收完就再次触发full gc，也就是”concurrent mode failure”，此时会进入stop the world，用serial old垃圾收集器来回收 CMS的相关核心参数 -XX:+UseConcMarkSweepGC:启用cms -XX:ConcGCThreads:并发的GC线程数 -XX:+UseCMSCompactAtFullCollection:FullGC之后做压缩整理(减少碎片) -XX:CMSFullGCsBeforeCompaction:多少次FullGC之后压缩一次，默认是0，代表每次FullGC后都会压缩一次 -XX:CMSInitiatingOccupancyFraction: 当老年代使用达到该比例时会触发FullGC(默认是92，这是百分比) XX:+UseCMSInitiatingOccupancyOnly:只使用设定的回收阈值(-XX:CMSInitiatingOccupancyFraction设 定的值)，如果不指定，JVM仅在第一次使用设定值，后续则会自动调整 -XX:+CMSScavengeBeforeRemark:在CMS GC前启动一次minor gc，目的在于减少老年代对年轻代的引 用，降低CMS GC的标记阶段时的开销，一般CMS的GC耗时 80%都在标记阶段 -XX:+CMSParallellnitialMarkEnabled:表示在初始标记的时候多线程执行，缩短STW -XX:+CMSParallelRemarkEnabled:在重新标记的时候多线程执行，缩短STW; JVM参数优化设置(ParNew+CMS) 对于8G内存，我们一般是分配4G内存给JVM，正常的JVM参数配置如下: 1‐Xms3072M ‐Xmx3072M ‐Xss1M ‐XX:MetaspaceSize&#x3D;256M ‐XX:MaxMetaspaceSize&#x3D;256M ‐XX:SurvivorRatio&#x3D;8 上节课说过，这样设置可能会由于动态对象年龄判断原则导致频繁full gc。 于是我们可以更新下JVM参数设置: 1‐Xms3072M ‐Xmx3072M ‐Xmn2048M ‐Xss1M ‐XX:MetaspaceSize&#x3D;256M ‐XX:MaxMetaspaceSize&#x3D;256M ‐XX:SurvivorRatio&#x3D;8 这样就降低了因为对象动态年龄判断原则导致的对象频繁进入老年代的问题，其实很多优化无非就是让短期存活的对象尽量都留在survivor里，不要进入老年代，这样在minor gc的时候这些对象都会被回收，不会进到老年代从而导致full gc。 对于对象年龄应该为多少才移动到老年代比较合适，本例中一次minor gc要间隔14秒，大多数对象一般在几秒内就 会变为垃圾，完全可以将默认的15岁改小一点，比如改为5，那么意味着对象要经过5次minor gc才会进入老年代，整个时间也有一两分钟了，如果对象这么长时间都没被回收，完全可以认为这些对象是会存活的比较长的对象，可以移动到老年代，而不是继续一直占用survivor区空间。 结论 JVM优化就是尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。 对于多大的对象直接进入老年代(参数-XX:PretenureSizeThreshold)，这个一般可以结合你自己系统看下有没有什么大对象生成，预估下大对象的大小，一般来说设置为1M就差不多了，很少有超过1M的大对象，这些对象一般就是你系统初始化分配的缓存对象，比如大的缓存List，Map之类的对象。 可以适当调整JVM参数如下: 1‐Xms3072M ‐Xmx3072M ‐Xmn2048M ‐Xss1M ‐XX:MetaspaceSize&#x3D;256M ‐XX:MaxMetaspaceSize&#x3D;256M ‐XX:SurvivorRatio&#x3D;8 2 ‐XX:MaxTenuringThreshold&#x3D;5‐XX:PretenureSizeThreshold&#x3D;1M 对于JDK8默认的垃圾回收器是-XX:+UseParallelGC(年轻代)和-XX:+UseParallelOldGC(老年代) 如果内存较大，系统对停顿时间比较敏感，我们可以使用ParNew+CMS(-XX:+UseParNewGC -XX:+UseConcMarkSweepGC) 对于老年代CMS的参数如何设置我们可以思考下，首先我们想下当前这个系统有哪些对象可能会长期存活躲过5次以上 minor gc最终进入老年代。 无非就是那些Spring容器里的Bean，线程池对象，一些初始化缓存数据对象等，这些加起来充其量也就几十MB。 还有就是某次minor gc完了之后还有超过一两百M的对象存活，那么就会直接进入老年代，比如突然某一秒瞬间要处理五六百单，那么每秒生成的对象可能有一百多M，再加上整个系统可能压力剧增，一个订单要好几秒才能处理完，下一秒可能又有很多订单过来。 我们可以估算下大概每隔五六分钟出现一次这样的情况，那么大概半小时到一小时之间就可能因为老年代满了触发一次 Full GC，Full GC的触发条件还有我们之前说过的老年代空间分配担保机制，历次的minor gc挪动到老年代的对象大小肯定是非常小的，所以几乎不会在minor gc触发之前由于老年代空间分配担保失败而产生full gc，其实在半小时后发生 full gc，这时候已经过了抢购的最高峰期，后续可能几小时才做一次FullGC。 对于碎片整理，因为都是1小时或几小时才做一次FullGC，是可以每做完一次就开始碎片整理，或者两到三次之后再做一次也行。 综上，只要年轻代参数设置合理，老年代CMS的参数设置基本都可以用默认值，如下所示: 12‐Xms3072M ‐Xmx3072M ‐Xmn2048M ‐Xss1M ‐XX:MetaspaceSize&#x3D;256M ‐XX:MaxMetaspaceSize&#x3D;256M ‐XX:SurvivorRatio&#x3D;8 ‐XX:MaxTenuringThreshold&#x3D;5 ‐XX:PretenureSizeThreshold&#x3D;1M ‐XX:+UseParNewGC‐XX:+UseConcMarkSweepGC‐XX:CMSInitiatingOccupancyFraction&#x3D;92 ‐XX:+UseCMSCompactAtFullCollection‐XX:CMSFullGCsBeforeCompaction&#x3D;0 垃圾收集底层算法实现三色标记在并发标记的过程中，因为标记期间应用线程还在继续跑，对象间的引用可能发生变化，多标和漏标的情况就有可能发生。 这里引入“三色标记”，把Gc roots可达性分析遍历对象过程中遇到的对象， 按照“是否访问过”这个条件标记成以下三种颜色: 黑色: 表示对象已经被垃圾收集器访问过， 且这个对象的所有引用都已经扫描过。 黑色的对象代表已经扫描过， 它是安全存活的， 如果有其他对象引用指向了黑色对象， 无须重新扫描一遍。 黑色对象不可能直接(不经过 灰色对象) 指向某个白色对象。 灰色: 表示对象已经被垃圾收集器访问过， 但这个对象上至少存在一个引用还没有被扫描过。 白色: 表示对象尚未被垃圾收集器访问过。 显然在可达性分析刚刚开始的阶段， 所有的对象都是白色的， 若在分析结束的阶段， 仍然是白色的对象， 即代表不可达。 123456789101112131415161718192021222324/*** 垃圾收集算法细节之三色标记*/public class ThreeColorRemark&#123; public static void main(String[] args) &#123; A a= new A(); //开始做并发标记 D d = a.b.d; // 1.读 a.b.d = null; // 2.写 a.d =d; // 3.写 &#125;&#125;class A&#123; B b = new B(); D d = null;&#125;class B&#123; C c = new C(); D d = new D();&#125;class C&#123;&#125;class D&#123;&#125; 多标-浮动垃圾在并发标记过程中，如果由于方法运行结束导致部分局部变量(gc root)被销毁，这个gc root引用的对象之前又被扫描过 (被标记为非垃圾对象)，那么本轮GC不会回收这部分内存。这部分本应该回收但是没有回收到的内存，被称之为“浮动 垃圾”。 浮动垃圾并不会影响垃圾回收的正确性，只是需要等到下一轮垃圾回收中才被清除。 另外，针对并发标记(还有并发清理)开始后产生的新对象，通常的做法是直接全部当成黑色，本轮不会进行清除。这部分对象期间可能也会变为垃圾，这也算是浮动垃圾的一部分。 漏标-读写屏障漏标会导致被引用的对象被当成垃圾误删除，这是严重bug，必须解决，有两种解决方案: 增量更新(Incremental Update) 和原始快照(Snapshot At The Beginning，SATB) 。 增量更新就是当黑色对象插入新的指向白色对象的引用关系时， 就将这个新插入的引用记录下来， 等并发扫描结束之 后， 再将这些记录过的引用关系中的黑色对象为根， 重新扫描一次。 这可以简化理解为， 黑色对象一旦新插入了指向 白色对象的引用之后， 它就变回灰色对象了。 原始快照就是当灰色对象要删除指向白色对象的引用关系时， 就将这个要删除的引用记录下来， 在并发扫描结束之后， 再将这些记录过的引用关系中的灰色对象为根， 重新扫描一次，这样就能扫描到白色的对象，将白色对象直接标记为黑色(目的就是让这种对象在本轮gc清理中能存活下来，待下一轮gc的时候重新扫描，这个对象也有可能是浮动垃圾) 以上无论是对引用关系记录的插入还是删除， 虚拟机的记录操作都是通过写屏障实现的。 写屏障给某个对象的成员变量赋值时，其底层代码大概长这样: 1234567 /** * @param field 某对象的成员变量，如 a.b.d * @param new_value 新值，如 null */ void oop_field_store(oop* field,oop new_value)&#123; *field = new_value; // 赋值操作&#125; 所谓的写屏障，其实就是指在赋值操作前后，加入一些处理(可以参考AOP的概念): 12345void oop_field_store(oop* field,oop new_value)&#123; pre_write_barrier(field); // 写屏障‐写前操作 *field = new_value; post_write_barrier(field, value); // 写屏障‐写后操作&#125; 写屏障实现SATB当对象B的成员变量的引用发生变化时，比如引用消失(a.b.d = null)，我们可以利用写屏障，将B原来成员变量的引用 对象D记录下来: 1234void pre_write_barrier(oop* field)&#123; oop old_value = *field; // 获取旧值 remark_set.add(old_value); // 记录原来的引用对象&#125; 写屏障实现增量更新当对象A的成员变量的引用发生变化时，比如新增引用(a.d = d)，我们可以利用写屏障，将A新的成员变量引用对象D 记录下来: 123void post_write_barrier(oop* field,oopnew_value)&#123; remark_set.add(new_value); // 记录新引用的对象&#125; 读屏障1234oop oop_field_load(oop* field)&#123; pre_load_barrier(field); // 读屏障‐读取前操作 return *field; &#125; 读屏障是直接针对第一步:D d = a.b.d，当读取成员变量时，一律记录下来: 1234void pre_load_barrier(oop* field)&#123; oop old_value = *field; remark_set.add(old_value); // 记录读取到的对象&#125; 现代追踪式(可达性分析)的垃圾回收器几乎都借鉴了三色标记的算法思想，尽管实现的方式不尽相同:比如白色/黑色 集合一般都不会出现(但是有其他体现颜色的地方)、灰色集合可以通过栈/队列/缓存日志等方式进行实现、遍历方式可 以是广度/深度遍历等等。 对于读写屏障，以Java HotSpot VM为例，其并发标记时对漏标的处理方案如下: CMS:写屏障 + 增量更新 G1，Shenandoah:写屏障 + SATB ZGC:读屏障 工程实现中，读写屏障还有其他功能，比如写屏障可以用于记录跨代/区引用的变化，读屏障可以用于支持移动对象的并 发执行等。功能之外，还有性能的考虑，所以对于选择哪种，每款垃圾回收器都有自己的想法。 为什么G1用SATB?CMS用增量更新? 我的理解:SATB相对增量更新效率会高(当然SATB可能造成更多的浮动垃圾)，因为不需要在重新标记阶段再次深度扫描 被删除引用对象，而CMS对增量引用的根对象会做深度扫描，G1因为很多对象都位于不同的region，CMS就一块老年代 区域，重新深度扫描对象的话G1的代价会比CMS高，所以G1选择SATB不深度扫描对象，只是简单标记，等到下一轮GC 再深度扫描。 记忆集与卡表在新生代做GCRoots可达性扫描过程中可能会碰到跨代引用的对象，这种如果又去对老年代再去扫描效率太低了。 为此，在新生代可以引入记录集(Remember Set)的数据结构(记录从非收集区到收集区的指针集合)，避免把整个 老年代加入GCRoots扫描范围。事实上并不只是新生代、 老年代之间才有跨代引用的问题， 所有涉及部分区域收集 (Partial GC) 行为的垃圾收集器， 典型的如G1、 ZGC和Shenandoah收集器， 都会面临相同的问题。 垃圾收集场景中，收集器只需通过记忆集判断出某一块非收集区域是否存在指向收集区域的指针即可，无需了解跨代引 用指针的全部细节。 hotspot使用一种叫做“卡表”(cardtable)的方式实现记忆集，也是目前最常用的一种方式。关于卡表与记忆集的关系， 可以类比为Java语言中HashMap与Map的关系。 卡表是使用一个字节数组实现:CARD_TABLE[ ]，每个元素对应着其标识的内存区域一块特定大小的内存块，称为“卡 页”。 hotSpot使用的卡页是2^9大小，即512字节 一个卡页中可包含多个对象，只要有一个对象的字段存在跨代指针，其对应的卡表的元素标识就变成1，表示该元素变 脏，否则为0. GC时，只要筛选本收集区的卡表中变脏的元素加入GCRoots里。 卡表的维护 卡表变脏上面已经说了，但是需要知道如何让卡表变脏，即发生引用字段赋值时，如何更新卡表对应的标识为1。 Hotspot使用写屏障维护卡表状态。 G1收集器G1 (Garbage-First)是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足GC 停顿时间要求的同时,还具备高吞吐量性能特征. G1将Java堆划分为多个大小相等的独立区域(Region)，JVM最多可以有2048个Region。 一般Region大小等于堆大小除以2048，比如堆大小为4096M，则Region大小为2M，当然也可以用参数”- XX:G1HeapRegionSize”手动指定Region大小，但是推荐默认的计算方式。 G1保留了年轻代和老年代的概念，但不再是物理隔阂了，它们都是可以不连续的Region的集合。 默认年轻代对堆内存的占比是5%，如果堆大小为4096M，那么年轻代占据200MB左右的内存，对应大概是100个 Region，可以通过“-XX:G1NewSizePercent”设置新生代初始占比，在系统运行中，JVM会不停的给年轻代增加更多的Region，但是最多新生代的占比不会超过60%，可以通过“-XX:G1MaxNewSizePercent”调整。 年轻代中的Eden和 Survivor对应的region也跟之前一样，默认8:1:1，假设年轻代现在有1000个region，eden区对应800个，s0对应100 个，s1对应100个。 一个Region可能之前是年轻代，如果Region进行了垃圾回收，之后可能又会变成老年代，也就是说Region的区域功能可能会动态变化。 G1垃圾收集器对于对象什么时候会转移到老年代跟之前的原则一样，唯一不同的是对大对象的处理，G1有专门分配大对象的Region叫Humongous区，而不是让大对象直接进入老年代的Region中。 在G1中，大对象的判定规则就是一个大对象超过了一个Region大小的50%，比如按照上面算的，每个Region是2M，只要一个大对象超过了1M，就会被放 入Humongous中，而且一个大对象如果太大，可能会横跨多个Region来存放。 Humongous区专门存放短期巨型对象，不用直接进老年代，可以节约老年代的空间，避免因为老年代空间不够的GC开销。 Full GC的时候除了收集年轻代和老年代之外，也会将Humongous区一并回收。 G1收集器一次GC的运作过程大致分为以下几个步骤: 初始标记(initial mark，STW): 暂停所有的其他线程，并记录下gc roots直接能引用的对象，速度很快 ; 并发标记(Concurrent Marking): 同CMS的并发标记； 最终标记(Remark，STW): 同CMS的重新标记； 筛选回收(Cleanup，STW): 筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间(可用 -XX:MaxGCPauseMillis指定)来制定回收计划，比如说老年代此时有1000个Region都满了，但是因为根据预期停顿时间，本次垃圾回收可能只能停顿200毫秒，那么通过之前回收成本计算得知，可能回收其中800个Region刚好需要200ms，那么就只会回收800个Region(Collection Set，要回收的集合)，尽量把GC导致的停顿时间控制在我们指定的范围内。 这个阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。不管是年轻代或是老年代，回收算法主要用的是复制算法，将一个region中的存活对象复制到另一个region中，这种不会像CMS那样回收完因为有很多内存碎片还需要整理一次，G1采用复制算法回收几乎不会有太多内存碎片。(注意:CMS回收阶 段是跟用户线程一起并发执行的，G1因为内部实现太复杂暂时没实现并发回收，不过到了Shenandoah就实现了并发收集，Shenandoah可以看成是G1的升级版本) G1收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的Region(这也就是它的名字 Garbage-First的由来)，比如一个Region花200ms能回收10M垃圾，另外一个Region花50ms能回收20M垃圾，在回收时间有限情况下，G1当然会优先选择后面这个Region回收。这种使用Region划分内存空间以及有优先级的区域回收方式，保证了G1收集器在有限时间内可以尽可能高的收集效率。 被视为JDK1.7以上版本Java虚拟机的一个重要进化特征。它具备以下特点: 并行与并发: G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU(CPU或者CPU核心)来缩短Stop-The-World停顿时间。部分其他收集器原本需要停顿Java线程来执行GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。 分代收集: 虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但是还是保留了分代的概念。 空间整合: 与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器;从局部 上来看是基于“复制”算法实现的。 可预测的停顿: 这是G1相对于CMS的另一个大优势，降低停顿时间是G1 和 CMS共同的关注点，但G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段(通过参数”- XX:MaxGCPauseMillis“指定)内完成垃圾收集。 设置不同的期望停顿时间，可使得G1在不 同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。不过， 这里设置的“期望值”必须是符合实际的， 不能异想天开， 毕竟G1是要冻结用户线程来复制对象的， 这个停顿时间再怎么低也得有个限度。 它默认的停顿目标为两百毫秒， 一般来说， 回收阶段占到几十到一百甚至接近两百毫秒都很正常， 但如果我们把停顿时间调得非常低， 譬如设置为二十毫秒， 很可能出现的结果就是由于停顿目标时间太短， 导致每次选出来的回收集只占堆内存很小的一部分， 收集器收集的速度逐渐跟不上分配器分配的速度， 导致垃圾慢慢堆积。 很可能一开始收集器还能从空闲的堆内存中获得一些喘息的时间， 但应用运行时间一长就不行了， 最终占满堆引发 Full GC反而降低性能， 所以通常把期望停顿时间设置为一两百毫秒或者两三百毫秒会是比较合理的。 G1垃圾收集分类 YoungGC YoungGC并不是说现有的Eden区放满了就会马上触发，G1会计算下现在Eden区回收大概要多久时间，如果回收时间远远小于参数 -XX:MaxGCPauseMills 设定的值，那么增加年轻代的region，继续给新对象存放，不会马上做Young GC，直到下一次Eden区放满，G1计算回收时间接近参数 -XX:MaxGCPauseMills 设定的值，那么就会触发Young GC MixedGC 不是FullGC，老年代的堆占有率达到参数(-XX:InitiatingHeapOccupancyPercent)设定的值则触发，回收所有的 Young和部分Old(根据期望的GC停顿时间确定old区垃圾收集的优先顺序)以及大对象区，正常情况G1的垃圾收集是先做 MixedGC，主要使用复制算法，需要把各个region中存活的对象拷贝到别的region里去，拷贝过程中如果发现没有足够的空region能够承载拷贝对象就会触发一次Full GC Full GC 停止系统程序，然后采用单线程进行标记、清理和压缩整理，好空闲出来一批Region来供下一次MixedGC使用，这个过程是非常耗时的。(Shenandoah优化成多线程收集了) G1收集器参数设置 -XX:+UseG1GC 使用G1收集器 -XX:ParallelGCThreads 指定GC工作的线程数量 -XX:G1HeapRegionSize 指定分区大小(1MB~32MB，且必须是2的N次幂)，默认将整堆划分为2048个分区 -XX:MaxGCPauseMillis 目标暂停时间(默认200ms) -XX:G1NewSizePercent 新生代内存初始空间(默认整堆5%) -XX:G1MaxNewSizePercent 新生代内存最大空间 -XX:TargetSurvivorRatio Survivor区的填充容量(默认50%)，Survivor区域里的一批对象(年龄1+年龄2+年龄n的多个年龄对象)总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代 -XX:MaxTenuringThreshold 最大年龄阈值(默认15) -XX:InitiatingHeapOccupancyPercent 老年代占用空间达到整堆内存阈值(默认45%)，则执行新生代和老年代的混合收集(MixedGC)，比如我们之前说的堆默认有2048个region，如果有接近1000个region都是老年代的region，则可能 就要触发MixedGC了 -XX:G1MixedGCLiveThresholdPercent 默认85%,region中的存活对象低于这个值时才会回收该region，如果超过这个值，存活对象过多，回收的的意义不大。 -XX:G1MixedGCCountTarget 在一次回收过程中指定做几次筛选回收(默认8次)，在最后一个筛选回收阶段可以回收一 会，然后暂停回收，恢复系统运行，一会再开始回收，这样可以让系统不至于单次停顿时间过长。 -XX:G1HeapWastePercent 默认5%，gc过程中空出来的region是否充足阈值，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清 理掉，这样的话在回收过程就会不断空出来新Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了。 G1垃圾收集器优化建议假设参数 -XX:MaxGCPauseMills 设置的值很大，导致系统运行很久，年轻代可能都占用了堆内存的60%了，此时才触发年轻代gc。 那么存活下来的对象可能就会很多，此时就会导致Survivor区域放不下那么多的对象，就会进入老年代中。 或者是你年轻代gc过后，存活下来的对象过多，导致进入Survivor区域后触发了动态年龄判定规则，达到了Survivor区域的50%，也会快速导致一些对象进入老年代中。 所以这里核心还是在于调节 -XX:MaxGCPauseMills 这个参数的值，在保证他的年轻代gc别太频繁的同时，还得考虑 每次gc过后的存活对象有多少,避免存活对象太多快速进入老年代，频繁触发mixed gc. G1使用场景 50%以上的堆被存活对象占用 对象分配和晋升的速度变化非常大 3. 垃圾回收时间特别长，超过1秒 8GB以上的堆内存(建议值) 停顿时间是500ms以内 ZGC收集器(-XX:+UseZGC)参考文章:https://wiki.openjdk.java.net/display/zgc/Main http://cr.openjdk.java.net/~pliden/slides/ZGC-Jfokus-2018.pdf ZGC是一款JDK 11中新加入的具有实验性质的低延迟垃圾收集器，ZGC可以说源自于是Azul System公司开发的 C4(Concurrent Continuously Compacting Collector) 收集器。 ZGC目标 如下图所示，ZGC的目标主要有4个: 支持TB量级的堆。 最大GC停顿时间不超10ms。目前一般线上环境运行良好的JAVA应用Minor GC停顿时间在10ms左右， Major GC一般都需要100ms以上(G1可以调节停顿时间，但是如果调的过低的话，反而会适得其反)，之所以能做到这一点是因为它的停顿时间主要跟Root扫描有关，而Root数量和堆大小是没有任何关系的。 奠定未来GC特性的基础。 最糟糕的情况下吞吐量会降低15%。这都不是事，停顿时间足够优秀。至于吞吐量，通过扩容分分钟解决。 另外，Oracle官方提到了它最大的优点是，它的停顿时间不会随着堆的增大而增长!也就是说，几十G堆的停顿时间是 10ms以下，几百G甚至上T堆的停顿时间也是10ms以下。 不分代(暂时)单代，即ZGC「没有分代」。我们知道以前的垃圾回收器之所以分代，是因为源于“「大部分对象朝生夕死」”的假设，事实上大部分系统的对象分配行为也确实符合这个假设。 那么为什么ZGC就不分代呢。因为分代实现起来麻烦，作者就先实现出一个比较简单可用的单代版本，后续会优化。 ZGC内存布局ZGC收集器是一款基于Region内存布局的， 暂时不设分代的， 使A用了读屏障、 颜色指针等技术来实现可并发的标记-整理算法的， 以低延迟为首要目标的一款垃圾收集器。ZGC的Region可以具有大、 中、 小三类容量: 小型Region(Small Region) : 容量固定为2MB， 用于放置小于256KB的小对象。 中型Region(Medium Region) : 容量固定为32MB， 用于放置大于等于256KB但小于4MB的对象。 大型Region(Large Region) : 容量不固定， 可以动态变化， 但必须为2MB的整数倍， 用于放置4MB或以上的大对象。 每个大型Region中只会存放一个大对象， 这也预示着虽然名字叫作“大型Region”， 但它的实际容量完全有可能小于中型Region， 最小容量可低至4MB。 大型Region在ZGC的实现中是不会被重分配的， 因为复制一个大对象的代价非常高昂。 NUMA-awareNUMA对应的有UMA，UMA即Uniform Memory Access Architecture，NUMA就是Non Uniform Memory Access Architecture。UMA表示内存只有一块，所有CPU都去访问这一块内存，那么就会存在竞争问题(争夺内存总线访问权)，有竞争就会有锁，有锁效率就会受到影响，而且CPU核心数越多，竞争就越激烈。NUMA的话每个CPU对应有一 块内存，且这块内存在主板上离这个CPU是最近的，每个CPU优先访问这块内存，那效率自然就提高了: 服务器的NUMA架构在中大型系统上一直非常盛行，也是高性能的解决方案，尤其在系统延迟方面表现都很优秀。ZGC 是能自动感知NUMA架构并充分利用NUMA架构特性的。 颜色指针Colored Pointers，即颜色指针，如下图所示，ZGC的核心设计之一。以前的垃圾回收器的GC信息都保存在对象头中， 而ZGC的GC信息保存在指针中。 每个对象有一个64位指针，这64位被分为: 18位:预留给以后使用; 1位:Finalizable标识，此位与并发引用处理有关，它表示这个对象只能通过finalizer才能访问; 1位:Remapped标识，设置此位的值后，对象未指向relocation set中(relocation set表示需要GC的Region集合); 1位:Marked1标识; 1位:Marked0标识，和上面的Marked1都是标记对象用于辅助GC; 42位:对象的地址(所以它可以支持2^42=4T内存): 为什么有2个mark标记?每一个GC周期开始时，会交换使用的标记位，使上次GC周期中修正的已标记状态失效，所有引用都变成未标记。 GC周期1:使用mark0, 则周期结束所有引用mark标记都会成为01。 GC周期2:使用mark1, 则期待的mark标记10，所有引用都能被重新标记。 通过对配置ZGC后对象指针分析我们可知，对象指针必须是64位，那么ZGC就无法支持32位操作系统，同样的也就无法支持压缩指针了(CompressedOops，压缩指针也是32位)。 颜色指针的三大优势: 一旦某个Region的存活对象被移走之后，这个Region立即就能够被释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修正后才能清理，这使得理论上只要还有一个空闲Region，ZGC就能完成收集。 颜色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量，ZGC只使用了读屏障。 颜色指针具备强大的扩展性，它可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数 据，以便日后进一步提高性能。 读屏障之前的GC都是采用Write Barrier，这次ZGC采用了完全不同的方案读屏障，这个是ZGC一个非常重要的特性。 在标记和移动对象的阶段，每次「从堆里对象的引用类型中读取一个指针」的时候，都需要加上一个Load Barriers。 那么我们该如何理解它呢?看下面的代码，第一行代码我们尝试读取堆中的一个对象引用obj.fieldA并赋给引用 o(fieldA也是一个对象时才会加上读屏障)。如果这时候对象在GC时被移动了，接下来JVM就会加上一个读屏障，这个屏障会把读出的指针更新到对象的新地址上，并且把堆里的这个指针“修正”到原本的字段里。这样就算GC把对象移动了，读屏障也会发现并修正指针，于是应用代码就永远都会持有更新后的有效指针，而且不需要STW。 JVM是如何判断对象被移动过呢?就是利用上面提到的颜色指针，如果指针是Bad Color，那么程序还不能往下执行，需要「slow path」，修正指针;如果指针是Good Color，那么正常往下执行即可: 这个动作是不是非常像JDK并发中用到的CAS自旋?读取的值发现已经失效了，需要重新读取。而ZGC这里是之前持有的指针由于GC后失效了，需要通过读屏障修正指针。后面3行代码都不需要加读屏障: Object p = o这行代码并没有从堆中读取数据; o.doSomething()也没有从堆中读取数据; obj.fieldB不是对象引用，而是原子类型。 正是因为Load Barriers的存在，所以会导致配置ZGC的应用的吞吐量会变低。官方的测试数据是需要多出额外4%的开销: 判断对象是Bad Color还是Good Color的依据是什么呢?就是根据上一段提到的Colored Pointers的4个颜色位。 当加上读屏障时，根据对象指针中这4位的信息，就能知道当前对象是Bad/Good Color了。 PS:既然低42位指针可以支持4T内存，那么能否通过预约更多位给对象地址来达到支持更大内存的目的呢?答案肯定是 不可以。因为目前主板地址总线最宽只有48bit，4位是颜色位，就只剩44位了，所以受限于目前的硬件，ZGC最大只能支持16T的内存，JDK13就把最大支持堆内存从4T扩大到了16T。 ZGC运作过程ZGC的运作过程大致可划分为以下四个大的阶段: 并发标记(Concurrent Mark) 与G1一样，并发标记是遍历对象图做可达性分析的阶段，它的初始标记 (Mark Start)和最终标记(Mark End)也会出现短暂的停顿，与G1不同的是， ZGC的标记是在指针上而不是在对象上进行的， 标记阶段会更新染色指针中的Marked 0、 Marked 1标志位。 并发预备重分配(Concurrent Prepare for Relocate) 这个阶段需要根据特定的查询条件统计得出本次收集过程要清理哪些Region，将这些Region组成重分配集(Relocation Set)。ZGC每次回收都会扫描所有的 Region，用范围更大的扫描成本换取省去G1中记忆集的维护成本。 并发重分配(Concurrent Relocate) 重分配是ZGC执行过程中的核心阶段，这个过程要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表(Forward Table)，记录从旧对象 到新对象的转向关系。ZGC收集器能仅从引用上就明确得知一个对象是否处于重分配集之中，如果用户线程此时并发访问了位于重分配集中的对象，这次访问将会被预置的内存屏障(读屏障)所截获，然后立即根据Region上的转发表记录将访问转发到新复制的对象上，并同时修正更新该引用的值，使其直接指向新对象，ZGC将这种行为称为指针的“自愈”(Self-Healing)能力。 并发重映射(Concurrent Remap):重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，但是ZGC中对象引用存在“自愈”功能，所以这个重映射操作并不是很迫切。ZGC很巧妙地把并发重映射阶段要做的工作，合并到了下一次垃圾收集循环中的并发标记阶段里去完成，反正它们都是要遍历所有对象的，这样合并就节省了一次遍历对象图的开销。一旦所有指针都被修正之后， 原来记录新旧对象关系的转发表就可以释放掉了。 ZGC存在的问题ZGC最大的问题是浮动垃圾。ZGC的停顿时间是在10ms以下，但是ZGC的执行时间还是远远大于这个时间的。假如ZGC全过程需要执行10分钟，在这个期间由于对象分配速率很高，将创建大量的新对象，这些对象很难进入当次GC，所以只能在下次GC的时候进行回收，这些只能等到下次GC才能回收的对象就是浮动垃圾。 ZGC没有分代概念，每次都需要进行全堆扫描，导致一些“朝生夕死”的对象没能及时的被回收。 解决方案目前唯一的办法是增大堆的容量，使得程序得到更多的喘息时间，但是这个也是一个治标不治本的方案。如果需要从根本上解决这个问题，还是需要引入分代收集，让新生对象都在一个专门的区域中创建，然后专门针对这个区域进行更频繁、更快的收集。 ZGC参数设置启用ZGC比较简单，设置JVM参数即可:-XX:+UnlockExperimentalVMOptions 「-XX:+UseZGC」。调优也并不难， 因为ZGC调优参数并不多，远不像CMS那么复杂。它和G1一样，可以调优的参数都比较少，大部分工作JVM能很好的自 动完成。下图所示是ZGC可以调优的参数: ZGC触发时机ZGC目前有4中机制触发GC 定时触发，默认为不使用，可通过ZCollectionInterval参数配置。 预热触发，最多三次，在堆内存达到10%、20%、30%时触发，主要时统计GC时间，为其他GC机制使用。 分配速率，基于正态分布统计，计算内存99.9%可能的最大分配速率，以及此速率下内存将要耗尽的时间点，在耗尽之前触发GC(耗尽时间 - 一次GC最大持续时间 - 一次GC检测周期时间)。 主动触发，(默认开启，可通过ZProactive参数配置) 距上次GC堆内存增长10%，或超过5分钟时，对比距上次GC的间隔时间跟(49 * 一次GC的最大持续时间)，超过则触发。 如何选择垃圾收集器 优先调整堆的大小让服务器自己来选择 如果内存小于100M，使用串行收集器 如果是单核，并且没有停顿时间的要求，串行或JVM自己选择 如果允许停顿时间超过1秒，选择并行或者JVM自己选 如果响应时间最重要，并且不能超过1秒，使用并发收集器 4G以下可以用parallel，4-8G可以用ParNew+CMS，8G以上可以用G1，几百G以上用ZGC 下图有连线的可以搭配使用 安全点与安全区域安全点就是指代码中一些特定的位置,当线程运行到这些位置时它的状态是确定的,这样JVM就可以安全的进行一些操作,比如GC等，所以GC不是想什么时候做就立即触发的，是需要等待所有线程运行到安全点后才能触发。 这些特定的安全点位置主要有以下几种: 方法返回之前 调用某个方法之后 抛出异常的位置 循环的末尾 大体实现思想是当垃圾收集需要中断线程的时候， 不直接对线程操作， 仅仅简单地设置一个标志位， 各个线程执行过程 时会不停地主动去轮询这个标志， 一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。 轮询标志的地方和安全点是重合的。 安全区域Safe Point 是对正在执行的线程设定的。如果一个线程处于 Sleep 或中断状态，它就不能响应 JVM 的中断请求，再运行到 Safe Point 上。因此 JVM 引入了 Safe Region。Safe Region 是指在一段代码片段中，引用关系不会发生变化。在这个区域内的任意地方开始 GC 都是安全的。","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tj-ever.github.io/tags/JVM/"}]},{"title":"JVM 内存结构","slug":"JVM 内存结构","date":"2021-08-23T16:00:00.000Z","updated":"2021-09-06T06:52:05.304Z","comments":true,"path":"2021/08/24/JVM 内存结构/","link":"","permalink":"https://tj-ever.github.io/2021/08/24/JVM%20%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/","excerpt":"","text":"整体结构及内存模型JVM内存结构主要有三大块：堆内存、方法区和栈。堆内存是JVM中最大的一块由年轻代和老年代组成，而年轻代内存又被分成三部分，Eden空间、From Survivor空间、To Survivor空间,默认情况下年轻代按照8:1:1的比例来分配； 方法区存储类信息、常量、静态变量等数据，是线程共享的区域，为与Java堆区分，方法区还有一个别名Non-Heap(非堆)； 栈又分为java虚拟机栈和本地方法栈主要用于方法的执行。 Java堆（Heap） 对于大多数应用来说，Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC堆”。如果从内存回收的角度看，由于现在收集器基本都是采用的分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点的有Eden空间、From Survivor空间、To Survivor空间等。 根据Java虚拟机规范的规定，Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像我们的磁盘空间一样。在实现时，既可以实现成固定大小的，也可以是可扩展的，不过当前主流的虚拟机都是按照可扩展来实现的（通过-Xmx和-Xms控制）。 如果在堆中没有内存完成实例分配，并且堆也无法再扩展时，将会抛出OutOfMemoryError异常。 方法区（Method Area） 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做Non-Heap（非堆），目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发和部署程序的开发者来说，很多人愿意把方法区称为“永久代”（Permanent Generation），本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。 Java虚拟机规范对这个区域的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是有必要的。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 方法区有时被称为持久代（PermGen）。 程序计数器（Program Counter Register） 程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器（对于多核处理器来说是一个内核）只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间的计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。 此内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 JVM栈（JVM Stacks） 与程序计数器一样，Java虚拟机栈（Java Virtual Machine Stacks）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它不等同于对象本身，根据不同的虚拟机实现，它可能是一个指向对象起始地址的引用指针，也可能指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。 其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分的Java虚拟机都可动态扩展，只不过Java虚拟机规范中也允许固定长度的虚拟机栈），当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。 本地方法栈（Native Method Stacks） 本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。虚拟机规范中对本地方法栈中的方法使用的语言、使用方式与数据结构并没有强制规定，因此具体的虚拟机可以自由实现它。甚至有的虚拟机（譬如Sun HotSpot虚拟机）直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。 所有的对象在实例化后的整个运行周期内，都被存放在堆内存中。堆内存又被划分成不同的部分：伊甸区(Eden)，幸存者区域(Survivor Sapce)，老年代（Old Generation Space）。 方法的执行都是伴随着线程的。原始类型的本地变量以及引用都存放在线程栈中。而引用关联的对象比如String，都存在在堆中。为了更好的理解上面这段话，我们可以看一个例子： 1234567891011121314import java.text.SimpleDateFormat;import java.util.Date;import org.apache.log4j.Logger;public class HelloWorld &#123; private static Logger LOGGER = Logger.getLogger(HelloWorld.class.getName()); public void sayHello(String message) &#123; SimpleDateFormat formatter = new SimpleDateFormat(&quot;dd.MM.YYYY&quot;); String today = formatter.format(new Date()); LOGGER.info(today + &quot;: &quot; + message); &#125; &#125; 这段程序的数据在内存中的存放如下： 内存参数设置 控制参数 -Xms设置堆的最小空间大小。 -Xmx设置堆的最大空间大小。 -XX:NewSize设置新生代最小空间大小。 -XX:MaxNewSize设置新生代最大空间大小。 -XX:PermSize设置永久代最小空间大小。 -XX:MaxPermSize设置永久代最大空间大小。 -Xss设置每个线程的堆栈大小。 老年代空间大小=堆空间大小-年轻代大空间大小 没有直接设置老年代的参数，但是可以设置堆空间大小和新生代空间大小两个参数来间接控制。 Spring Boot程序的JVM参数设置格式(Tomcat启动直接加在bin目录下catalina.sh文件里): 1java ‐Xms2048M ‐Xmx2048M ‐Xmn1024M ‐Xss512K ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M ‐jar microservice‐eurek a‐server.jar 关于元空间的JVM参数有两个:-XX:MetaspaceSize=N和 -XX:MaxMetaspaceSize=N -XX:MaxMetaspaceSize: 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存大小。 -XX:MetaspaceSize: 指定元空间触发Full gc的初始阈值(元空间无固定初始大小)， 以字节为单位，默认是21M，达到该值就会触发 full gc进行类型卸载， 同时收集器会对该值进行调整: 如果释放了大量的空间， 就适当降低该值; 如果释放了很少的空间， 那么在不超过-XX:MaxMetaspaceSize 的情况下，适当提高该值。这个跟早期jdk版本的-XX:PermSize参数意思不一样，- XX:PermSize代表永久代的初始容量。由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生 了大小调整，基于这种情况，一般建议在JVM参数中将MetaspaceSize和MaxMetaspaceSize设置成一样的值，并设置得比初始值要大， 对于8G物理内存的机器来说，一般我会将这两个值都设置为256M。 StackOverflowError示例: 123456789101112131415161718192021222324// JVM设置 ‐Xss128k(默认1M) public class StackOverflowTest&#123; static int count = 0; static void redo() &#123; count++; redo(); &#125; public static void main(String[] args) &#123; try&#123; redo(); &#125; catch (Throwable t) &#123; t.printStackTrace(); System.out.println(count); &#125; &#125; &#125;//运行结果://java.lang.StackOverflowError//at com.tuling.jvm.StackOverflowTest.redo(StackOverflowTest.java:12)//at com.tuling.jvm.StackOverflowTest.redo(StackOverflowTest.java:13)//at com.tuling.jvm.StackOverflowTest.redo(StackOverflowTest.java:13)//...... 结论: -Xss设置越小count值越小，说明一个线程栈里能分配的栈帧就越少，但是对JVM整体来说能开启的线程数会更多 对象结构java对象由如下几部分组成： 对象头：Mark word和klasspointer两部分组成，如果是数组，还包括数组长度 实例属性 对齐填充 如何能看到上图结构？ 注意：要打印上述内存结构图，需要引入如下依赖： 123456&lt;!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt; &lt;/dependency&gt; 对象头HotSpot虚拟机的对象头包括两部分信息。 第一部分用于存储对象自身的运行时数据， 如哈希码(HashCode)、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。 对象头的另外一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 如果是数组，还包括数组长度 注意：JVM会默认使用选项 +UseCompressedOops 开启指针压缩，将指针压缩至32位。 对象属性数据区 对齐填充区Java对象占用空间是8字节对齐的，即所有Java对象占用字节数必须是8的倍数。如下图所示： 对象创建流程 类加载检查虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。 new指令对应到语言层面上讲是，new关键词、对象克隆、对象序列化等。 分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需内存的大小在类 加载完成后便可完全确定，为对象分配空间的任务等同于把 一块确定大小的内存从Java堆中划分出来。 这个步骤有两个问题: 1.如何划分内存。 2.在并发情况下， 可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。 划分内存指针碰撞“指针碰撞”(Bump the Pointer)(默认用指针碰撞) 如果Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离。 空闲列表“空闲列表”(Free List)如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例， 并更新列表上的记录 解决并发CASCAS(compare and swap) 虚拟机采用CAS配上失败重试的方式保证更新操作的原子性来对分配内存空间的动作进行同步处理。 本地线程分配缓冲本地线程分配缓冲(Thread Local Allocation Buffer,TLAB)，把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存。通过­XX:+/­ UseTLAB参数来设定虚拟机是否使用TLAB(JVM会默认开启­XX:+UseTLAB)，­XX:TLABSize 指定TLAB大小。 初始化内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值(不包括对象头)， 如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 设置对象头初始化零值之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息。这些信息存放在对象的对象头Object Header之中。 执行init方法 执行方法，即对象按照程序员的意愿进行初始化。对应到语言层面上讲，就是为属性赋值(注意，这与上面的赋零值不同，这是由程序员赋的值)，和执行构造方法。 指针压缩jdk1.6 update14开始，在64bit操作系统中，JVM支持指针压缩 jvm配置参数:UseCompressedOops，compressed­­压缩、oop(ordinary object pointer)­­对象指针 启用指针压缩:­XX:+UseCompressedOops(默认开启)，禁止指针压缩:­XX:­-UseCompressedOops 为什么要进行指针压缩 在64位平台的HotSpot中使用32位指针，内存使用会多出1.5倍左右，使用较大指针在主内存和缓存之间移动数据， 占用较大宽带，同时GC也会承受较大压力，为了减少64位平台下内存的消耗，启用指针压缩功能 在jvm中，32位地址最大支持4G内存(2的32次方)，可以通过对对象指针的压缩编码、解码方式进行优化，使得jvm 只用32位地址就可以支持更大的内存配置(小于等于32G) 堆内存小于4G时，不需要启用指针压缩，jvm会直接去除高32位地址，即使用低虚拟地址空间 堆内存大于32G时，压缩指针会失效，会强制使用64位(即8字节)来对java对象寻址，这就会出现1的问题，所以堆内存不要大于32G为好 对象内存分配 对象栈上分配通过JVM内存分配可以知道JAVA中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠GC进行回收内存，如果对象数量较多的时候，会给GC带来较大压力，也间接影响了应用的性能。 为了减少临时对象在堆内分配的数量，JVM通过逃逸分析确定该对象不会被外部访问。如果不会逃逸可以将该对象在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。 对象逃逸分析就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。 1234567891011121314public User test1()&#123; User user = new User(); user.setId(1); user.setName(&quot;zhuge&quot;); //TODO 保存到数据库 return user;&#125;public void test2()&#123; User user = new User(); user.setId(1); user.setName(&quot;zhuge&quot;); //TODO 保存到数据库&#125; 很显然test1方法中的user对象被返回了，这个对象的作用域范围不确定，test2方法中的user对象我们可以确定当方法结束这个对象就可以认为是无效对象了，对于这样的对象我们其实可以将其分配在栈内存里，让其在方法结束时跟随栈内 存一起被回收掉。 JVM对于这种情况可以通过开启逃逸分析参数(-XX:+DoEscapeAnalysis)来优化对象内存分配位置，使其通过标量替换优先分配在栈上(栈上分配)。JDK7之后默认开启逃逸分析，如果要关闭使用参数(-XX:-DoEscapeAnalysis) 标量替换通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配。 开启标量替换参数(-XX:+EliminateAllocations)，JDK7之后默认 开启。 标量与聚合量标量即不可被进一步分解的量，而JAVA的基本数据类型就是标量(如:int，long等基本数据类型以及 reference类型等)，标量的对立就是可以被进一步分解的量，而这种量称之为聚合量。而在JAVA中对象就是可以被进一 步分解的聚合量。 栈上分配示例123456789101112131415161718192021222324/*** 栈上分配，标量替换 代码调用了1亿次alloc()，如果是分配到堆上，大概需要1GB以上堆空间，如果堆空间小于该值，必然会触发GC。* 使用如下参数不会发生GC* ‐Xmx15m ‐Xms15m ‐XX:+DoEscapeAnalysis ‐XX:+PrintGC ‐XX:+EliminateAllocations* 使用如下参数都会发生大量GC* ‐Xmx15m ‐Xms15m ‐XX:‐DoEscapeAnalysis ‐XX:+PrintGC ‐XX:+EliminateAllocations* ‐Xmx15m ‐Xms15m ‐XX:+DoEscapeAnalysis ‐XX:+PrintGC ‐XX:‐EliminateAllocations*/public class AllotOnStack&#123; public static void main(String[] args) &#123; long start = System.currentTimeMillis(); for (int i = 0; i &lt; 100000000; i++) &#123; alloc(); &#125; long end = System.currentTimeMillis(); System.out.println(end ‐ start); &#125; private static void alloc() &#123; User user = new User(); user.setId(1); user.setName(&quot;zhuge&quot;); &#125;&#125; 结论:栈上分配依赖于逃逸分析和标量替换 对象在Eden区分配 大多数情况下，对象在新生代中 Eden 区分配。当 Eden 区没有足够空间进行分配时，虚拟机将发起一次Minor GC。 Minor GC/Young GC:指发生新生代的的垃圾收集动作，Minor GC非常频繁，回收速度一般也比较快。 Major GC/Full GC:一般会回收老年代 ，年轻代，方法区的垃圾，Major GC的速度一般会比Minor GC的慢 10倍以上。 Eden与Survivor区默认8:1:1 大量对象被分配在eden区，eden区满了后会触发minor gc，可能会有99%以上的对象成为垃圾被回收掉，剩余存活的对象会被挪到为空的那块survivor区，下一次eden区满了后又会触发minor gc，把eden区和survivor区垃圾对象回收，把剩余存活的对象一次性挪动到另外一块为空的survivor区，因为新生代的对象都是朝生夕死的，存活时间很短，所以JVM默认的8:1:1的比例是很合适的，让eden区尽量的大，survivor区够用即可。 JVM默认有这个参数-XX:+UseAdaptiveSizePolicy(默认开启)，会导致这个8:1:1比例自动变化，如果不想这个比例有变化可以设置参数 -XX:-UseAdaptiveSizePolicy 示例： 123456789101112131415161718192021222324//添加运行JVM参数: ‐XX:+PrintGCDetails public class GCTest&#123; public static void main(String[] args) throws InterruptedException &#123; byte[] allocation1, allocation2/*, allocation3, allocation4, allocation5, allocation6*/; allocation1 = new byte[60000*1024]; //allocation2 = new byte[8000*1024]; /*allocation3 = new byte[1000*1024]; allocation4 = new byte[1000*1024]; allocation5 = new byte[1000*1024]; allocation6 = new byte[1000*1024]; */ &#125;&#125;运行结果:Heap PSYoungGen total 76288K, used 65536K [0x000000076b400000, 0x0000000770900000, 0x00000007c0000000) eden space 65536K, 100% used [0x000000076b400000,0x000000076f400000,0x000000076f400000) from space 10752K, 0% used [0x000000076fe80000,0x000000076fe80000,0x0000000770900000) to space 10752K, 0% used [0x000000076f400000,0x000000076f400000,0x000000076fe80000) ParOldGen total 175104K, used 0K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000) object space 175104K, 0% used [0x00000006c1c00000,0x00000006c1c00000,0x00000006cc700000) Metaspace used 3342K, capacity 4496K, committed 4864K, reserved 1056768K class space used 361K, capacity 388K, committed 512K, reserved 1048576K 可以看出eden区内存几乎已经被分配完全(即使程序什么也不做，新生代也会使用至少几M内存)。假如再为 allocation2分配内存会出现什么情况呢? 123456789101112131415161718192021222324252627//添加运行JVM参数: ‐XX:+PrintGCDetails public class GCTest&#123; public static void main(String[] args) throws InterruptedException &#123; byte[] allocation1, allocation2/*, allocation3, allocation4, allocation5, allocation6*/; allocation1 = new byte[60000*1024]; allocation2 = new byte[8000*1024]; /*allocation3 = new byte[1000*1024]; allocation4 = new byte[1000*1024]; allocation5 = new byte[1000*1024]; allocation6 = new byte[1000*1024]; */ &#125;&#125;运行结果:[GC(AllocationFailure)[PSYoungGen:65253K‐&gt;936K(76288K)]65253K‐&gt;60944K(251392K),0.0279083secs][Times:user=0.13 sys=0.02, real=0.03 secs]Heap PSYoungGen total 76288K, used 9591K [0x000000076b400000, 0x0000000774900000, 0x00000007c0000000) eden space 65536K, 13% used [0x000000076b400000,0x000000076bc73ef8,0x000000076f400000) from space 10752K, 8% used [0x000000076f400000,0x000000076f4ea020,0x000000076fe80000) to space 10752K, 0% used [0x0000000773e80000,0x0000000773e80000,0x0000000774900000) ParOldGen total 175104K, used 60008K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000) object space 175104K, 34% used [0x00000006c1c00000,0x00000006c569a010,0x00000006cc700000) Metaspace used 3342K, capacity 4496K, committed 4864K, reserved 1056768K class space used 361K, capacity 388K, committed 512K, reserved 1048576K 给allocation2分配内存的时候eden区内存几乎已经被分配完了，当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC，GC期间虚拟机又发现allocation1无法存入 Survior空间，所以只好把新生代的对象提前转移到老年代中去，老年代上的空间足够存放allocation1，所以不会出现 Full GC。执行Minor GC后，后面分配的对象如果能够存在eden区的话，还是会在eden区分配内存。 可以执行如下代码验证: 12345678910111213141516171819202122232425//添加运行JVM参数: ‐XX:+PrintGCDetails public class GCTest&#123; public static void main(String[] args) throws InterruptedException &#123; byte[] allocation1, allocation2/*, allocation3, allocation4, allocation5, allocation6*/; allocation1 = new byte[60000*1024]; allocation2 = new byte[8000*1024]; allocation3 = new byte[1000*1024]; allocation4 = new byte[1000*1024]; allocation5 = new byte[1000*1024]; allocation6 = new byte[1000*1024]; &#125;&#125;运行结果:[GC(AllocationFailure)[PSYoungGen:65253K‐&gt;952K(76288K)]65253K‐&gt;60960K(251392K),0.0311467secs][Times: user=0.08 sys=0.02, real=0.03 secs]Heap PSYoungGen total 76288K, used 13878K [0x000000076b400000, 0x0000000774900000, 0x00000007c0000000) eden space 65536K, 19% used [0x000000076b400000,0x000000076c09fb68,0x000000076f400000) from space 10752K, 8% used [0x000000076f400000,0x000000076f4ee030,0x000000076fe80000) to space 10752K, 0% used [0x0000000773e80000,0x0000000773e80000,0x0000000774900000) ParOldGen total 175104K, used 60008K [0x00000006c1c00000, 0x00000006cc700000, 0x000000076b400000) object space 175104K, 34% used [0x00000006c1c00000,0x00000006c569a010,0x00000006cc700000) Metaspace used 3343K, capacity 4496K, committed 4864K, reserved 1056768K class space used 361K, capacity 388K, committed 512K, reserved 1048576K 大对象直接进入老年代大对象就是需要大量连续内存空间的对象(比如:字符串、数组)。 JVM参数 -XX:PretenureSizeThreshold 可以设置大对象的大小，如果对象超过设置大小会直接进入老年代，不会进入年轻代，这个参数只在 Serial 和ParNew两个收集器下有效。 比如设置JVM参数:-XX:PretenureSizeThreshold=1000000 (单位是字节) -XX:+UseSerialGC ，再执行下上面的第一个程序会发现大对象直接进了老年代 为什么要这样呢?为了避免为大对象分配内存时的复制操作而降低效率。 长期存活的对象将进入老年代虚拟机采用了分代收集的思想来管理内存，内存回收时就必须能识别哪些对象应放在新生代，哪些对象应放在老年代中，为了做到这一点，虚拟机给每个对象一个对象年龄(Age)计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1。对象在 Survivor 中每熬过一次 MinorGC，年龄就增加1岁，当它的年龄增加到一定程度 (默认为15岁，CMS收集器默认6岁，不同的垃圾收集器会略微有点不同)，就会被晋升到老年代中。 对象晋升到老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold来设置。 对象动态年龄判断当前放对象的Survivor区域里，一批对象的总大小大于这块Survivor区域内存大小的 50%(-XX:TargetSurvivorRatio可以指定)，那么此时大于等于这批对象年龄最大值的对象，就可以直接进入老年代了。 例如Survivor区域里现在有一批对象，年龄1+年龄2+年龄n的多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n(含)以上的对象都放入老年代。这个规则其实是希望那些可能是长期存活的对象，尽早进入老年代。对象动态年龄判断机制一般是在minor gc之后触发的。 老年代空间分配担保机制年轻代每次minor gc之前JVM都会计算下老年代剩余可用空间 ，如果这个可用空间小于年轻代里现有的所有对象大小之和(包括垃圾对象) ，就会看一个-XX:-HandlePromotionFailure(jdk1.8默认就设置了)的参数是否设置了 。 如果有这个参数，就会看看老年代的可用内存大小，是否大于之前每一次minor gc后进入老年代的对象的平均大小。 如果上一步结果是小于或者之前说的参数没有设置，那么就会触发一次Full gc，对老年代和年轻代一起回收一次垃圾， 如果回收完还是没有足够空间存放新的对象就会发生”OOM” 当然，如果minor gc之后剩余存活的需要挪动到老年代的对象大小还是大于老年代可用空间，那么也会触发full gc，full gc完之后如果还是没有空间放minor gc之后的存活对象，则也会发生“OOM” 对象内存回收堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断哪些对象已经死亡(即不能再被任何途径使用的对象) 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1;当引用失效，计数器就减1;任何时候计数器为0 的对象就是不可能再被使用的。 这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，如下面代码所示:除了对象objA 和 objB 相互引用着对 方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为0，于是引用计数算 法无法通知 GC 回收器回收他们。 1234567891011public class ReferenceCountingGc&#123; Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGc objA = new ReferenceCountingGc(); ReferenceCountingGc objB = new ReferenceCountingGc(); objA.instance = objB; objB.instance = objA; objA = null; objB = null; &#125;&#125; 可达性分析算法将“GC Roots” 对象作为起点，从这些节点开始向下搜索引用的对象，找到的对象都标记为非垃圾对象，其余未标记的对象都是垃圾对象。 GC Roots根节点:线程栈的本地变量、静态变量、本地方法栈的变量等等 常见引用类型java的引用类型一般分为四种:强引用、软引用、弱引用、虚引用 强引用: 普通的变量引用 public static User user=new User(); 软引用 将对象用SoftReference软引用类型的对象包裹，正常情况不会被回收，但是GC做完后发现释放不出空间存放 新的对象，则会把这些软引用的对象回收掉。软引用可用来实现内存敏感的高速缓存。 1public static SoftReference&lt;User&gt; user = new SoftReference&lt;User&gt;(newUser()); 弱引用 将对象用WeakReference软引用类型的对象包裹，弱引用跟没引用差不多，GC会直接回收掉，很少用 1public static WeakReference&lt;User&gt;user=newWeakReference&lt;User&gt;(newUser()); 虚引用 虚引用也称为幽灵引用或者幻影引用，它是最弱的一种引用关系，几乎不用 finalize()finalize()方法最终判定对象是否存活 即使在可达性分析算法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历再次标记过程。 标记的前提是对象在进行可达性分析后发现没有与GC Roots相连接的引用链。 第一次标记并进行一次筛选。 筛选的条件是此对象是否有必要执行finalize()方法。当对象没有覆盖finalize方法，对象将直接被回收。 第二次标记 如果这个对象覆盖了finalize方法，finalize方法是对象脱逃死亡命运的最后一次机会，如果对象要在finalize()中成功拯救自己，只要重新与引用链上的任何的一个对象建立关联即可，譬如把自己赋值给某个类变量或对象的成员变量，那在第二次标记时它将移除出“即将回收”的集合。如果对象这时候还没逃脱，那基本上它就真的被回收了。 注意:一个对象的finalize()方法只会被执行一次，也就是说通过调用finalize方法自我救命的机会就一次。 判断一个类是无用的类方法区主要回收的是无用的类，那么如何判断一个类是无用的类的呢 类需要同时满足下面3个条件才能算是 “无用的类” : 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tj-ever.github.io/tags/JVM/"}]},{"title":"JVM 类加载机制","slug":"JVM 类加载&双亲委派","date":"2021-08-23T16:00:00.000Z","updated":"2021-08-24T06:24:45.257Z","comments":true,"path":"2021/08/24/JVM 类加载&双亲委派/","link":"","permalink":"https://tj-ever.github.io/2021/08/24/JVM%20%E7%B1%BB%E5%8A%A0%E8%BD%BD&%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE/","excerpt":"","text":"什么是类的加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 类加载 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误（LinkageError错误）。如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 加载.class文件的方式 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 类的生命周期 类的生命周期 其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定（也成为动态绑定或晚期绑定）。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 加载查找并加载类的二进制数据。加载是类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段（准确地说，是加载阶段获取类的二进制字节流的动作）是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 验证确保被加载的类的正确性 验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备为类的静态变量分配内存，并将其初始化为默认值 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意： 1、这时候进行内存分配的仅包括类变量（static），而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 2、这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式地赋予的值。 假设一个类变量的定义为：public static int value = 3; 那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的public static指令是在程序编译后，存放于类构造器&lt;clinit&gt;()方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。 这里还需要注意如下几点： 对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。 3、如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。 假设上面的类变量value被定义为： public static final int value = 3； 编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中 解析把类中的符号引用转换为直接引用 解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。 符号引用就是一组符号来描述目标，可以是任何字面量。 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式： ①声明类变量时指定初始值 ②使用静态代码块为类变量指定初始值 JVM初始化步骤 1、假如这个类还没有被加载和连接，则程序先加载并连接该类 2、假如该类的直接父类还没有被初始化，则先初始化其直接父类 3、假如类中有初始化语句，则系统依次执行这些初始化语句 类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种： 创建类的实例，也就是new的方式 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（如Class.forName(“com.shengsiyuan.Test”)） 初始化某个类的子类，则其父类也会被初始化 Java虚拟机启动时被标明为启动类的类（Java Test），直接使用java.exe命令来运行某个主类 结束生命周期在如下几种情况下，Java虚拟机将结束生命周期： 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载器1234567891011121314package com.neo.classloader;public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println(loader); System.out.println(loader.getParent()); System.out.println(loader.getParent().getParent()); &#125;&#125;//运行后，输出结果：//sun.misc.Launcher$AppClassLoader@64fef26a//sun.misc.Launcher$ExtClassLoader@1ddd40f3//null 从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是Bootstrap Loader（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。 这几种类加载器的层次关系如下图所示： 类加载器的层次关系 注意：这里父类加载器并不是通过继承关系来实现的，而是采用组合实现的。 站在Java虚拟机的角度来讲，只存在两种不同的类加载器： 启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分； 其它的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。 扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 1、在执行非置信代码之前，自动验证数字签名。 2、动态地创建符合用户特定需要的定制化构建类。 3、从特定的场所取得java class，例如数据库中和网络中。 JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 类的加载类加载有三种方式： 1、命令行启动应用时候由JVM初始化加载 2、通过Class.forName()方法动态加载 3、通过ClassLoader.loadClass()方法动态加载 123456789101112131415package com.neo.classloader;public class LoaderTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; ClassLoader loader = Test2.class.getClassLoader(); System.out.println(loader); //使用ClassLoader.loadClass()来加载类，不会执行初始化块 loader.loadClass(&quot;Test2&quot;); //使用Class.forName()来加载类，默认会执行初始化块 //Class.forName(&quot;Test2&quot;); //使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块 //Class.forName(&quot;Test2&quot;, false, loader); &#125; &#125; demo类 12345public class Test2 &#123; static &#123; System.out.println(&quot;静态初始化块执行了！&quot;); &#125; &#125; 分别切换加载方式，会有不同的输出结果。 Class.forName()和ClassLoader.loadClass()区别 Class.forName()：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块。 ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容，只有在newInstance时才会去执行static块。 Class.forName(name, initialize, loader)：带参函数可控制是否加载static块。initialize为true时加载，为false时不加载。 双亲委派机制一个类加载器示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class TestJDKClassLoader&#123; public static void main(String[] args) &#123; System.out.println(String.class.getClassLoader()); System.out.println(com.sun.crypto.provider.DESKeyFactory.class.getClassLoader().getClass().getName()); System.out.println(TestJDKClassLoader.class.getClassLoader().getClass().getN ame()); System.out.println(); ClassLoader appClassLoader = ClassLoader.getSystemClassLoader(); ClassLoader extClassloader = appClassLoader.getParent(); ClassLoader bootstrapLoader = extClassloader.getParent(); System.out.println(&quot;the bootstrapLoader : &quot; + bootstrapLoader); System.out.println(&quot;the extClassloader : &quot; + extClassloader); System.out.println(&quot;the appClassLoader : &quot; + appClassLoader); System.out.println(); System.out.println(&quot;bootstrapLoader加载以下文件:&quot;); URL[] urls = Launcher.getBootstrapClassPath().getURLs(); for (int i = 0; i &lt; urls.length; i++) &#123; System.out.println(urls[i]); &#125; System.out.println(); System.out.println(&quot;extClassloader加载以下文件:&quot;); System.out.println(System.getProperty(&quot;java.ext.dirs&quot;)); System.out.println(); System.out.println(&quot;appClassLoader加载以下文件:&quot;); System.out.println(System.getProperty(&quot;java.class.path&quot;)); &#125; &#125;//运行结果:nullsun.misc.Launcher$ExtClassLoadersun.misc.Launcher$AppClassLoader the bootstrapLoader:null theextClassloader:sun.misc.Launcher$ExtClassLoader@3764951dthe appClassLoader:sun.misc.Launcher$AppClassLoader@14dad5dcbootstrapLoader加载以下文件: file:/D:/dev/Java/jdk1.8.0_45/jre/lib/resources.jar file:/D:/dev/Java/jdk1.8.0_45/jre/lib/rt.jar file:/D:/dev/Java/jdk1.8.0_45/jre/lib/sunrsasign.jar file:/D:/dev/Java/jdk1.8.0_45/jre/lib/jsse.jarfile:/D:/dev/Java/jdk1.8.0_45/jre/lib/jce.jar file:/D:/dev/Java/jdk1.8.0_45/jre/lib/charsets.jar file:/D:/dev/Java/jdk1.8.0_45/jre/lib/jfr.jar file:/D:/dev/Java/jdk1.8.0_45/jre/classes extClassloader加载以下文件:D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\ext;C:\\Windows\\Sun\\Java\\lib\\extappClassLoader加载以下文件:(全部加载)D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\charsets.jar;D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\deploy.jar;D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\ext\\access‐bridge‐64.jar;D:\\dev\\Jav\\jdk1.8.0_45\\jre\\lib\\ext\\cldrdata.jar;D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\ext\\dnsns.jar;D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\ext\\jaccess.jar;D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\ext\\jfxrt.jar;D:\\dev\\Java\\jdk1.8.0_45\\jre\\lib\\ext\\localedata.jar;......C:\\Users\\zhuge\\.m2\\repository\\netty\\netty\\3.10.6.Final\\netty‐3.10.6.Final.jar;C:\\Users\\zhuge\\.m2\\repository\\com\\google\\j2objc\\j2objc‐annotations\\1.1\\jobjc‐annotations‐1.1.jar;D:\\dev\\IntelliJ IDEA 2018.3.2\\lib\\idea_rt.jar 类加载器初始化过程JVM启动会创建实例sun.misc.Launcher。 sun.misc.Launcher初始化使用了单例模式设计，保证一个JVM虚拟机内只有一个 sun.misc.Launcher实例。在Launcher构造方法内部，其创建了两个类加载器，分别是 sun.misc.Launcher.ExtClassLoader(扩展类加载器)和sun.misc.Launcher.AppClassLoader(应用类加载器)。 JVM默认使用Launcher的getClassLoader()方法返回的类加载器AppClassLoader的实例加载我们的应用程序。 1234567891011121314151617181920212223//Launcher的构造方法 public Launcher()&#123; Launcher.ExtClassLoader var1; try&#123; //构造扩展类加载器，在构造的过程中将其父加载器设置为null var1 = Launcher.ExtClassLoader.getExtClassLoader(); &#125; catch (IOException var10) &#123; throw new InternalError(&quot;Could not create extension class loader&quot;, var10); &#125; try&#123; //构造应用类加载器，在构造的过程中将其父加载器设置为ExtClassLoader， //Launcher的loader属性值是AppClassLoader，我们一般都是用这个类加载器来加载我们自己写的应用程序 this.loader = Launcher.AppClassLoader.getAppClassLoader(var1); &#125; catch (IOException var9) &#123; throw new InternalError(&quot;Could not create application class loader&quot;, var9); &#125; Thread.currentThread().setContextClassLoader(this.loader); String var2 = System.getProperty(&quot;java.security.manager&quot;); // 。。。 。。。 省略一些不需关注代码&#125; JVM类加载器是有亲子结构的 这里类加载其实就有一个双亲委派机制，加载某个类时会先委托父加载器寻找目标类，找不到再委托上层父加载器加载，如果所有父加载器在自己的加载类路径下都找不到目标类，则在自己的类加载路径中查找并载入目标类。 比如我们自己写的DTO类，最先会找应用程序类加载器加载，应用程序类加载器会先委托扩展类加载器加载，扩展类加载器再委托引导类加载器，顶层引导类加载器在自己的类加载路径里找了半天没找到DTO类，则向下退回加载DTO类的请求，扩展类加载器收到回复就自己加载，在自己的类加载路径里找了半天也没找到DTO类，又向下退回DTO类的加载请求给应用程序类加载器， 应用程序类加载器于是在自己的类加载路径里找DTO类，结果找到了就自己加载了。 双亲委派机制说简单点就是，先找parent（双亲）加载，不行再由儿子自己加载。 双亲委派机制： 1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 3、如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 4、若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 ClassLoader源码分析： 1234567891011121314151617181920212223242526272829public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125;protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类， //通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 为什么要设计双亲委派机制? 沙箱安全机制:自己写的java.lang.String.class类不会被加载，这样便可以防止核心API库被随意篡改 避免类的重复加载:当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次，保证被加载类的唯一性 看一个类加载示例: 123456789101112package java.lang;public class String&#123; public static void main(String[] args) &#123; System.out.println(&quot;**************My String Class**************&quot;); &#125;&#125;//运行结果://错误: 在类 java.lang.String 中找不到 main 方法, 请将 main 方法定义为: public static void main(String[] args)//否则 JavaFX 应用程序类必须扩展javafx.application.Application 自定义类加载器自定义类加载器只需要继承 java.lang.ClassLoader 类，该类有两个核心方法， 一个是 loadClass(String, boolean)，实现了双亲委派机制， 还有一个方法是findClass，默认实现是空方法，所以我们自定义类加载器主要是重写该方法。 通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自ClassLoader类，从上面对loadClass方法来分析来看，我们只需要重写 findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package com.neo.classloader; import java.io.*; public class MyClassLoader extends ClassLoader &#123; private String root; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = loadClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] loadClassData(String className) &#123; String fileName = root + File.separatorChar + className.replace(&#x27;.&#x27;, File.separatorChar) + &quot;.class&quot;; try &#123; InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, length); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public String getRoot() &#123; return root; &#125; public void setRoot(String root) &#123; this.root = root; &#125; public static void main(String[] args) &#123; //初始化自定义类加载器，会先初始化父类ClassLoader，其中会把自定义类加载器的父加载 //器设置为应用程序类加载器AppClassLoader MyClassLoader classLoader = new MyClassLoader(); //E盘创建 temp/com/neo/classloader 几级目录，将Test类的复制类Test2.class丢入该目录 classLoader.setRoot(&quot;E:\\\\temp&quot;); Class&lt;?&gt; testClass = null; try &#123; testClass = classLoader.loadClass(&quot;com.neo.classloader.Test2&quot;); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。这里有几点需要注意： 1、这里传递的文件名需要是类的全限定性名称，即com.paddx.test.classloading.Test格式的，因为 defineClass 方法是按这种格式进行处理的。 2、最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 3、这类Test 类本身可以被 AppClassLoader类加载，因此我们不能把com/paddx/test/classloading/Test.class放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由AppClassLoader加载，而不会通过我们自定义类加载器来加载。 打破双亲委派机制再来一个沙箱安全机制示例，尝试打破双亲委派机制，用自定义类加载器加载我们自己实现的 java.lang.String.class 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public class MyClassLoaderTest&#123; static class MyClassLoader extends ClassLoader &#123; private String classPath; public MyClassLoader(String classPath) &#123; this.classPath = classPath; &#125; private byte[] loadByte(String name) throws Exception &#123; name = name.replaceAll(&quot;\\\\.&quot;, &quot;/&quot;); FileInputStream fis = new FileInputStream(classPath + &quot;/&quot; + name + &quot;.class&quot;); int len = fis.available(); byte[] data = new byte[len]; fis.read(data); fis.close(); return data; &#125; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; try&#123; byte[] data = loadByte(name); return defineClass(name, data, 0, data.length); &#125; catch (Exception e) &#123; e.printStackTrace(); throw new ClassNotFoundException(); &#125; &#125; /** * 重写类加载方法，实现自己的加载逻辑，不委派给双亲加载 * @param name * @param resolve * @return * @throws ClassNotFoundException */ protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if(c==null)&#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; public static void main(String args[]) throws Exception &#123; MyClassLoader classLoader = new MyClassLoader(&quot;D:/test&quot;); //尝试用自己改写类加载机制去加载自己写的java.lang.String.class Class clazz = classLoader.loadClass(&quot;java.lang.String&quot;); Object obj = clazz.newInstance(); Method method= clazz.getDeclaredMethod(&quot;sout&quot;, null); method.invoke(obj, null); System.out.println(clazz.getClassLoader().getClass().getName()); &#125; &#125;&#125;// 运行结果:// java.lang.SecurityException:Prohibitedpackagename:java.lang// at java.lang.ClassLoader.preDefineClass(ClassLoader.java:659)// at java.lang.ClassLoader.defineClass(ClassLoader.java:758)//需要将 Class clazz = classLoader.loadClass(&quot;java.lang.String&quot;);//改为非java开头路径 ，这是jvm的安全机制 破坏双亲委派模型双亲委派模型主要出现过 3 较大规模的“被破坏”情况。 双亲委派模型在引入之前已经存在破坏它的代码存在了。双亲委派模型在 JDK 1.2 之后才被引入，而类加载器和抽象类 java.lang.ClassLoader 则在 JDK 1.0 时代就已经存在，JDK 1.2之后，其添加了一个新的 protected 方法 findClass()，在此之前，用户去继承 ClassLoader 类的唯一目的就是为了重写 loadClass() 方法，而双亲委派的具体逻辑就实现在这个方法之中，JDK 1.2 之后已不提倡用户再去覆盖 loadClass() 方法，而应当把自己的类加载逻辑写到 findClass() 方法中，这样就可以保证新写出来的类加载器是符合双亲委派规则的。 基础类无法调用类加载器加载用户提供的代码。双亲委派很好地解决了各个类加载器的基础类的统一问题（越基础的类由越上层的加载器进行加载），但如果基础类又要调用用户的代码，例如 JNDI 服务，JNDI 现在已经是 Java 的标准服务，它的代码由启动类加载器去加载（在 JDK 1.3 时放进去的 rt.jar ），但 JNDI 的目的就是对资源进行集中管理和查找，它需要调用由独立厂商实现并部署在应用程序的 ClassPath 下的 JNDI 接口提供者（SPI,Service Provider Interface，例如 JDBC 驱动就是由 MySQL 等接口提供者提供的）的代码，但启动类加载器只能加载基础类，无法加载用户类。 为此 Java 引入了线程上下文类加载器（Thread Context ClassLoader）。这个类加载器可以通过 java.lang.Thread.setContextClassLoaser() 方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。如此，JNDI 服务使用这个线程上下文类加载器去加载所需要的 SPI 代码，也就是父类加载器请求子类加载器去完成类加载的动作，这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则，但这也是无可奈何的事情。Java 中所有涉及 SPI 的加载动作基本上都采用这种方式，例如 JNDI、JDBC、JCE、JAXB 和 JBI 等。 用户对程序动态性的追求。代码热替换（HotSwap）、模块热部署（Hot Deployment）等，OSGi 实现模块化热部署的关键则是它自定义的类加载器机制的实现。每一个程序模块（Bundle）都有一个自己的类加载器，当需要更换一个 Bundle 时，就把 Bundle 连同类加载器一起换掉以实现代码的热替换。 在 OSGi 环境下，类加载器不再是双亲委派模型中的树状结构，而是进一步发展为更加复杂的网状结构，当收到类加载请求时，OSGi 将按照下面的顺序进行类搜索：1）将以 java.* 开头的类委派给父类加载器加载。2）否则，将委派列表名单内的类委派给父类加载器加载。3）否则，将 Import 列表中的类委派给 Export 这个类的 Bundle 的类加载器加载。4）否则，查找当前 Bundle 的 ClassPath，使用自己的类加载器加载。5）否则，查找类是否在自己的 Fragment Bundle 中，如果在，则委派给 Fragment Bundle 的类加载器加载。6）否则，查找 Dynamic Import 列表的 Bundle，委派给对应 Bundle 的类加载器加载。7）否则，类查找失败。上面的查找顺序中只有开头两点仍然符合双亲委派规则，其余的类查找都是在平级的类加载器中进行的。OSGi 的 Bundle 类加载器之间只有规则，没有固定的委派关系。 第四次破坏双亲委派：JDK的模块化 在JDK9之前，JVM的基础类以前都是在rt.jar这个包里，这个包也是JRE运行的基石。这不仅是违反了单一职责原则，同样程序在编译的时候会将很多无用的类也一并打包，造成臃肿。 在JDK9中，整个JDK都基于模块化进行构建，以前的rt.jar, tool.jar被拆分成数十个模块，编译的时候只编译实际用到的模块，同时各个类加载器各司其职，只加载自己负责的模块。 模块化加载源码 123456789101112131415Class&lt;?&gt; c = findLoadedClass(cn); if (c == null) &#123; // 找到当前类属于哪个模块 LoadedModule loadedModule = findLoadedModule(cn); if (loadedModule != null) &#123; //获取当前模块的类加载器 BuiltinClassLoader loader = loadedModule.loader(); //进行类加载 c = findClassInModuleOrNull(loadedModule, cn); &#125; else &#123; // 找不到模块信息才会进行双亲委派 if (parent != null) &#123; c = parent.loadClassOrNull(cn); &#125; &#125;","categories":[],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://tj-ever.github.io/tags/JVM/"}]},{"title":"线程池相关学习","slug":"并发编程 线程池相关学习","date":"2021-08-10T06:27:38.342Z","updated":"2021-08-17T09:57:15.185Z","comments":true,"path":"2021/08/10/并发编程 线程池相关学习/","link":"","permalink":"https://tj-ever.github.io/2021/08/10/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9B%B8%E5%85%B3%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"概述在执行一个异步任务或并发任务时，往往是通过直接new Thread()方法来创建新的线程，这样做弊端较多，更好的解决方案是合理地利用线程池，线程池的优势很明显，如下： 降低系统资源消耗，通过重用已存在的线程，降低线程创建和销毁造成的消耗； 提高系统响应速度，当有任务到达时，无需等待新线程的创建便能立即执行； 方便线程并发数的管控，线程若是无限制的创建，不仅会额外消耗大量系统资源，更是占用过多资源而阻塞系统或oom等状况，从而降低系统的稳定性。线程池能有效管控线程，统一分配、调优，提供资源使用率； 更强大的功能，线程池提供了定时、定期以及可控线程数等功能的线程池，使用方便简单。 实现方式Runnable接口实现runnanle接口的类将被Thread执行，表示一个基本的任务 1234public interface Runnable &#123; // run方法就是实际执行任务 public abstract void run();&#125; Callable接口callable接口同样是任务，与runnable接口的区别是它接收泛型，并且执行任务后带有返回值 1234public interface Callable&lt;V&gt; &#123; // 相对于run方法带有返回值的call方法 V call() throws Exception;&#125; Executor框架Executor接口是线程池框架中最基础的部分，定义了一个用于执行Runnable的execute方法。 Executor下有一个重要子接口ExecutorService，其中定义了线程池的具体行为 execute(Runnable command):履行Ruannable类型的任务 submit(task):可用来提交Callable或Runnable任务，并返回代表此任务的Future 对象 shutdown():在完成已提交的任务后封闭办事，不再接管新任务 shutdownNow():停止所有正在履行的任务并封闭办事 isTerminated():测试是否所有任务都履行完毕了 isShutdown():测试是否该ExecutorService已被关闭 重点属性12345678910111213141516171819202122232425262728293031323334//用来标记线程池状态（高3位），线程个数（低29位）//默认是RUNNING状态，线程个数为0private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//线程个数掩码位数，并不是所有平台int类型是32位，所以准确说是具体平台下Integer的二进制位数-3后的剩余位数才是线程的个数，private static final int COUNT_BITS = Integer.SIZE - 3;//线程最大个数(低29位)00011111111111111111111111111111private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// 线程池状态//（高3位）：11100000000000000000000000000000private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;//（高3位）：00000000000000000000000000000000private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;//（高3位）：00100000000000000000000000000000private static final int STOP = 1 &lt;&lt; COUNT_BITS;//（高3位）：01000000000000000000000000000000private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;//（高3位）：01100000000000000000000000000000private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// 获取高三位 运行状态private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;//获取低29位 线程个数private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;//计算ctl新值，线程状态 与 线程个数private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 线程池状态切换1、RUNNING 状态说明:线程池处在RUNNING状态时，能够接收新任务，以及对已添加的任务进行处理。 状态切换:线程池的初始化状态是RUNNING。换句话说，线程池被一旦被创建，就处于RUNNING状态，并且线程池中的任务数为0 2、 SHUTDOWN 状态说明:线程池处在SHUTDOWN状态时，不接收新任务，但能处理已添加的任务。 状态切换:调用线程池的shutdown()接口时，线程池由RUNNING -&gt; SHUTDOWN。 3、STOP 状态说明:线程池处在STOP状态时，不接收新任务，不处理已添加的任务，并且会中 断正在处理的任务。 状态切换:调用线程池的shutdownNow()接口时，线程池由(RUNNING or SHUTDOWN ) -&gt; STOP。 4、TIDYING 状态说明:当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING 状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在 ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理; 可以通过重载terminated()函数来实现。 状态切换:当线程池在SHUTDOWN状态下，阻塞队列为空并且线程池中执行的任务也为空时，就会由 SHUTDOWN -&gt; TIDYING。 当线程池在STOP状态下，线程池中执行的任务为空时，就会由STOP -&gt; TIDYING。 5、 TERMINATED 状态说明:线程池彻底终止，就变成TERMINATED状态。 状态切换:线程池处在TIDYING状态时，执行完terminated()之后，就会由 TIDYING - &gt; TERMINATED。 进入TERMINATED的条件如下: 1234线程池不是RUNNING状态; 线程池状态不是TIDYING状态或TERMINATED状态; 如果线程池状态是SHUTDOWN并且workerQueue为空;workerCount为0; 设置TIDYING状态成功。 源码分析excute 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public void execute(Runnable command) &#123; //(1) 如果任务为null，则抛出NPE异常 if (command == null) throw new NullPointerException(); //（2）获取当前线程池的状态+线程个数变量的组合值 // clt记录着runState和workerCount int c = ctl.get(); //（3） workerCountOf方法取出低29位的值，表示当前活动的线程数; // 如果当前活动线程数小于corePoolSize，则新建一个线程放入线程池中，并把任务添加到该线程中。 if (workerCountOf(c) &lt; corePoolSize) &#123; /* * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize 来判断还是maximumPoolSize来判断; * 如果为true，根据corePoolSize来判断; * 如果为false，则根据maximumPoolSize来判断 */ if (addWorker(command, true)) return; // 如果添加失败，则重新获取ctl值 c = ctl.get(); &#125; //（4）如果线程池处于RUNNING状态，则添加任务到阻塞队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; //（4.1）二次检查，重新获取ctl值 int recheck = ctl.get(); //（4.2）如果当前线程池状态不是RUNNING则从队列删除任务，并执行拒绝策略 if (!isRunning(recheck) &amp;&amp; remove(command)) reject(command); //（4.3）否则如果当前线程池线程空，则添加一个线程 /* * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法 * 这里传入的参数表示: * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动; * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为 maximumPoolSize，添加线程时根据maximumPoolSize来判断; * 如果判断workerCount大于0，则直接返回，在workQueue中新增的 command会在将来的某个时刻被执行。 */ else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //（5）如果队列满了，则新增线程，新增失败则执行拒绝策略 /* * 如果执行到这里，有两种情况: * 1. 线程池已经不是RUNNING状态; * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且 workQueue已满。 * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限 线程数量的上限设置为maximumPoolSize; * 如果失败则拒绝该任务 */ else if (!addWorker(command, false)) reject(command);&#125; 简单来说，在执行execute()方法时如果状态一直是RUNNING时，的执行过程如下: 如果workerCount &lt; corePoolSize，则创建并启动一个线程来执行新提交的任 务; 如果workerCount &gt;= corePoolSize，且线程池内的阻塞队列未满，则将任务添 加到该阻塞队列中; 如果 workerCount &gt;= corePoolSize &amp;&amp; workerCount &lt; maximumPoolSize，且线程池内的阻塞队列已满，则创建并启动一个线程来执行新 提交的任务; 如果workerCount &gt;= maximumPoolSize，并且线程池内的阻塞队列已满, 则根据拒绝策略来处理该任务, 默认的处理方式是直接抛异常。 这里要注意一下addWorker(null, false);，也就是创建一个线程，但并没有传入任务，因为任务已经被添加到workQueue中了，所以worker在执行的时候，会直接从workQueue中 获取任务。所以，在workerCountOf(recheck) == 0时执行addWorker(null, false);也是 为了保证线程池在RUNNING状态下必须要有一个线程来执行任务。 addworkeraddWorker方法的主要工作是在线程池中创建一个新的线程并执行，firstTask参数用于指定新增的线程执行的第一个任务，core参数为true表示在新增线程时会判断当前活动线 程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于 maximumPoolSize，代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); // 获取运行状态 int rs = runStateOf(c); /* * 这个if判断 * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务; * 接着判断以下3个条件，只要有1个不满足，则返回false: * 1. rs == SHUTDOWN，这时表示关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务 * 2. firsTask为空 * 3. 阻塞队列不为空 * * 首先考虑rs == SHUTDOWN的情况 * 这种情况下不会接受新提交的任务，所以在firstTask不为空的时候会返回false; * 然后，如果firstTask为空，并且workQueue也为空，则返回false， * 因为队列中已经没有任务了，不需要再添加线程了 */ // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; // 获取线程数 int wc = workerCountOf(c); // 如果wc超过CAPACITY，也就是ctl的低29位的最大值(二进制是29个1)，返回false; // 这里的core是addWorker方法的第二个参数，如果为true表示根据corePoolSize来比较， // 如果为false则根据maximumPoolSize来比较。 // if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 尝试增加workerCount，如果成功，则跳出第一个for循环 if (compareAndIncrementWorkerCount(c)) break retry; // 如果增加workerCount失败，则重新获取ctl的值 c = ctl.get(); // Reread ctl // 如果当前的运行状态不等于rs，说明状态已被改变，返回第一个 for循环继续执行 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 根据firstTask来创建Worker对象 w = new Worker(firstTask); // 每一个Worker对象都会创建一个线程 final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN表示是RUNNING状态; // 如果rs是RUNNING状态或者rs是SHUTDOWN状态并且firstTask为null，向线程池中添加线程。 // 因为在SHUTDOWN时不会在添加新的任务，但还是会执行workQueue中的任务 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // workers是一个HashSet workers.add(w); int s = workers.size(); // largestPoolSize记录着线程池中出现过的最大线程数量 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 启动线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; Worker类线程池中的每一个线程被封装成一个Worker对象，ThreadPool维护的其实就是一组 Worker对象，请参见JDK源码。 Worker类继承了AQS，并实现了Runnable接口，注意其中的firstTask和thread属性:firstTask用它来保存传入的任务;thread是在调用构造方法时通过ThreadFactory来创建的线程，是用来处理任务的线程。 在调用构造方法时，需要把任务传入，这里通过 getThreadFactory().newThread(this); 来 新 建 一 个 线 程 ， newThread 方 法 传 入 的 参 数 是 this，因为Worker本身继承了Runnable接口，也就是一个线程，所以一个Worker对象在 启动的时候会调用Worker类中的run方法。 Worker继承了AQS，使用AQS来实现独占锁的功能。 lock方法一旦获取了独占锁，表示当前线程正在执行任务中; 如果正在执行任务，则不应该中断线程; 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务， 这时可以对该线程进行中断; 线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers 方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程 池中的线程是否是空闲状态; 之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的 线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果 在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线 程。 所以，Worker继承自AQS，用于判断线程是否空闲以及是否可以被中断。 此外，在构造方法中执行了setState(-1);，把state变量设置为-1，为什么这么做呢? 是因为AQS中默认的state是0，如果刚创建了一个Worker对象，还没有执行任务时，这时就不应该被中断，看一下tryAquire方法: 1234567protected boolean tryAcquire(int unused) &#123; //cas修改state，不可重入 if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true;&#125; return false;&#125; tryAcquire方法是根据state是否是0来判断的，所以，setState(-1);将state设置为-1是 为了禁止在执行任务前对线程进行中断。 正因为如此，在runWorker方法中会先调用Worker对象的unlock方法将state设置为 0。 runWorker在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); // 获取第一个任务 Runnable task = w.firstTask; w.firstTask = null; //允许中断 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为空，通过getTask获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 这里说明一下第一个if判断，目的是: 如果线程池正在停止，那么要保证当前线程是中断状态; 如果不是的话，则要保证当前线程不是中断状态; 这里要考虑在执行该if语句期间可能也执行了shutdownNow方法，shutdownNow方法会 把状态设置为STOP，回顾一下STOP状态: 不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到 该状态。 STOP状态要中断线程池中的所有线程，而这里使用Thread.interrupted()来判断是否中断 是 为 了 确 保 在 RUNNING 或 者 SHUTDOWN 状 态 时 线 程 是 非 中 断 状 态 的 ， 因 为 Thread.interrupted()方法会复位中断的状态。 总结一下runWorker方法的执行过程: while循环不断地通过getTask()方法获取任务; getTask()方法从阻塞队列中取任务; 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是 中断状态; 调用task.run()执行任务; 如果task为null则跳出循环，执行processWorkerExit()方法; runWorker方法执行完毕，也代表着Worker中的run方法执行完毕，销毁线程。 这里的beforeExecute方法和afterExecute方法在ThreadPoolExecutor类中是空的，留给 子类来实现。 completedAbruptly 变 量 来 表 示 在 执 行 任 务 过 程 中 是 否 出 现 了 异 常 ， 在 processWorkerExit方法中会对该变量的值进行判断。 getTaskgetTask方法用来从阻塞队列中取任务，代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private Runnable getTask() &#123; // timeOut 变量表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 如果线程池状态rs &gt;= SHUTDOWN 也就是非RUNNING状态，再进行以下判断 // 1. rs &gt;= STOP,线程池是否正在stop // 2. 阻塞队列是否为空 // 如果以上条件成立，则workerCount减1并返回null // 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列添加任务 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty()))&#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // timed变量用于判断是否需要进行超时控制 // allowCoreThreadTimeOut 默认为false，也就是核心线程不允许超时 // wc &gt; corePoolSize 表示线程池中的线程数量大于核心线程数量 // 对于超过核心线程数量的线程，需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * wc &gt; maximumPoolSize 的情况是因为在此方法执行阶段的同时执行了setMaximumPoolSize方法 * timed &amp;&amp; timedOut如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时 * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试workerCount减一 * 如果减一失败，则重试 * 如果wc == 1，也就说明当前线程是线程池中唯一的线程了 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; // 根据timed来判断， // 如果为true，则通过阻塞队列的poll方法进行超时控制，如果在keepAliveTime时间内没有获取到任务，则返回null // 否则通过take方法，如果此时队列为空，则take方法会阻塞直到队列不为空 Runnable r = timed ? workQueue.poll(keepAliveTime,TimeUnit.NANOSECONDS) :workQueue.take(); if (r != null) return r; // 如果 r == null timedOut timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断，则设置timedOut为false，并返回循环重试 timedOut = false; &#125; &#125; 这里重要的地方是第二个if判断，目的是控制线程池的有效线程数量。由上文中的分析可以知道，在执行execute方法时，如果当前线程池的线程数量超过了corePoolSize且小于 maximumPoolSize，并且workQueue已满时，则可以增加工作线程，但这时如果超时没有获取到任务，也就是timedOut为true的情况，说明workQueue已经为空了，也就说明了当前线程池中不需要那么多线程来执行任务了，可以把多于corePoolSize数量的线程销毁掉，保持线程数量在corePoolSize即可。 什么时候会销毁?当然是runWorker方法执行完之后，也就是Worker中的run方法执 行完，由JVM自动回收。 getTask方法返回null时，在runWorker方法中会跳出while循环，然后会执行 processWorkerExit方法。 processWorkerExit12345678910111213141516171819202122232425262728293031323334private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果completedAbruptly的值为true，说明线程执行时出了异常，需要将workerCount减一 // 如果线程执行时没有出现异常，说明在getTask（）方法中已经对workerCount进行了减一操作，这里就不必再减了 if (completedAbruptly) // If abrupt, then workerCount wasn&#x27;t decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // 统计完成的任务数 completedTaskCount += w.completedTasks; // 从workers中移除，也就表示从线程池中移除了一个工作线程 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态判断是否结束线程池 tryTerminate(); int c = ctl.get(); // 当线程池是RUNNING或SHUTDOWN状态时，如果worker是异常结束，那么会直接addWorker // 如果allowCoreThreadTimeOut=true，并且等待队列有任务，至少保留一个worker // 如果allowCoreThreadTimeOut=false，workderCount不少于corePoolSize if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed addWorker(null, false); &#125; &#125;&#125; 至此，processWorkerExit执行完之后，工作线程被销毁，以上就是整个工作线程的生命周期，从execute方法开始，Worker使用ThreadFactory创建新的工作线程， runWorker通过getTask获取任务，然后执行任务，如果getTask返回null，进入 processWorkerExit方法，整个线程结束，如图所示: 原理Executors类提供4个静态工厂方法：newCachedThreadPool()、newFixedThreadPool(int)、newSingleThreadExecutor和newScheduledThreadPool(int)。这些方法最终都是通过ThreadPoolExecutor类来完成的，这里强烈建议大家直接使用Executors类提供的便捷的工厂方法，能完成绝大多数的用户场景，当需要更细节地调整配置，需要先了解每一项参数的意义。 ThreadPoolExecutor123456789101112131415public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; corePoolSize（线程池基本大小）：当向线程池提交一个任务时，若线程池已创建的线程数小于corePoolSize，即便此时存在空闲线程，也会通过创建一个新线程来执行该任务，直到已创建的线程数大于或等于corePoolSize时，才会根据是否存在空闲线程，来决定是否需要创建新的线程。除了利用提交新任务来创建和启动线程（按需构造），也可以通过 prestartCoreThread() 或 prestartAllCoreThreads() 方法来提前启动线程池中的基本线程。 maximumPoolSize（线程池最大大小）：线程池所允许的最大线程个数。当队列满了，且已创建的线程数小于maximumPoolSize，则线程池会创建新的线程来执行任务。另外，对于无界队列，可忽略该参数。 keepAliveTime（线程存活保持时间）：默认情况下，当线程池的线程个数多于corePoolSize时，线程的空闲时间超过keepAliveTime则会终止。但只要keepAliveTime大于0，allowCoreThreadTimeOut(boolean) 方法也可将此超时策略应用于核心线程。另外，也可以使用setKeepAliveTime()动态地更改参数。 unit（存活时间的单位）：时间单位，分为7类，从细到粗顺序：NANOSECONDS（纳秒），MICROSECONDS（微妙），MILLISECONDS（毫秒），SECONDS（秒），MINUTES（分），HOURS（小时），DAYS（天）； workQueue（任务队列）：用于传输和保存等待执行任务的阻塞队列。可以使用此队列与线程池进行交互： 如果运行的线程数少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。 如果运行的线程数等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。 如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。 threadFactory（线程工厂）：用于创建新线程。由同一个threadFactory创建的线程，属于同一个ThreadGroup，创建的线程优先级都为Thread.NORM_PRIORITY，以及是非守护进程状态。threadFactory创建的线程也是采用new Thread()方式，threadFactory创建的线程名都具有统一的风格：pool-m-thread-n（m为线程池的编号，n为线程池内的线程编号）; handler（线程饱和策略）：线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务。线程池提供了4种策略: AbortPolicy:直接抛出异常，默认策略; CallerRunsPolicy:用调用者所在的线程来执行任务; DiscardOldestPolicy:丢弃阻塞队列中靠最前的任务，并执行当前任务; DiscardPolicy:直接丢弃任务; 上面的4种策略都是ThreadPoolExecutor的内部类。 当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如 记录日志或持久化存储不能处理的任务。 排队策略 直接提交。工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 无界队列。使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize 的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web 页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 有界队列。当使用有限的 maximumPoolSizes 时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O 边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU 使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 BlockingQueue实现BlockingQueue接口的常见类如下： ArrayBlockingQueue：基于数组的有界阻塞队列。队列按FIFO原则对元素进行排序，队列头部是在队列中存活时间最长的元素，队尾则是存在时间最短的元素。新元素插入到队列的尾部，队列获取操作则是从队列头部开始获得元素。 这是一个典型的“有界缓存区”，固定大小的数组在其中保持生产者插入的元素和使用者提取的元素。一旦创建了这样的缓存区，就不能再增加其容量。试图向已满队列中放入元素会导致操作受阻塞；试图从空队列中提取元素将导致类似阻塞。ArrayBlockingQueue构造方法可通过设置fairness参数来选择是否采用公平策略，公平性通常会降低吞吐量，但也减少了可变性和避免了“不平衡性”，可根据情况来决策。 LinkedBlockingQueue：基于链表的无界阻塞队列。与ArrayBlockingQueue一样采用FIFO原则对元素进行排序。基于链表的队列吞吐量通常要高于基于数组的队列。 SynchronousQueue：同步的阻塞队列。其中每个插入操作必须等待另一个线程的对应移除操作，等待过程一直处于阻塞状态，同理，每一个移除操作必须等到另一个线程的对应插入操作。SynchronousQueue没有任何容量。不能在同步队列上进行 peek，因为仅在试图要移除元素时，该元素才存在；除非另一个线程试图移除某个元素，否则也不能（使用任何方法）插入元素；也不能迭代队列，因为其中没有元素可用于迭代。Executors.newCachedThreadPool使用了该队列。 PriorityBlockingQueue：基于优先级的无界阻塞队列。优先级队列的元素按照其自然顺序进行排序，或者根据构造队列时提供的 Comparator 进行排序，具体取决于所使用的构造方法。优先级队列不允许使用 null 元素。依靠自然顺序的优先级队列还不允许插入不可比较的对象（这样做可能导致 ClassCastException）。虽然此队列逻辑上是无界的，但是资源被耗尽时试图执行 add 操作也将失败（导致 OutOfMemoryError）。 线程池关闭调用线程池的shutdown()或shutdownNow()方法来关闭线程池 shutdown原理：将线程池状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。 shutdownNow原理：将线程池的状态设置成STOP状态，然后中断所有任务(包括正在执行的)的线程，并返回等待执行任务的列表。 中断采用interrupt方法，所以无法响应中断的任务可能永远无法终止。但调用上述的两个关闭之一，isShutdown()方法返回值为true，当所有任务都已关闭，表示线程池关闭完成，则isTerminated()方法返回值为true。当需要立刻中断所有的线程，不一定需要执行完任务，可直接调用shutdownNow()方法。 线程池流程 判断核心线程池是否已满，即已创建线程数是否小于corePoolSize？没满则创建一个新的工作线程来执行任务。已满则进入下个流程。 判断工作队列是否已满？没满则将新提交的任务添加在工作队列，等待执行。已满则进入下个流程。 判断整个线程池是否已满，即已创建线程数是否小于maximumPoolSize？没满则创建一个新的工作线程来执行任务，已满则交给饱和策略来处理这个任务。 用法Java API针对不同需求，利用Executors类提供了4种不同的线程池：newCachedThreadPool, newFixedThreadPool, newScheduledThreadPool, newSingleThreadExecutor。 newCachedThreadPool创建一个可缓存的无界线程池，该方法无参数。当线程池中的线程空闲时间超过60s则会自动回收该线程，当任务超过线程池的线程数则创建新线程。线程池的大小上限为Integer.MAX_VALUE，可看做是无限大。 123456789101112131415161718192021222324252627public void cachedThreadPoolDemo()&#123; ExecutorService cachedThreadPool = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) &#123; final int index = i; cachedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;, index=&quot;+index); &#125; &#125;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//运行结果pool-1-thread-1, index=0pool-1-thread-1, index=1pool-1-thread-1, index=2pool-1-thread-1, index=3pool-1-thread-1, index=4 从运行结果可以看出，整个过程都在同一个线程pool-1-thread-1中运行，后面线程复用前面的线程。 newFixedThreadPool创建一个固定大小的线程池，该方法可指定线程池的固定大小，对于超出的线程会在LinkedBlockingQueue队列中等待。 12345678910111213141516171819202122232425262728public void fixedThreadPoolDemo()&#123; ExecutorService fixedThreadPool = Executors.newFixedThreadPool(3); for (int i = 0; i &lt; 6; i++) &#123; final int index = i; fixedThreadPool.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;, index=&quot;+index); &#125; &#125;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//运行结果pool-1-thread-1, index=0pool-1-thread-2, index=1pool-1-thread-3, index=2pool-1-thread-1, index=3pool-1-thread-2, index=4pool-1-thread-3, index=5 从运行结果可以看出，线程池大小为3，每休眠1s后将任务提交给线程池的各个线程轮番交错地执行。线程池的大小设置，可参数Runtime.getRuntime().availableProcessors()。 newSingleThreadExecutor创建一个只有线程的线程池，该方法无参数，所有任务都保存队列LinkedBlockingQueue中，等待唯一的单线程来执行任务，并保证所有任务按照指定顺序(FIFO或优先级)执行。 12345678910111213141516171819202122232425public void singleThreadExecutorDemo()&#123; ExecutorService singleThreadExecutor = Executors.newSingleThreadExecutor(); for (int i = 0; i &lt; 3; i++) &#123; final int index = i; singleThreadExecutor.execute(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;, index=&quot;+index); &#125; &#125;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//运行结果pool-1-thread-1, index=0pool-1-thread-1, index=1pool-1-thread-1, index=2 从运行结果可以看出，所有任务都是在单一线程运行的。 newScheduledThreadPool创建一个可定时执行或周期执行任务的线程池，该方法可指定线程池的核心线程个数。 12345678910111213141516171819202122232425262728public void scheduledThreadPoolDemo()&#123; ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(3); //定时执行一次的任务，延迟1s后执行 scheduledThreadPool.schedule(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;, delay 1s&quot;); &#125; &#125;, 1, TimeUnit.SECONDS); //周期性地执行任务，延迟2s后，每3s一次地周期性执行任务 scheduledThreadPool.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot;, every 3s&quot;); &#125; &#125;, 2, 3, TimeUnit.SECONDS);&#125;//运行结果pool-1-thread-1, delay 1spool-1-thread-1, every 3spool-1-thread-2, every 3spool-1-thread-2, every 3s... schedule(Runnable command, long delay, TimeUnit unit)，延迟一定时间后执行Runnable任务； schedule(Callable callable, long delay, TimeUnit unit)，延迟一定时间后执行Callable任务； scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)，延迟一定时间后，以间隔period时间的频率周期性地执行任务； scheduleWithFixedDelay(Runnable command, long initialDelay, long delay,TimeUnit unit)，与scheduleAtFixedRate()方法很类似，但是不同的是scheduleWithFixedDelay()方法的周期时间间隔是以上一个任务执行结束到下一个任务开始执行的间隔，而scheduleAtFixedRate()方法的周期时间间隔是以上一个任务开始执行到下一个任务开始执行的间隔，也就是这一些任务系列的触发时间都是可预知的。 ScheduledExecutorService功能强大，对于定时执行的任务，建议多采用该方法。 方法对比 工厂方法 corePoolSize maximumPoolSize keepAliveTime workQueue newCachedThreadPool 0 Integer.MAX_VALUE 60s SynchronousQueue newFixedThreadPool nThreads nThreads 0 LinkedBlockingQueue newSingleThreadExecutor 1 1 0 LinkedBlockingQueue newScheduledThreadPool corePoolSize Integer.MAX_VALUE 0 DelayedWorkQueue 其他参数都相同，其中线程工厂的默认类为DefaultThreadFactory，线程饱和的默认策略为ThreadPoolExecutor.AbortPolicy。 优化合理地配置线程池需要针对具体情况而具体处理，不同的任务类别应采用不同规模的线程池，任务类别可划分为CPU密集型任务、IO密集型任务和混合型任务。 对于CPU密集型任务：线程池中线程个数应尽量少，不应大于CPU核心数； 对于IO密集型任务：由于IO操作速度远低于CPU速度，那么在运行这类任务时，CPU绝大多数时间处于空闲状态，那么线程池可以配置尽量多些的线程，以提高CPU利用率； 对于混合型任务：可以拆分为CPU密集型任务和IO密集型任务，当这两类任务执行时间相差无几时，通过拆分再执行的吞吐率高于串行执行的吞吐率，但若这两类任务执行时间有数据级的差距，那么没有拆分的意义。 线程池监控利用线程池提供的参数进行监控，参数如下： taskCount：线程池需要执行的任务数量。 completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。 largestPoolSize：线程池曾经创建过的最大线程数量，通过这个数据可以知道线程池是否满过。如等于线程池的最大大小，则表示线程池曾经满了。 getPoolSize：线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以这个大小只增不减。 getActiveCount：获取活动的线程数。 通过扩展线程池进行监控：继承线程池并重写线程池的beforeExecute()，afterExecute()和terminated()方法，可以在任务执行前、后和线程池关闭前自定义行为。如监控任务的平均执行时间，最大执行时间和最小执行时间等。","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"Hashmap重读","slug":"Hashmap重读","date":"2021-07-15T16:00:00.000Z","updated":"2021-07-22T09:40:45.171Z","comments":true,"path":"2021/07/16/Hashmap重读/","link":"","permalink":"https://tj-ever.github.io/2021/07/16/Hashmap%E9%87%8D%E8%AF%BB/","excerpt":"","text":"HashMap1.7定义123public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable 数据结构HashMap 采用的数据结构 = 数组（主） + 单链表（副），具体描述如下 该数据结构方式也称：拉链法 数组（主） 核心底层=1个数组（哈希数组，table []） 数组下标=经过处理的键key的value值（通过hashCode() 计算等一系列处理） 数组元素=1个键值对=1个链表（头结点） 数组大小=HashMap的容量（capacity） 单链表（副） 每个链表=哈希表的桶（bucket） 链表的节点值=1个键值对 链表长度=桶的大小 链表主要用于解决hash冲突：若不同key值计算出来的hash值相同，由于之前该hash值的数组位置已经存放好元素，则将原先位置的元素移到单链表中（即发生冲突时，新元素插入到链表头；新元素总是添加到数组中，旧元素移到单链表中）该采用链表解决hash冲突的方法=链地址法 示意图 数组元素 &amp; 链表节点的 实现类HashMap中的数组元素 &amp; 链表节点 采用 Entry类 实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Entry类实现了Map.Entry接口 * 即 实现了getKey()、getValue()、equals(Object o)和hashCode()等方法**/ static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; // 键 V value; // 值 Entry&lt;K,V&gt; next; // 指向下一个节点 ，也是一个Entry对象，从而形成解决hash冲突的单链表 int hash; // hash值 /** * 构造方法，创建一个Entry * 参数：哈希值h，键值k，值v、下一个节点n */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; // 返回 与 此项 对应的键 public final K getKey() &#123; return key; &#125; // 返回 与 此项 对应的值 public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * equals（） * 作用：判断2个Entry是否相等，必须key和value都相等，才返回true */ public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; /** * hashCode（） */ public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + &quot;=&quot; + getValue(); &#125; /** * 当向HashMap中添加元素时，即调用put(k,v)时， * 对已经在HashMap中k位置进行v的覆盖时，会调用此方法 * 此处没做任何处理 */ void recordAccess(HashMap&lt;K,V&gt; m) &#123; &#125; /** * 当从HashMap中删除了一个Entry时，会调用该函数 * 此处没做任何处理 */ void recordRemoval(HashMap&lt;K,V&gt; m) &#123; &#125; &#125; 方法1234567891011121314151617181920212223242526272829303132// 获得指定键的值V get(Object key);// 添加键值对V put(K key, V value); // 将指定Map中的键值对 复制到 此Map中void putAll(Map&lt;? extends K, ? extends V&gt; m); // 删除该键值对V remove(Object key); // 判断是否存在该键的键值对；是 则返回trueboolean containsKey(Object key);// 判断是否存在该值的键值对；是 则返回trueboolean containsValue(Object value); // 单独抽取key序列，将所有key生成一个SetSet&lt;K&gt; keySet(); // 单独value序列，将所有value生成一个CollectionCollection&lt;V&gt; values(); // 清除哈希表中的所有键值对void clear(); // 返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对int size(); // 判断HashMap是否为空；size == 0时 表示为 空 boolean isEmpty(); 属性12345678910111213141516171819202122232425262728// 1. 容量（capacity）： HashMap中数组的长度// a. 容量范围：必须是2的幂 &amp; &lt;最大容量（2的30次方）// b. 初始容量 = 哈希表创建时的容量 // 默认容量 = 16 = 1&lt;&lt;4 = 00001中的1向左移4位 = 10000 = 十进制的2^4=16 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // 最大容量 = 2的30次方（若传入的容量过大，将被最大值替换） static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 2. 加载因子(Load factor)：HashMap在其容量自动增加前可达到多满的一种尺度// a. 加载因子越大、填满的元素越多 = 空间利用率高、但冲突的机会加大、查找效率变低（因为链表变长了）// b. 加载因子越小、填满的元素越少 = 空间利用率小、冲突的机会减小、查找效率高（链表不长） // 实际加载因子 final float loadFactor; // 默认加载因子 = 0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f;// 3. 扩容阈值（threshold）：当哈希表的大小 ≥ 扩容阈值时，就会扩容哈希表（即扩充HashMap的容量） // a. 扩容 = 对哈希表进行resize操作（即重建内部数据结构），从而哈希表将具有大约两倍的桶数// b. 扩容阈值 = 容量 x 加载因子 int threshold;// 4. 其他 // 存储数据的Entry类型 数组，长度 = 2的幂 // HashMap的实现方式 = 拉链法，Entry数组上的每个元素本质上是一个单向链表 transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; // HashMap的大小，即 HashMap中存储的键值对的数量 transient int size; 加载因子说明 声明对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * 函数使用原型 */ Map&lt;String,Integer&gt; map = new HashMap&lt;String,Integer&gt;(); /** * 源码分析：主要是HashMap的构造函数 = 4个 * 仅贴出关于HashMap构造函数的源码 */ public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123; // 省略上节阐述的参数 /** * 构造函数1：默认构造函数（无参） * 加载因子 &amp; 容量 = 默认 = 0.75、16 */ public HashMap() &#123; // 实际上是调用构造函数3：指定“容量大小”和“加载因子”的构造函数 // 传入的指定容量 &amp; 加载因子 = 默认 this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); &#125; /** * 构造函数2：指定“容量大小”的构造函数 * 加载因子 = 默认 = 0.75 、容量 = 指定大小 */ public HashMap(int initialCapacity) &#123; // 实际上是调用指定“容量大小”和“加载因子”的构造函数 // 只是在传入的加载因子参数 = 默认加载因子 this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * 构造函数3：指定“容量大小”和“加载因子”的构造函数 * 加载因子 &amp; 容量 = 自己指定 */ public HashMap(int initialCapacity, float loadFactor) &#123; // HashMap的最大容量只能是MAXIMUM_CAPACITY，哪怕传入的 &gt; 最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 设置 加载因子 this.loadFactor = loadFactor; // 设置 扩容阈值 = 初始容量 // 注：此处不是真正的阈值，是为了扩展table，该阈值后面会重新计算，下面会详细讲解 threshold = initialCapacity; init(); // 一个空方法用于未来的子对象扩展 &#125; /** * 构造函数4：包含“子Map”的构造函数 * 即 构造出来的HashMap包含传入Map的映射关系 * 加载因子 &amp; 容量 = 默认 */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 设置容量大小 &amp; 加载因子 = 默认 this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); // 该方法用于初始化 数组 &amp; 阈值，下面会详细说明 inflateTable(threshold); // 将传入的子Map中的全部元素逐个添加到HashMap中 putAllForCreate(m); &#125;&#125; 此处仅用于接收初始容量大小（capacity）、加载因子(Load factor)，但仍无真正初始化哈希表，即初始化存储数组table 此处先给出结论：真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时。下面会详细说明 添加数据12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 函数使用原型 */ map.put(&quot;Android&quot;, 1); map.put(&quot;Java&quot;, 2); map.put(&quot;iOS&quot;, 3); map.put(&quot;数据挖掘&quot;, 4); map.put(&quot;产品经理&quot;, 5); /** * 源码分析：主要分析： HashMap的put函数 */ public V put(K key, V value)（分析1）// 1. 若 哈希表未初始化（即 table为空) // 则使用 构造函数时设置的阈值(即初始容量) 初始化 数组table if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 2. 判断key是否为空值null（分析2）// 2.1 若key == null，则将该键-值 存放到数组table 中的第1个位置，即table [0] // （本质：key = Null时，hash值 = 0，故存放到table[0]中） // 该位置永远只有1个value，新传进来的value会覆盖旧的value if (key == null) return putForNullKey(value);（分析3） // 2.2 若 key ≠ null，则计算存放数组 table 中的位置（下标、索引） // a. 根据键值key计算hash值 int hash = hash(key); // b. 根据hash值 最终获得 key对应存放的数组Table中位置 int i = indexFor(hash, table.length); // 3. 判断该key对应的值是否已存在（通过遍历 以该数组元素为头结点的链表 逐个判断） for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k;（分析4）// 3.1 若该key已存在（即 key-value已存在 ），则用 新value 替换 旧value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; //并返回旧的value &#125; &#125; modCount++;（分析5）// 3.2 若 该key不存在，则将“key-value”添加到table中 addEntry(hash, key, value, i); return null; &#125; inflateTable初始化哈希表 12345678910111213141516171819202122232425262728293031323334353637/** * 函数使用原型 */ if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; /** * 源码分析：inflateTable(threshold); */ private void inflateTable(int toSize) &#123; // 1. 将传入的容量大小转化为：&gt;传入容量大小的最小的2的次幂 // 即如果传入的是容量大小是19，那么转化后，初始化容量大小为32（即2的5次幂） int capacity = roundUpToPowerOf2(toSize);-&gt;&gt;分析1 // 2. 重新计算阈值 threshold = 容量 * 加载因子 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 3. 使用计算后的初始容量（已经是2的次幂） 初始化数组table（作为数组长度） // 即 哈希表的容量大小 = 数组大小（长度） table = new Entry[capacity]; //用该容量初始化table initHashSeedAsNeeded(capacity); &#125; /** * 分析1：roundUpToPowerOf2(toSize) * 作用：将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂 * 特别注意：容量大小必须为2的幂，该原因在下面的讲解会详细分析 */ private static int roundUpToPowerOf2(int number) &#123; //若 容量超过了最大值，初始化容量设置为最大值 ；否则，设置为：&gt;传入容量大小的最小的2的次幂 return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; &#125; 真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时 putForNullKey当 key ==null时，将该 key-value 的存储位置规定为数组table 中的第1个位置，即table [0] 1234567891011121314151617181920212223242526272829303132 /** * 函数使用原型 */ if (key == null) return putForNullKey(value); /** * 源码分析：putForNullKey(value) */ private V putForNullKey(V value) &#123; // 遍历以table[0]为首的链表，寻找是否存在key==null 对应的键值对 // 1. 若有：则用新value 替换 旧value；同时返回旧的value值 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 2 .若无key==null的键，那么调用addEntry（），将空键 &amp; 对应的值封装到Entry中，并放到table[0]中 addEntry(0, null, value, 0); // 注： // a. addEntry（）的第1个参数 = hash值 = 传入0 // b. 即 说明：当key = null时，也有hash值 = 0，所以HashMap的key 可为null // c. 对比HashTable，由于HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null // d. 此处只需知道是将 key-value 添加到HashMap中即可，关于addEntry（）的源码分析将等到下面再详细说明， return null; &#125; HashMap的键key 可为null（区别于 HashTable的key 不可为null） HashMap的键key 可为null且只能为1个，但值value可为null且为多个 hash计算存放数组 table 中的位置（即 数组下标 or 索引） 123456789101112131415161718192021222324252627282930313233343536373839404142 /** * 函数使用原型 * 主要分为2步：计算hash值、根据hash值再计算得出最后数组位置 */ // a. 根据键值key计算hash值 -&gt;&gt; 分析1 int hash = hash(key); // b. 根据hash值 最终获得 key对应存放的数组Table中位置 -&gt;&gt; 分析2 int i = indexFor(hash, table.length);/** * 源码分析1：hash(key) * 该函数在JDK 1.7 和 1.8 中的实现不同，但原理一样 = 扰动函数 = 使得根据key生成的哈希码（hash值）分布更加均匀、更具备随机性，避免出现hash值冲突（即指不同key但生成同1个hash值） * JDK 1.7 做了9次扰动处理 = 4次位运算 + 5次异或运算 * JDK 1.8 简化了扰动函数 = 只做了2次扰动 = 1次位运算 + 1次异或运算 */ // JDK 1.7实现：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 4次位运算 + 5次异或运算（9次扰动） static final int hash(int h) &#123; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; // JDK 1.8实现：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 1次位运算 + 1次异或运算（2次扰动） // 1. 取hashCode值： h = key.hashCode() // 2. 高位参与低位的运算：h ^ (h &gt;&gt;&gt; 16) static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // a. 当key = null时，hash值 = 0，所以HashMap的key 可为null // 注：对比HashTable，HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null // b. 当key ≠ null时，则通过先计算出 key的 hashCode()（记为h），然后 对哈希码进行 扰动处理： 按位 异或（^） 哈希码自身右移16位后的二进制 &#125;/** * 函数源码分析2：indexFor(hash, table.length) * JDK 1.8中实际上无该函数，但原理相同，即具备类似作用的函数 */ static int indexFor(int h, int length) &#123; return h &amp; (length-1); // 将对哈希码扰动处理后的结果 与运算(&amp;) （数组长度-1），最终得到存储在数组table的位置（即数组下标、索引）&#125; 问题 为什么不直接采用经过hashCode（）处理的哈希码 作为 存储数组table的下标位置 容易出现 哈希码 与 数组大小范围不匹配的情况，即计算出来的哈希码可能 不在数组大小范围内，从而导致无法匹配存储位置 为什么采用 哈希码 与运算(&amp;) （数组长度-1） 计算数组下标？ 根据HashMap的容量大小（数组长度），按需取 哈希码一定数量的低位 作为存储的数组下标位置，从而 解决 “哈希码与数组大小范围不匹配” 的问题 为什么在计算数组下标前，需对哈希码进行二次处理：扰动处理？ 加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 &amp; 均匀性，最终减少Hash冲突 addEntry若对应的key已存在，则 使用 新value 替换 旧value 若对应的key不存在，则将该“key-value”添加到数组table的对应位置中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124 /** * 函数使用原型 */ // 2. 判断该key对应的值是否已存在 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 2.1 若该key对应的值已存在，则用新的value取代旧的value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 2.2 若 该key对应的值不存在，则将“key-value”添加到table中 addEntry(hash, key, value, i); /** * 源码分析：addEntry(hash, key, value, i) * 作用：添加键值对（Entry ）到 HashMap中 */ void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 参数3 = 插入数组table的索引位置 = 数组下标 // 1. 插入前，先判断容量是否足够 // 1.1 若不足够，则进行扩容（2倍）、重新计算Hash值、重新计算存储数组下标 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); // a. 扩容2倍 --&gt; 分析1 hash = (null != key) ? hash(key) : 0; // b. 重新计算该Key对应的hash值 bucketIndex = indexFor(hash, table.length); // c. 重新计算该Key对应的hash值的存储数组下标位置 &#125; // 1.2 若容量足够，则创建1个新的数组元素（Entry） 并放入到数组中--&gt; 分析2 createEntry(hash, key, value, bucketIndex); &#125; /** * 分析1：resize(2 * table.length) * 作用：当容量不足时（容量 &gt; 阈值），则扩容（扩到2倍） */ void resize(int newCapacity) &#123; // 1. 保存旧数组（old table） Entry[] oldTable = table; // 2. 保存旧容量（old capacity ），即数组长度 int oldCapacity = oldTable.length; // 3. 若旧容量已经是系统默认最大容量了，那么将阈值设置成整型的最大值，退出 if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 4. 根据新容量（2倍容量）新建1个数组，即新table Entry[] newTable = new Entry[newCapacity]; // 5. 将旧数组上的数据（键值对）转移到新table中，从而完成扩容 -&gt;&gt;分析1.1 transfer(newTable); // 6. 新数组table引用到HashMap的table属性上 table = newTable; // 7. 重新设置阈值 threshold = (int)(newCapacity * loadFactor); &#125; /** * 分析1.1：transfer(newTable); * 作用：将旧数组上的数据（键值对）转移到新table中，从而完成扩容 * 过程：按旧链表的正序遍历链表、在新链表的头部依次插入 */ void transfer(Entry[] newTable) &#123; // 1. src引用了旧数组 Entry[] src = table; // 2. 获取新数组的大小 = 获取新容量大小 int newCapacity = newTable.length; // 3. 通过遍历 旧数组，将旧数组上的数据（键值对）转移到新数组中 for (int j = 0; j &lt; src.length; j++) &#123; // 3.1 取得旧数组的每个元素 Entry&lt;K,V&gt; e = src[j]; if (e != null) &#123; // 3.2 释放旧数组的对象引用（for循环后，旧数组不再引用任何对象） src[j] = null; do &#123; // 3.3 遍历 以该数组元素为首 的链表 // 注：转移链表时，因是单链表，故要保存下1个结点，否则转移后链表会断开 Entry&lt;K,V&gt; next = e.next; // 3.4 重新计算每个元素的存储位置 int i = indexFor(e.hash, newCapacity); // 3.5 将元素放在数组上：采用单链表的头插入方式 = 在链表头上存放数据 = 将数组位置的原有数据放在后1个指针、将需放入的数据放到数组位置中 // 即 扩容后，可能出现逆序：按旧链表的正序遍历链表、在新链表的头部依次插入 e.next = newTable[i]; newTable[i] = e; // 3.6 访问下1个Entry链上的元素，如此不断循环，直到遍历完该链表上的所有节点 e = next; &#125; while (e != null); // 如此不断循环，直到遍历完数组上的所有数据元素 &#125; &#125; &#125; /** * 分析2：createEntry(hash, key, value, bucketIndex); * 作用： 若容量足够，则创建1个新的数组元素（Entry） 并放入到数组中 */ void createEntry(int hash, K key, V value, int bucketIndex) &#123; // 1. 把table中该位置原来的Entry保存 Entry&lt;K,V&gt; e = table[bucketIndex]; // 2. 在table中该位置新建一个Entry：将原头结点位置（数组上）的键值对 放入到（链表）后1个节点中、将需插入的键值对 放入到头结点中（数组上）-&gt; 从而形成链表 // 即 在插入元素时，是在链表头插入的，table中的每个位置永远只保存最新插入的Entry，旧的Entry则放入到链表中（即 解决Hash冲突） table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); // 3. 哈希表的键值对数量计数增加 size++; &#125; 替换过程 头插法 扩容机制 转移过程 总结向 HashMap 添加数据（成对 放入 键 - 值对）的全流程 获取数据123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 函数原型 * 作用：根据键key，向HashMap获取对应的值 */ map.get(key)； /** * 源码分析 */ public V get(Object key) &#123; // 1. 当key == null时，则到 以哈希表数组中的第1个元素（即table[0]）为头结点的链表去寻找对应 key == null的键 if (key == null) return getForNullKey(); --&gt; 分析1 // 2. 当key ≠ null时，去获得对应值 --&gt;分析2 Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); &#125; /** * 分析1：getForNullKey() * 作用：当key == null时，则到 以哈希表数组中的第1个元素（即table[0]）为头结点的链表去寻找对应 key == null的键 */ private V getForNullKey() &#123; if (size == 0) &#123; return null; &#125; // 遍历以table[0]为头结点的链表，寻找 key==null 对应的值 for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; // 从table[0]中取key==null的value值 if (e.key == null) return e.value; &#125; return null; &#125; /** * 分析2：getEntry(key) * 作用：当key ≠ null时，去获得对应值 */ final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; // 1. 根据key值，通过hash（）计算出对应的hash值 int hash = (key == null) ? 0 : hash(key); // 2. 根据hash值计算出对应的数组下标 // 3. 遍历 以该数组下标的数组元素为头结点的链表所有节点，寻找该key对应的值 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; // 若 hash值 &amp; key 相等，则证明该Entry = 我们要的键值对 // 通过equals（）判断key是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; 其他方法isEmpty12345678 /** * 函数：isEmpty() * 作用：判断HashMap是否为空，即无键值对；size == 0时 表示为 空 */public boolean isEmpty() &#123; return size == 0; &#125; size12345678 /** * 函数：size() * 作用：返回哈希表中所有 键值对的数量 = 数组中的键值对 + 链表中的键值对 */ public int size() &#123; return size; &#125; clear12345678910 /** * 函数：clear() * 作用：清空哈希表，即删除所有键值对 * 原理：将数组table中存储的Entry全部置为null、size置为0 */ public void clear() &#123; modCount++; Arrays.fill(table, null); size = 0;&#125; putAll1234567891011121314151617181920212223242526272829303132/** * 函数：putAll(Map&lt;? extends K, ? extends V&gt; m) * 作用：将指定Map中的键值对 复制到 此Map中 * 原理：类似Put函数 */ public void putAll(Map&lt;? extends K, ? extends V&gt; m) &#123; // 1. 统计需复制多少个键值对 int numKeysToBeAdded = m.size(); if (numKeysToBeAdded == 0) return; // 2. 若table还没初始化，先用刚刚统计的复制数去初始化table if (table == EMPTY_TABLE) &#123; inflateTable((int) Math.max(numKeysToBeAdded * loadFactor, threshold)); &#125; // 3. 若需复制的数目 &gt; 阈值，则需先扩容 if (numKeysToBeAdded &gt; threshold) &#123; int targetCapacity = (int)(numKeysToBeAdded / loadFactor + 1); if (targetCapacity &gt; MAXIMUM_CAPACITY) targetCapacity = MAXIMUM_CAPACITY; int newCapacity = table.length; while (newCapacity &lt; targetCapacity) newCapacity &lt;&lt;= 1; if (newCapacity &gt; table.length) resize(newCapacity); &#125; // 4. 开始复制（实际上不断调用Put函数插入） for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) put(e.getKey(), e.getValue());&#125; remove123456789101112131415161718192021222324252627282930313233343536373839404142434445 /** * 函数：remove(Object key) * 作用：删除该键值对 */ public V remove(Object key) &#123; Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value); &#125; final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; if (size == 0) &#123; return null; &#125; // 1. 计算hash值 int hash = (key == null) ? 0 : hash(key); // 2. 计算存储的数组下标位置 int i = indexFor(hash, table.length); Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; e = prev; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; modCount++; size--; // 若删除的是table数组中的元素（即链表的头结点） // 则删除操作 = 将头结点的next引用存入table[i]中 if (prev == e) table[i] = next; //否则 将以table[i]为头结点的链表中，当前Entry的前1个Entry中的next 设置为 当前Entry的next（即删除当前Entry = 直接跳过当前Entry） else prev.next = next; e.recordRemoval(this); return e; &#125; prev = e; e = next; &#125; return e; &#125; containsKey12345678/** * 函数：containsKey(Object key) * 作用：判断是否存在该键的键值对；是 则返回true * 原理：调用get（），判断是否为Null */ public boolean containsKey(Object key) &#123; return getEntry(key) != null; &#125; containsValue123456789101112131415161718192021222324252627 /** * 函数：containsValue(Object value) * 作用：判断是否存在该值的键值对；是 则返回true */ public boolean containsValue(Object value) &#123; // 若value为空，则调用containsNullValue() if (value == null) return containsNullValue(); // 若value不为空，则遍历链表中的每个Entry，通过equals（）比较values 判断是否存在 Entry[] tab = table; for (int i = 0; i &lt; tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (value.equals(e.value)) return true;//返回true return false; &#125; // value为空时调用的方法 private boolean containsNullValue() &#123; Entry[] tab = table; for (int i = 0; i &lt; tab.length ; i++) for (Entry e = tab[i] ; e != null ; e = e.next) if (e.value == null) return true; return false; &#125; HashMap1.8 数组元素 &amp; 链表节点的 实现HashMap中的数组元素 &amp; 链表节点 采用 Node类 实现 与 JDK 1.7 的对比（Entry类），仅仅只是换了名字 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Node = HashMap的内部类，实现了Map.Entry接口，本质是 = 一个映射(键值对) * 实现了getKey()、getValue()、equals(Object o)和hashCode()等方法 **/ static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; // 哈希值，HashMap根据该值确定记录的位置 final K key; // key V value; // value Node&lt;K,V&gt; next;// 链表下一个节点 // 构造方法 Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; // 返回 与 此项 对应的键 public final V getValue() &#123; return value; &#125; // 返回 与 此项 对应的值 public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; /** * hashCode（） */ public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; /** * equals（） * 作用：判断2个Entry是否相等，必须key和value都相等，才返回true */ public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 红黑树节点 实现HashMap中的红黑树节点 采用 TreeNode 类 实现 12345678910111213141516171819202122232425/** * 红黑树节点 实现类：继承自LinkedHashMap.Entry&lt;K,V&gt;类 */ static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; // 属性 = 父节点、左子树、右子树、删除辅助节点 + 颜色 TreeNode&lt;K,V&gt; parent; TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; boolean red; // 构造函数 TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; super(hash, key, val, next); &#125; // 返回当前节点的根节点 final TreeNode&lt;K,V&gt; root() &#123; for (TreeNode&lt;K,V&gt; r = this, p;;) &#123; if ((p = r.parent) == null) return r; r = p; &#125; &#125; 新增变量由于数据结构中引入了红黑树，故加入了 与红黑树相关的参数 12345678910111213/** * 与红黑树相关的参数 */ // 1. 桶的树化阈值：即 链表转成红黑树的阈值，在存储数据时，当链表长度 &gt; 该值时，则将链表转换成红黑树 static final int TREEIFY_THRESHOLD = 8; // 2. 桶的链表还原阈值：即 红黑树转为链表的阈值，当在扩容（resize（））时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 &lt; 6时，则将 红黑树转换成链表 static final int UNTREEIFY_THRESHOLD = 6; // 3. 最小树形化容量阈值：即 当哈希表中的容量 &gt; 该值时，才允许树形化链表 （即 将链表 转换成红黑树） // 否则，若桶内元素太多时，则直接扩容，而不是树形化 // 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD static final int MIN_TREEIFY_CAPACITY = 64; 参数区别 声明对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394/** * 函数使用原型 */ Map&lt;String,Integer&gt; map = new HashMap&lt;String,Integer&gt;(); /** * 源码分析：主要是HashMap的构造函数 = 4个 * 仅贴出关于HashMap构造函数的源码 */public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable&#123; // 省略上节阐述的参数 /** * 构造函数1：默认构造函数（无参） * 加载因子 &amp; 容量 = 默认 = 0.75、16 */ public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; &#125; /** * 构造函数2：指定“容量大小”的构造函数 * 加载因子 = 默认 = 0.75 、容量 = 指定大小 */ public HashMap(int initialCapacity) &#123; // 实际上是调用指定“容量大小”和“加载因子”的构造函数 // 只是在传入的加载因子参数 = 默认加载因子 this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /** * 构造函数3：指定“容量大小”和“加载因子”的构造函数 * 加载因子 &amp; 容量 = 自己指定 */ public HashMap(int initialCapacity, float loadFactor) &#123; // 指定初始容量必须非负，否则报错 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); // HashMap的最大容量只能是MAXIMUM_CAPACITY，哪怕传入的 &gt; 最大容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 填充比必须为正 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); // 设置 加载因子 this.loadFactor = loadFactor; // 设置 扩容阈值 // 注：此处不是真正的阈值，仅仅只是将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂，该阈值后面会重新计算 // 下面会详细讲解 -&gt;&gt; 分析1 this.threshold = tableSizeFor(initialCapacity); &#125; /** * 构造函数4：包含“子Map”的构造函数 * 即 构造出来的HashMap包含传入Map的映射关系 * 加载因子 &amp; 容量 = 默认 */ public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 设置容量大小 &amp; 加载因子 = 默认 this.loadFactor = DEFAULT_LOAD_FACTOR; // 将传入的子Map中的全部元素逐个添加到HashMap中 putMapEntries(m, false); &#125;&#125; /** * 分析1：tableSizeFor(initialCapacity) * 作用：将传入的容量大小转化为：&gt;传入容量大小的最小的2的幂 * 与JDK 1.7对比：类似于JDK 1.7 中 inflateTable()里的 roundUpToPowerOf2(toSize) */ static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; 注：（同JDK 1.7类似）此处仅用于接收初始容量大小（capacity）、加载因子(Load factor)，但仍无真正初始化哈希表，即初始化存储数组table此处先给出结论：真正初始化哈希表（初始化存储数组table）是在第1次添加键值对时，即第1次调用put（）时。 添加数据在该步骤中，与JDK 1.7的差别较大： put1234567891011121314151617/** * 函数使用原型 */ map.put(&quot;Android&quot;, 1); map.put(&quot;Java&quot;, 2); map.put(&quot;iOS&quot;, 3); map.put(&quot;数据挖掘&quot;, 4); map.put(&quot;产品经理&quot;, 5); /** * 源码分析：主要分析HashMap的put函数 */ public V put(K key, V value) &#123; // 1. 对传入数组的键Key计算Hash值 -&gt;&gt;分析1 // 2. 再调用putVal（）添加数据进去 -&gt;&gt;分析2 return putVal(hash(key), key, value, false, true); &#125; hash()1234567891011121314151617181920212223242526272829303132333435/** * 分析1：hash(key) * 作用：计算传入数据的哈希码（哈希值、Hash值） * 该函数在JDK 1.7 和 1.8 中的实现不同，但原理一样 = 扰动函数 = 使得根据key生成的哈希码（hash值）分布更加均匀、更具备随机性，避免出现hash值冲突（即指不同key但生成同1个hash值） * JDK 1.7 做了9次扰动处理 = 4次位运算 + 5次异或运算 * JDK 1.8 简化了扰动函数 = 只做了2次扰动 = 1次位运算 + 1次异或运算 */ // JDK 1.7实现：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 4次位运算 + 5次异或运算（9次扰动） static final int hash(int h) &#123; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; // JDK 1.8实现：将 键key 转换成 哈希码（hash值）操作 = 使用hashCode() + 1次位运算 + 1次异或运算（2次扰动） // 1. 取hashCode值： h = key.hashCode() // 2. 高位参与低位的运算：h ^ (h &gt;&gt;&gt; 16) static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // a. 当key = null时，hash值 = 0，所以HashMap的key 可为null // 注：对比HashTable，HashTable对key直接hashCode（），若key为null时，会抛出异常，所以HashTable的key不可为null // b. 当key ≠ null时，则通过先计算出 key的 hashCode()（记为h），然后 对哈希码进行 扰动处理： 按位 异或（^） 哈希码自身右移16位后的二进制 &#125; /** * 计算存储位置的函数分析：indexFor(hash, table.length) * 注：该函数仅存在于JDK 1.7 ，JDK 1.8中实际上无该函数（直接用1条语句判断写出），但原理相同 * 为了方便讲解，故提前到此讲解 */ static int indexFor(int h, int length) &#123; return h &amp; (length-1); // 将对哈希码扰动处理后的结果 与运算(&amp;) （数组长度-1），最终得到存储在数组table的位置（即数组下标、索引） &#125; putVal 与 JDK 1.7的区别： JDK 1.7只需判断 数组 &amp; 链表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140 /** * 分析2：putVal(hash(key), key, value, false, true) */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 1. 若哈希表的数组tab为空，则 通过resize() 创建 // 所以，初始化哈希表的时机 = 第1次调用put函数时，即调用resize() 初始化创建 // 关于resize（）的源码分析将在下面讲解扩容时详细分析，此处先跳过 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 2. 计算插入存储的数组索引i：根据键值key计算的hash值 得到 // 此处的数组下标计算方式 = i = (n - 1) &amp; hash，同JDK 1.7中的indexFor（），上面已详细描述 // 3. 插入时，需判断是否存在Hash冲突： // 若不存在（即当前table[i] == null），则直接在该数组位置新建节点，插入完毕 // 否则，代表存在Hash冲突，即当前存储位置已存在节点，则依次往下判断：a. 当前位置的key是否与需插入的key相同、b. 判断需插入的数据结构是否为红黑树 or 链表 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // newNode(hash, key, value, null)的源码 = new Node&lt;&gt;(hash, key, value, next) else &#123; Node&lt;K,V&gt; e; K k; // a. 判断 table[i]的元素的key是否与 需插入的key一样，若相同则 直接用新value 覆盖 旧value // 判断原则：equals（） if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // b. 继续判断：需插入的数据结构是否为红黑树 or 链表 // 若是红黑树，则直接在树中插入 or 更新键值对 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); -&gt;&gt;分析3 // 若是链表,则在链表中插入 or 更新键值对 // i. 遍历table[i]，判断Key是否已存在：采用equals（） 对比当前遍历节点的key 与 需插入数据的key：若已存在，则直接用新value 覆盖 旧value // ii. 遍历完毕后仍无发现上述情况，则直接在链表尾部插入数据 // 注：新增节点后，需判断链表长度是否&gt;8（8 = 桶的树化阈值）：若是，则把链表转换为红黑树 else &#123; for (int binCount = 0; ; ++binCount) &#123; // 对于ii：若数组的下1个位置，表示已到表尾也没有找到key值相同节点，则新建节点 = 插入节点 // 注：此处是从链表尾插入，与JDK 1.7不同（从链表头插入，即永远都是添加到数组的位置，原来数组位置的数据则往后移） if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 插入节点后，若链表节点&gt;数阈值，则将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); // 树化操作 break; &#125; // 对于i if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // 更新p指向下一个节点，继续遍历 p = e; &#125; &#125; // 对i情况的后续操作：发现key已存在，直接用新value 覆盖 旧value &amp; 返回旧value if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); // 替换旧值时会调用的方法（默认实现为空） return oldValue; &#125; &#125; ++modCount; // 插入成功后，判断实际存在的键值对数量size &gt; 最大容量threshold // 若 &gt; ，则进行扩容 -&gt;&gt;分析4（但单独讲解，请直接跳出该代码块） if (++size &gt; threshold) resize(); afterNodeInsertion(evict);// 插入成功时会调用的方法（默认实现为空） return null;&#125; /** * 分析3：putTreeVal(this, tab, hash, key, value) * 作用：向红黑树插入 or 更新数据（键值对） * 过程：遍历红黑树判断该节点的key是否与需插入的key 相同： * a. 若相同，则新value覆盖旧value * b. 若不相同，则插入 */ final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int h, K k, V v) &#123; Class&lt;?&gt; kc = null; boolean searched = false; TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this; for (TreeNode&lt;K,V&gt; p = root;;) &#123; int dir, ph; K pk; if ((ph = p.hash) &gt; h) dir = -1; else if (ph &lt; h) dir = 1; else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk))) return p; else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) &#123; if (!searched) &#123; TreeNode&lt;K,V&gt; q, ch; searched = true; if (((ch = p.left) != null &amp;&amp; (q = ch.find(h, k, kc)) != null) || ((ch = p.right) != null &amp;&amp; (q = ch.find(h, k, kc)) != null)) return q; &#125; dir = tieBreakOrder(k, pk); &#125; TreeNode&lt;K,V&gt; xp = p; if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; Node&lt;K,V&gt; xpn = xp.next; TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn); if (dir &lt;= 0) xp.left = x; else xp.right = x; xp.next = x; x.parent = x.prev = xp; if (xpn != null) ((TreeNode&lt;K,V&gt;)xpn).prev = x; moveRootToFront(tab, balanceInsertion(root, x)); return null; &#125; &#125; &#125;","categories":[],"tags":[{"name":"hashmap","slug":"hashmap","permalink":"https://tj-ever.github.io/tags/hashmap/"}]},{"title":"并发编程 BlockingQueue","slug":"并发编程 阻塞队列BlockingQueue","date":"2021-07-12T16:00:00.000Z","updated":"2021-07-14T08:30:08.685Z","comments":true,"path":"2021/07/13/并发编程 阻塞队列BlockingQueue/","link":"","permalink":"https://tj-ever.github.io/2021/07/13/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%20%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97BlockingQueue/","excerpt":"","text":"BlockingQueueBlockingQueue即阻塞队列，从阻塞这个词可以看出，在某些情况下对阻塞队列的访问可能会造成阻塞。 被阻塞的情况主要有如下两种： 当队列满了的时候进行入队列操作 当队列空了的时候进行出队列操作 用法阻塞队列主要用在生产者/消费者的场景，下面这幅图展示了一个线程生产、一个线程消费的场景： 负责生产的线程不断的制造新对象并插入到阻塞队列中，直到达到这个队列的上限值。队列达到上限值之后生产线程将会被阻塞，直到消费的线程对这个队列进行消费。 负责消费的线程不断的从队列中消费对象，直到这个队列为空，当队列为空时，消费线程将会被阻塞，除非队列中有新的对象被插入。 方法 - 抛出异常 特殊值 阻塞 超时 插入 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除 remove(o) poll() take() poll(timeout, timeunit) 检查 element() peek() 不能向BlockingQueue中插入null，否则会报NullPointerException。 实现类BlockingQueue只是java.util.concurrent包中的一个接口，而在具体使用时，我们用到的是它的实现类，当然这些实现类也位于java.util.concurrent包中。 Java并发包中的阻塞队列一共7个，当然他们都是线程安全的。 ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。 DealyQueue：一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue：一个不存储元素的阻塞队列。 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。 ArrayBlockingQueueArrayBlockingQueue是一个有边界的阻塞队列，它的内部实现是一个数组。有边界的意思是它的容量是有限的，我们必须在其初始化的时候指定它的容量大小，容量大小一旦指定就不可改变。 属性队列的操作主要有读、写，所以用了两个 int 类型的属性作为下一个读写位置的的指针。存放元素的数组是 final 修饰的，所以数组的大小是固定的。对于并发控制，是所有的访问都必须加锁，并用两个条件对象用于协调读写操作。 1234567891011121314151617181920// 队列存放元素的容器final Object[] items;// 下一次读取或移除的位置int takeIndex;// 存放下一个放入元素的位置int putIndex;// 队列里有效元素的数量int count;// 所有访问的保护锁final ReentrantLock lock;// 等待获取的条件private final Condition notEmpty;// 等待放入的条件private final Condition notFull; 构造函数1234567891011121314151617181920212223242526272829303132333435363738394041public ArrayBlockingQueue(int capacity) &#123; //默认构造非公平锁的阻塞队列 this(capacity, false);&#125;public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; //初始化ReentrantLock重入锁，出队入队拥有这同一个锁 lock = new ReentrantLock(fair); //初始化非空等待队列，有关Condition可参考 notEmpty = lock.newCondition; //初始化非满等待队列 notFull = lock.newCondition;&#125;//在第15行，源码里给了一句注释： Lock only for visibility, not mutual exclusion。//这句话的意思就是给出，这个锁的操作并不是为了互斥操作，而是保证其可见性。//线程T1是实例化ArrayBlockingQueue对象，T2是对实例化的ArrayBlockingQueue对象做入队操作（当然要保证T1和T2的执行顺序），如果不对它进行加锁操作（加锁会保证其可见性，也就是写回主存），T1的集合c有可能只存在T1线程维护的缓存中，并没有写回主存，T2中实例化的ArrayBlockingQueue维护的缓存以及主存中并没有集合c，此时就因为可见性造成数据不一致的情况，引发线程安全问题。public ArrayBlockingQueue(int capacity, boolean fair, Collecation&lt;? extends E&gt; c) &#123; this(capacity, fair); final ReentrantLock lock = this.lock; lock.lock();//注意在这个地方需要获得锁，这为什么需要获取锁的操作呢？ try &#123; int i = 0; try &#123; for (E e : c) &#123; checkNotNull(e); item[i++] = e;//将集合添加进数组构成的队列中 &#125; &#125; catch (ArrayIndexOutOfBoundsException ex) &#123; throw new IllegalArgumentException(); &#125; count = i;//队列中的实际数据数量 putIndex = (i == capacity) ? 0 : i; &#125; finally &#123; lock.unlock(); &#125;&#125; put1234567891011121314151617public void put(E e) throws InterruptedException &#123; checkNotNull(e); // 获取可重入锁 final ReentrantLock lock = this.lock; // 如果当前线程未被中断，则获取锁 lock.lockInterruptibly(); try &#123; while (count == items.length) // 判断元素是否已满 // 若满，则等待 notFull.await(); // 入队列 enqueue(e); &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; put函数用于存放元素，在当前线程被中断时会抛出异常，并且当队列已经满时，会阻塞一直等待。 enqueue12345678910111213141516private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; // 获取数组 final Object[] items = this.items; // 将元素放入 items[putIndex] = x; // 放入后存元素的索引等于数组长度（表示已满） if (++putIndex == items.length) // 重置存索引为0 putIndex = 0; // 元素数量加1 count++; // 唤醒在notEmpty条件上等待的线程 notEmpty.signal();&#125; enqueue函数用于将元素存入底层Object数组中，并且会唤醒等待notEmpty条件的线程。 offer12345678910111213141516171819public boolean offer(E e) &#123; // 检查元素不能为空 checkNotNull(e); // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; if (count == items.length) // 元素个数等于数组长度，则返回 return false; else &#123; // 添加进数组 enqueue(e); return true; &#125; &#125; finally &#123; // 释放数组 lock.unlock(); &#125;&#125; offer函数也用于存放元素，在调用ArrayBlockingQueue的add方法时，会间接的调用到offer函数，offer函数添加元素不会抛出异常，当底层Object数组已满时，则返回false，否则，会调用enqueue函数，将元素存入底层Object数组。并唤醒等待notEmpty条件的线程。 take12345678910111213141516public E take() throws InterruptedException &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 如果当前线程未被中断，则获取锁，中断会抛出异常 lock.lockInterruptibly(); try &#123; while (count == 0) // 元素数量为0，即Object数组为空 // 则等待notEmpty条件 notEmpty.await(); // 出队列 return dequeue(); &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; take函数用于从ArrayBlockingQueue中获取一个元素，其与put函数相对应，在当前线程被中断时会抛出异常，并且当队列为空时，会阻塞一直等待。 dequeue123456789101112131415161718192021private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings(&quot;unchecked&quot;) // 取元素 E x = (E) items[takeIndex]; // 该索引的值赋值为null items[takeIndex] = null; // 取值索引等于数组长度 if (++takeIndex == items.length) // 重新赋值取值索引 takeIndex = 0; // 元素个数减1 count--; if (itrs != null) itrs.elementDequeued(); // 唤醒在notFull条件上等待的线程 notFull.signal(); return x;&#125; dequeue函数用于取元素，并且会唤醒等待notFull条件的线程。 Poll12345678910111213public E poll() &#123; // 重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 若元素个数为0则返回null，否则，调用dequeue，出队列 return (count == 0) ? null : dequeue(); &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; poll函数用于获取元素，其与offer函数相对应，不会抛出异常，当元素个数为0是，返回null，否则，调用dequeue函数，并唤醒等待notFull条件的线程。并返回。 clear1234567891011121314151617181920212223242526272829303132333435public void clear() &#123; // 数组 final Object[] items = this.items; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 保存元素个数 int k = count; if (k &gt; 0) &#123; // 元素个数大于0 // 存数元素索引 final int putIndex = this.putIndex; // 取元素索引 int i = takeIndex; do &#123; // 赋值为null items[i] = null; if (++i == items.length) // 重新赋值i i = 0; &#125; while (i != putIndex); // 重新赋值取元素索引 takeIndex = putIndex; // 元素个数为0 count = 0; if (itrs != null) itrs.queueIsEmpty(); for (; k &gt; 0 &amp;&amp; lock.hasWaiters(notFull); k--) // 若有等待notFull条件的线程，则逐一唤醒 notFull.signal(); &#125; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; clear函数用于清空ArrayBlockingQueue，并且会释放所有等待notFull条件的线程（存放元素的线程）。 LinkedBlockingQueueLinkedBlockingQueue采用的是单链表结构，包含了头结点和尾节点。 内部类LinkedBlockingQueue内部有一个Node类，表示结点，用于存放元素。 12345678static class Node&lt;E&gt; &#123; // 元素 E item; // next域 Node&lt;E&gt; next; // 构造函数 Node(E x) &#123; item = x; &#125;&#125; 属性 123456789101112131415161718192021public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = -6903933977591709194L; // 容量 private final int capacity; // 元素的个数 private final AtomicInteger count = new AtomicInteger(); // 头结点 transient Node&lt;E&gt; head; // 尾结点 private transient Node&lt;E&gt; last; // 取元素锁 private final ReentrantLock takeLock = new ReentrantLock(); // 非空条件 private final Condition notEmpty = takeLock.newCondition(); // 存元素锁 private final ReentrantLock putLock = new ReentrantLock(); // 非满条件 private final Condition notFull = putLock.newCondition();&#125; 可以看到LinkedBlockingQueue包含了读、写重入锁（与ArrayBlockingQueue不同，ArrayBlockingQueue只包含了一把重入锁），读写操作进行了分离，并且不同的锁有不同的Condition条件（与ArrayBlockingQueue不同，ArrayBlockingQueue是一把重入锁的两个条件）。 构造函数1234567891011121314151617181920212223242526272829303132333435363738// 该构造函数用于创建一个容量为 Integer.MAX_VALUE 的 LinkedBlockingQueue。public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125;// 该构造函数用于创建一个具有给定（固定）容量的 LinkedBlockingQueue。public LinkedBlockingQueue(int capacity) &#123; // 初始化容量必须大于0 if (capacity &lt;= 0) throw new IllegalArgumentException(); // 初始化容量 this.capacity = capacity; // 初始化头结点和尾结点 last = head = new Node&lt;E&gt;(null);&#125;// 该构造函数用于创建一个容量是 Integer.MAX_VALUE 的 LinkedBlockingQueue，最初包含给定 collection 的元素，元素按该 collection 迭代器的遍历顺序添加。public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) &#123; // 调用重载构造函数 this(Integer.MAX_VALUE); // 存锁 final ReentrantLock putLock = this.putLock; // 获取锁 putLock.lock(); // Never contended, but necessary for visibility try &#123; int n = 0; for (E e : c) &#123; // 遍历c集合 if (e == null) // 元素为null,抛出异常 throw new NullPointerException(); if (n == capacity) // throw new IllegalStateException(&quot;Queue full&quot;); enqueue(new Node&lt;E&gt;(e)); ++n; &#125; count.set(n); &#125; finally &#123; putLock.unlock(); &#125;&#125; put123456789101112131415161718192021222324252627282930313233public void put(E e) throws InterruptedException &#123; // 值不为空 if (e == null) throw new NullPointerException(); int c = -1; // 新生结点 Node&lt;E&gt; node = new Node&lt;E&gt;(e); // 存元素锁 final ReentrantLock putLock = this.putLock; // 元素个数 final AtomicInteger count = this.count; // 如果当前线程未被中断，则获取锁 putLock.lockInterruptibly(); try &#123; // 元素个数到达指定容量 while (count.get() == capacity) &#123; // 在notFull条件上进行等待 notFull.await(); &#125; // 入队列 enqueue(node); // 更新元素个数，返回的是以前的元素个数 c = count.getAndIncrement(); if (c + 1 &lt; capacity) // 元素个数是否小于容量 // 唤醒在notFull条件上等待的某个线程 notFull.signal(); &#125; finally &#123; // 释放锁 putLock.unlock(); &#125; if (c == 0) // 元素个数为0，表示已有take线程在notEmpty条件上进入了等待，则需要唤醒在notEmpty条件上等待的线程 signalNotEmpty();&#125; put函数用于存放元素，其流程如下。 判断元素是否为null，若是，则抛出异常，否则，进入步骤② 获取存元素锁，并上锁，如果当前线程被中断，则抛出异常，否则，进入步骤③ 判断当前队列中的元素个数是否已经达到指定容量，若是，则在notFull条件上进行等待，否则，进入步骤④ 将新生结点入队列，更新队列元素个数，若元素个数小于指定容量，则唤醒在notFull条件上等待的线程，表示可以继续存放元素。进入步骤5 释放锁，判断结点入队列之前的元素个数是否为0，若是，则唤醒在notEmpty条件上等待的线程（表示队列中没有元素，取元素线程被阻塞了）。 enqueue123456private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; // 更新尾结点域 last = last.next = node;&#125; enqueue函数只是更新了尾节点。 signalNotEmpty12345678910111213private void signalNotEmpty() &#123; // 取元素锁 final ReentrantLock takeLock = this.takeLock; // 获取锁 takeLock.lock(); try &#123; // 唤醒在notEmpty条件上等待的某个线程 notEmpty.signal(); &#125; finally &#123; // 释放锁 takeLock.unlock(); &#125;&#125; signalNotEmpty函数用于唤醒在notEmpty条件上等待的线程，其首先获取取元素锁，然后上锁，然后唤醒在notEmpty条件上等待的线程，最后释放取元素锁。 offer12345678910111213141516171819202122232425262728293031323334public boolean offer(E e) &#123; // 确保元素不为null if (e == null) throw new NullPointerException(); // 获取计数器 final AtomicInteger count = this.count; if (count.get() == capacity) // 元素个数到达指定容量 // 返回 return false; int c = -1; // 新生结点 Node&lt;E&gt; node = new Node&lt;E&gt;(e); // 存元素锁 final ReentrantLock putLock = this.putLock; // 获取锁 putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; // 元素个数小于指定容量 // 入队列 enqueue(node); // 更新元素个数，返回的是以前的元素个数 c = count.getAndIncrement(); if (c + 1 &lt; capacity) // 元素个数是否小于容量 // 唤醒在notFull条件上等待的某个线程 notFull.signal(); &#125; &#125; finally &#123; // 释放锁 putLock.unlock(); &#125; if (c == 0) // 元素个数为0，则唤醒在notEmpty条件上等待的某个线程 signalNotEmpty(); return c &gt;= 0;&#125; offer函数也用于存放元素，offer函数添加元素不会抛出异常（其他的域put函数类似）。 take123456789101112131415161718192021222324252627282930public E take() throws InterruptedException &#123; E x; int c = -1; // 获取计数器 final AtomicInteger count = this.count; // 获取取元素锁 final ReentrantLock takeLock = this.takeLock; // 如果当前线程未被中断，则获取锁 takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; // 元素个数为0 // 在notEmpty条件上等待 notEmpty.await(); &#125; // 出队列 x = dequeue(); // 更新元素个数，返回的是以前的元素个数 c = count.getAndDecrement(); if (c &gt; 1) // 元素个数大于1，则唤醒在notEmpty上等待的某个线程 notEmpty.signal(); &#125; finally &#123; // 释放锁 takeLock.unlock(); &#125; if (c == capacity) // 元素个数到达指定容量 // 唤醒在notFull条件上等待的某个线程 signalNotFull(); // 返回 return x;&#125; take函数用于获取一个元素，其与put函数相对应，其流程如下。 获取取元素锁，并上锁，如果当前线程被中断，则抛出异常，否则，进入步骤2 判断当前队列中的元素个数是否为0，若是，则在notEmpty条件上进行等待，否则，进入步骤3 出队列，更新队列元素个数，若元素个数大于1，则唤醒在notEmpty条件上等待的线程，表示可以继续取元素。进入步骤4 释放锁，判断结点出队列之前的元素个数是否为指定容量，若是，则唤醒在notFull条件上等待的线程（表示队列已满，存元素线程被阻塞了）。 dequeue123456789101112131415161718private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; // 头结点 Node&lt;E&gt; h = head; // 第一个结点 Node&lt;E&gt; first = h.next; // 头结点的next域为自身 h.next = h; // help GC // 更新头结点 head = first; // 返回头结点的元素 E x = first.item; // 头结点的item域赋值为null first.item = null; // 返回结点元素 return x;&#125; dequeue函数的作用是将头结点更新为之前头结点的下一个结点，并且将更新后的头结点的item域设置为null。 signalNotFull12345678910111213private void signalNotFull() &#123; // 存元素锁 final ReentrantLock putLock = this.putLock; // 获取锁 putLock.lock(); try &#123; // 唤醒在notFull条件上等待的某个线程 notFull.signal(); &#125; finally &#123; // 释放锁 putLock.unlock(); &#125;&#125; signalNotFull函数用于唤醒在notFull条件上等待的某个线程，其首先获取存元素锁，然后上锁，然后唤醒在notFull条件上等待的线程，最后释放存元素锁。 poll1234567891011121314151617181920212223242526272829303132public E poll() &#123; // 获取计数器 final AtomicInteger count = this.count; if (count.get() == 0) // 元素个数为0 return null; // E x = null; int c = -1; // 取元素锁 final ReentrantLock takeLock = this.takeLock; // 获取锁 takeLock.lock(); try &#123; if (count.get() &gt; 0) &#123; // 元素个数大于0 // 出队列 x = dequeue(); // 更新元素个数，返回的是以前的元素个数 c = count.getAndDecrement(); if (c &gt; 1) // 元素个数大于1 // 唤醒在notEmpty条件上等待的某个线程 notEmpty.signal(); &#125; &#125; finally &#123; // 释放锁 takeLock.unlock(); &#125; if (c == capacity) // 元素大小达到指定容量 // 唤醒在notFull条件上等待的某个线程 signalNotFull(); // 返回元素 return x;&#125; poll函数也用于存放元素，poll函数添加元素不会抛出异常（其他的与take函数类似）。 remove1234567891011121314151617181920public boolean remove(Object o) &#123; // 元素为null，返回false if (o == null) return false; // 获取存元素锁和取元素锁（不允许存或取元素） fullyLock(); try &#123; for (Node&lt;E&gt; trail = head, p = trail.next; p != null; trail = p, p = p.next) &#123; // 遍历整个链表 if (o.equals(p.item)) &#123; // 结点的值与指定值相等 // 断开结点 unlink(p, trail); return true; &#125; &#125; return false; &#125; finally &#123; fullyUnlock(); &#125;&#125; remove函数的流程如下 获取读、写锁（防止此时继续出、入队列）。进入步骤2 遍历链表，寻找指定元素，若找到，则将该结点从链表中断开，有利于被GC，进入步骤3 释放读、写锁（可以继续出、入队列）。步骤2中找到指定元素则返回true，否则，返回false。 unlink123456789101112131415void unlink(Node&lt;E&gt; p, Node&lt;E&gt; trail) &#123; // assert isFullyLocked(); // p.next is not changed, to allow iterators that are // traversing p to maintain their weak-consistency guarantee. // 结点的item域赋值为null p.item = null; // 断开p结点 trail.next = p.next; if (last == p) // 尾节点为p结点 // 重新赋值尾节点 last = trail; if (count.getAndDecrement() == capacity) // 更新元素个数，返回的是以前的元素个数，若结点个数到达指定容量 // 唤醒在notFull条件上等待的某个线程 notFull.signal();&#125; unlink函数用于将指定结点从链表中断开，并且更新队列元素个数，并且判断若之前队列元素的个数达到了指定容量，则会唤醒在notFull条件上等待的某个线程。 示例以LinkedBlockingQueue作为示例，使用ArrayBlockingQueue效果一样。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.hust.grid.leesf.collections;import java.util.concurrent.LinkedBlockingQueue;class PutThread extends Thread &#123; private LinkedBlockingQueue&lt;Integer&gt; lbq; public PutThread(LinkedBlockingQueue&lt;Integer&gt; lbq) &#123; this.lbq = lbq; &#125; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; System.out.println(&quot;put &quot; + i); lbq.put(i); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class GetThread extends Thread &#123; private LinkedBlockingQueue&lt;Integer&gt; lbq; public GetThread(LinkedBlockingQueue&lt;Integer&gt; lbq) &#123; this.lbq = lbq; &#125; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; System.out.println(&quot;take &quot; + lbq.take()); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class LinkedBlockingQueueDemo &#123; public static void main(String[] args) &#123; LinkedBlockingQueue&lt;Integer&gt; lbq = new LinkedBlockingQueue&lt;Integer&gt;(); PutThread p1 = new PutThread(lbq); GetThread g1 = new GetThread(lbq); p1.start(); g1.start(); &#125;&#125; 示例中使用了两个线程，一个用于存元素，一个用于读元素，存和读各10次，每个线程存一个元素或者读一个元素后都会休眠100ms，可以看到结果是交替打印，并且首先打印的肯定是put线程语句（因为若取线程先取元素，此时队列并没有元素，其会阻塞，等待存线程存入元素），并且最终程序可以正常结束。 若修改取元素线程，将次数修改为15次，此时程序无法正常结束，因为take方法被阻塞了，等待被唤醒。","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"并发编程 ReentrantLock","slug":"并发编程 Reentrantlock","date":"2021-07-11T16:00:00.000Z","updated":"2021-07-13T01:27:07.822Z","comments":true,"path":"2021/07/12/并发编程 Reentrantlock/","link":"","permalink":"https://tj-ever.github.io/2021/07/12/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%20Reentrantlock/","excerpt":"","text":"ReentrantLockReentrantLock是一个可重入的互斥锁，又被称为“独占锁”。 ReentrantLock锁在同一个时间点只能被一个线程锁持有；而可重入的意思是，ReentrantLock锁，可以被单个线程多次获取。 ReentrantLock分为“公平锁”和“非公平锁”，它们的区别体现在获取锁的机制上是否公平。“锁”是为了保护竞争资源，防止多个线程同时操作线程而出错，ReentrantLock在同一个时间点只能被一个线程获取(当某线程获取到“锁”时，其它线程就必须等待)；ReentraantLock是通过一个FIFO的等待队列来管理获取该锁所有线程的。在“公平锁”的机制下，线程依次排队获取锁；而“非公平锁”在锁是可获取状态时，不管自己是不是在队列的开头都会获取锁。 函数列表1234567891011121314151617181920212223242526272829303132333435363738394041// 创建一个 ReentrantLock ，默认是“非公平锁”。ReentrantLock()// 创建策略是fair的 ReentrantLock。fair为true表示是公平锁，fair为false表示是非公平锁。ReentrantLock(boolean fair)// 查询当前线程保持此锁的次数。int getHoldCount()// 返回目前拥有此锁的线程，如果此锁不被任何线程拥有，则返回 null。protected Thread getOwner()// 返回一个 collection，它包含可能正等待获取此锁的线程。protected Collection&lt;Thread&gt; getQueuedThreads()// 返回正等待获取此锁的线程估计数。int getQueueLength()// 返回一个 collection，它包含可能正在等待与此锁相关给定条件的那些线程。protected Collection&lt;Thread&gt; getWaitingThreads(Condition condition)// 返回等待与此锁相关的给定条件的线程估计数。int getWaitQueueLength(Condition condition)// 查询给定线程是否正在等待获取此锁。boolean hasQueuedThread(Thread thread)// 查询是否有些线程正在等待获取此锁。boolean hasQueuedThreads()// 查询是否有些线程正在等待与此锁有关的给定条件。boolean hasWaiters(Condition condition)// 如果是“公平锁”返回true，否则返回false。boolean isFair()// 查询当前线程是否保持此锁。boolean isHeldByCurrentThread()// 查询此锁是否由任意线程保持。boolean isLocked()// 获取锁。void lock()// 如果当前线程未被中断，则获取锁。void lockInterruptibly()// 返回用来与此 Lock 实例一起使用的 Condition 实例。Condition newCondition()// 仅在调用时锁未被另一个线程保持的情况下，才获取该锁。boolean tryLock()// 如果锁在给定等待时间内没有被另一个线程保持，且当前线程未被中断，则获取该锁。boolean tryLock(long timeout, TimeUnit unit)// 试图释放此锁。void unlock() 案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133package com.example.demo.test;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;import java.util.concurrent.locks.Condition;// 仓库class Depot &#123; // 仓库的容量 private int capacity; // 仓库的实际数量 private int size; // 独占锁 private Lock lock; // 生产条件 private Condition fullCondtion; // 消费条件 private Condition emptyCondtion; public Depot(int capacity) &#123; this.capacity = capacity; this.size = 0; this.lock = new ReentrantLock(); this.fullCondtion = lock.newCondition(); this.emptyCondtion = lock.newCondition(); &#125; public void produce(int val) &#123; lock.lock(); try &#123; // left 表示“想要生产的数量”(有可能生产量太多，需多此生产) int left = val; while (left &gt; 0) &#123; // 库存已满时，等待“消费者”消费产品。 while (size &gt;= capacity) &#123; fullCondtion.await(); &#125; // 获取“实际生产的数量”(即库存中新增的数量) // 如果“库存”+“想要生产的数量”&gt;“总的容量”，则“实际增量”=“总的容量”-“当前容量”。(此时填满仓库) // 否则“实际增量”=“想要生产的数量” int inc = (size + left) &gt; capacity ? (capacity - size) : left; size += inc; left -= inc; System.out.printf(&quot;%s produce(%3d) --&gt; left=%3d, inc=%3d, size=%3d\\n&quot;, Thread.currentThread().getName(), val, left, inc, size); // 通知“消费者”可以消费了。 emptyCondtion.signal(); &#125; &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; public void consume(int val) &#123; lock.lock(); try &#123; // left 表示“客户要消费数量”(有可能消费量太大，库存不够，需多此消费) int left = val; while (left &gt; 0) &#123; // 库存为0时，等待“生产者”生产产品。 while (size &lt;= 0) emptyCondtion.await(); // 获取“实际消费的数量”(即库存中实际减少的数量) // 如果“库存”&lt;“客户要消费的数量”，则“实际消费量”=“库存”； // 否则，“实际消费量”=“客户要消费的数量”。 int dec = (size &lt; left) ? size : left; size -= dec; left -= dec; System.out.printf(&quot;%s consume(%3d) &lt;-- left=%3d, dec=%3d, size=%3d\\n&quot;, Thread.currentThread().getName(), val, left, dec, size); fullCondtion.signal(); &#125; &#125; catch (InterruptedException e) &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; public String toString() &#123; return &quot;capacity:&quot; + capacity + &quot;, actual size:&quot; + size; &#125;&#125;;// 生产者class Producer &#123; private Depot depot; public Producer(Depot depot) &#123; this.depot = depot; &#125; // 消费产品：新建一个线程向仓库中生产产品。 public void produce(final int val) &#123; new Thread() &#123; public void run() &#123; depot.produce(val); &#125; &#125;.start(); &#125;&#125;// 消费者class Customer &#123; private Depot depot; public Customer(Depot depot) &#123; this.depot = depot; &#125; // 消费产品：新建一个线程从仓库中消费产品。 public void consume(final int val) &#123; new Thread() &#123; public void run() &#123; depot.consume(val); &#125; &#125;.start(); &#125;&#125;public class LockTest &#123; public static void main(String[] args) &#123; Depot mDepot = new Depot(100); Producer mPro = new Producer(mDepot); Customer mCus = new Customer(mDepot); mPro.produce(60); mPro.produce(120); mCus.consume(90); mCus.consume(150); mPro.produce(110); &#125;&#125; 公平锁ReentrantLock中，包含了Sync对象；而且，Sync是AQS的子类；Sync有两个子类FairSync(公平锁)和NonFairSync(非公平锁)。 源码分析lock()lock()在ReentrantLock.java的FairSync类中实现，它的源码如下： 123final void lock() &#123; acquire(1);&#125; “1”的含义，它是设置“锁的状态”的参数。对于“独占锁”而言，锁处于可获取状态时，它的状态值是0；锁被线程初次获取到了，它的状态值就变成了1。由于ReentrantLock(公平锁/非公平锁)是可重入锁，所以“独占锁”可以被单个线程多此获取，每获取1次就将锁的状态+1。也就是说，初次获取锁时，通过acquire(1)将锁的状态值设为1；再次获取锁时，将锁的状态值设为2；依次类推…这就是为什么获取锁时，传入的参数是1的原因了。可重入就是指锁可以被单个线程多次获取。 acquire()acquire()在AQS中实现的，它的源码如下： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire()尝试直接去获取资源，如果成功则直接返回（这里体现了非公平锁，每个线程获取锁时会尝试直接抢占加塞一次，而CLH队列中可能还有别的线程在等待）； addWaiter()将该线程加入等待队列的尾部，并标记为独占模式； acquireQueued()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 tryAcquire()公平锁的tryAcquire()在ReentrantLock.java的FairSync类中实现，源码如下： 1234567891011121314151617181920212223242526protected final boolean tryAcquire(int acquires) &#123; // 获取“当前线程” final Thread current = Thread.currentThread(); // 获取“独占锁”的状态 int c = getState(); // c=0意味着“锁没有被任何线程锁拥有”， if (c == 0) &#123; // 若“锁没有被任何线程锁拥有”， // 则判断“当前线程”是不是CLH队列中的第一个线程线程， // 若是的话，则获取该锁，设置锁的状态，并切设置锁的拥有者为“当前线程”。 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 如果“独占锁”的拥有者已经为“当前线程”， // 则将更新锁的状态。 int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; tryAcquire()的作用就是尝试去获取锁。注意，这里只是尝试！尝试成功的话，返回true；尝试失败的话，返回false，后续再通过其它办法来获取该锁。 hasQueuedPredecessors()hasQueuedPredecessors()在AQS中实现，源码如下： 1234567public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; hasQueuedPredecessors() 是通过判断”当前线程”是不是在CLH队列的队首，来返回AQS中是不是有比“当前线程”等待更久的线程。 下面对head、tail和Node进行说明。 Node源码Node就是CLH队列的节点。Node在AQS中实现，它的数据结构如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465private transient volatile Node head; // CLH队列的队首private transient volatile Node tail; // CLH队列的队尾// CLH队列的节点static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; // 线程已被取消，对应的waitStatus的值 static final int CANCELLED = 1; // “当前线程的后继线程需要被unpark(唤醒)”，对应的waitStatus的值。 // 一般发生情况是：当前线程的后继线程处于阻塞状态，而当前线程被release或cancel掉，因此需要唤醒当前线程的后继线程。 static final int SIGNAL = -1; // 线程(处在Condition休眠状态)在等待Condition唤醒，对应的waitStatus的值 static final int CONDITION = -2; // (共享锁)其它线程获取到“共享锁”，对应的waitStatus的值 static final int PROPAGATE = -3; // waitStatus为“CANCELLED, SIGNAL, CONDITION, PROPAGATE”时分别表示不同状态， // 若waitStatus=0，则意味着当前线程不属于上面的任何一种状态。 volatile int waitStatus; // 前一节点 volatile Node prev; // 后一节点 volatile Node next; // 节点所对应的线程 volatile Thread thread; // nextWaiter是“区别当前CLH队列是 ‘独占锁’队列 还是 ‘共享锁’队列 的标记” // 若nextWaiter=SHARED，则CLH队列是“共享锁”队列。 // 若nextWaiter=EXCLUSIVE，(即nextWaiter=null)，则CLH队列是“独占锁”队列； Node nextWaiter; // “共享锁”则返回true，“独占锁”则返回false。 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 返回前一节点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; // 构造函数。thread是节点所对应的线程，mode是用来表示thread的锁是“独占锁”还是“共享锁”。 Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; // 构造函数。thread是节点所对应的线程，waitStatus是线程的等待状态。 Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; Node是CLH队列的节点，代表“等待锁的线程队列”。每个Node都会一个线程对应。每个Node会通过prev和next分别指向上一个节点和下一个节点，这分别代表上一个等待线程和下一个等待线程。Node通过waitStatus保存线程的等待状态。Node通过nextWaiter来区分线程是“独占锁”线程还是“共享锁”线程。如果是“独占锁”线程，则nextWaiter的值为EXCLUSIVE；如果是“共享锁”线程，则nextWaiter的值是SHARED。 compareAndSetState()compareAndSetState()在AQS中实现。它的源码如下： 123protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; compareAndSwapInt() 是sun.misc.Unsafe类中的一个本地方法。对此，我们需要了解的是 compareAndSetState(expect, update) 是以原子的方式操作当前线程；若当前线程的状态为expect，则设置它的状态为update。 setExclusiveOwnerThread()setExclusiveOwnerThread()在AbstractOwnableSynchronizer.java中实现，它的源码如下： 12345// exclusiveOwnerThread是当前拥有“独占锁”的线程private transient Thread exclusiveOwnerThread;protected final void setExclusiveOwnerThread(Thread t) &#123; exclusiveOwnerThread = t;&#125; setExclusiveOwnerThread()的作用就是，设置线程t为当前拥有“独占锁”的线程。 getState(), setState()12345678910// 锁的状态private volatile int state;// 设置锁的状态protected final void setState(int newState) &#123; state = newState;&#125;// 获取锁的状态protected final int getState() &#123; return state;&#125; state表示锁的状态，对于“独占锁”而已，state=0表示锁是可获取状态(锁没有被任何线程锁持有)。由于java中的独占锁是可重入的，state的值可以&gt;1。 小结tryAcquire()的作用就是让“当前线程”尝试获取锁。获取成功返回true，失败则返回false。 addWaiter(Node.EXCLUSIVE)addWaiter(Node.EXCLUSIVE)的作用是，创建“当前线程”的Node节点，且Node中记录“当前线程”对应的锁是“独占锁”类型，并且将该节点添加到CLH队列的末尾。 addWaiter()addWaiter()在AQS中实现，源码如下： 12345678910111213141516private Node addWaiter(Node mode) &#123; // 新建一个Node节点，节点对应的线程是“当前线程”，“当前线程”的锁的模型是mode。 Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 若CLH队列不为空，则将“当前线程”添加到CLH队列末尾 if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 若CLH队列为空，则调用enq()新建CLH队列，然后再将“当前线程”添加到CLH队列中。 enq(node); return node;&#125; compareAndSetTail()compareAndSetTail()在AQS中实现，源码如下： 123private final boolean compareAndSetTail(Node expect, Node update) &#123; return unsafe.compareAndSwapObject(this, tailOffset, expect, update);&#125; compareAndSetTail也属于CAS函数，也是通过“本地方法”实现的。compareAndSetTail(expect, update)会以原子的方式进行操作，它的作用是判断CLH队列的队尾是不是为expect，是的话，就将队尾设为update。 enq()enq()在AQS中实现，源码如下： 123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; enq()的作用很简单。如果CLH队列为空，则新建一个CLH表头；然后将node添加到CLH末尾。否则，直接将node添加到CLH末尾。 小结addWaiter()的作用，就是将当前线程添加到CLH队列中。这就意味着将当前线程添加到等待获取“锁”的等待线程队列中了。 acquireQueued()前面，我们已经将当前线程添加到CLH队列中了。而acquireQueued()的作用就是逐步的去执行CLH队列的线程，如果当前线程获取到了锁，则返回；否则，当前线程进行休眠，直到唤醒并重新获取锁了才返回。下面，我们看看acquireQueued()的具体流程。 acquireQueued()acquireQueued()在AQS中实现，源码如下： 12345678910111213141516171819202122232425final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; // interrupted表示在CLH队列的调度中， // “当前线程”在休眠时，有没有被中断过。 boolean interrupted = false; for (;;) &#123; // 获取上一个节点。 // node是“当前线程”对应的节点，这里就意味着“获取上一个等待锁的线程”。 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; acquireQueued()的目的是从队列中获取锁。 shouldParkAfterFailedAcquire()shouldParkAfterFailedAcquire()在AQS中实现，源码如下： 12345678910111213141516171819// 返回“当前线程是否应该阻塞”private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 前继节点的状态 int ws = pred.waitStatus; // 如果前继节点是SIGNAL状态，则意味这当前线程需要被unpark唤醒。此时，返回true。 if (ws == Node.SIGNAL) return true; // 如果前继节点是“取消”状态，则设置 “当前节点”的 “当前前继节点” 为 “‘原前继节点’的前继节点”。 if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 如果前继节点为“0”或者“共享锁”状态，则设置前继节点为SIGNAL状态。 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; shouldParkAfterFailedAcquire()通过以下规则，判断“当前线程”是否需要被阻塞。 规则1：如果前继节点状态为SIGNAL，表明当前节点需要被unpark(唤醒)，此时则返回true。规则2：如果前继节点状态为CANCELLED(ws&gt;0)，说明前继节点已经被取消，则通过先前回溯找到一个有效(非CANCELLED状态)的节点，并返回false。规则3：如果前继节点状态为非SIGNAL、非CANCELLED，则设置前继的状态为SIGNAL，并返回false。 如果“规则1”发生，即“前继节点是SIGNAL”状态，则意味着“当前线程”需要被阻塞。接下来会调用parkAndCheckInterrupt()阻塞当前线程，直到当前先被唤醒才从parkAndCheckInterrupt()中返回。 parkAndCheckInterrupt())123456private final boolean parkAndCheckInterrupt() &#123; // 通过LockSupport的park()阻塞“当前线程”。 LockSupport.park(this); // 返回线程的中断状态。 return Thread.interrupted();&#125; parkAndCheckInterrupt()的作用是阻塞当前线程，并且返回“线程被唤醒之后”的中断状态。它会先通过LockSupport.park()阻塞“当前线程”，然后通过Thread.interrupted()返回线程的中断状态。 这里介绍一下线程被阻塞之后如何唤醒。一般有2种情况：第1种情况：unpark()唤醒。“前继节点对应的线程”使用完锁之后，通过unpark()方式唤醒当前线程。第2种情况：中断唤醒。其它线程通过interrupt()中断当前线程。 补充：LockSupport()中的park(),unpark()的作用 和 Object中的wait(),notify()作用类似，是阻塞/唤醒。它们的用法不同，park(),unpark()是轻量级的，而wait(),notify()是必须先通过Synchronized获取同步锁。 小结acquireQueued()的作用就是“当前线程”会根据公平性原则进行阻塞等待，直到获取锁为止；并且返回当前线程在等待过程中有没有并中断过。 selfInterrupt()selfInterrupt()是AQS中实现，源码如下： 123private static void selfInterrupt() &#123; Thread.currentThread().interrupt();&#125; selfInterrupt()的代码很简单，就是“当前线程”自己产生一个中断。但是，为什么需要这么做呢？这必须结合acquireQueued()进行分析。如果在acquireQueued()中，当前线程被中断过，则执行selfInterrupt()；否则不会执行。 在acquireQueued()中，即使是线程在阻塞状态被中断唤醒而获取到cpu执行权利；但是，如果该线程的前面还有其它等待锁的线程，根据公平性原则，该线程依然无法获取到锁。它会再次阻塞！ 该线程再次阻塞，直到该线程被它的前面等待锁的线程锁唤醒；线程才会获取锁，然后“真正执行起来”！也就是说，在该线程“成功获取锁并真正执行起来”之前，它的中断会被忽略并且中断标记会被清除！ 因为在parkAndCheckInterrupt()中，我们线程的中断状态时调用了Thread.interrupted()。该函数不同于Thread的isInterrupted()函数，isInterrupted()仅仅返回中断状态，而interrupted()在返回当前中断状态之后，还会清除中断状态。 正因为之前的中断状态被清除了，所以这里需要调用selfInterrupt()重新产生一个中断！ 小结selfInterrupt()的作用就是当前线程自己产生一个中断。 释放公平锁unlock()unlock()在ReentrantLock.java中实现的，源码如下： 123public void unlock() &#123; sync.release(1);&#125; unlock()是解锁函数，它是通过AQS的release()函数来实现的。在这里，“1”的含义和“获取锁的函数acquire(1)的含义”一样，它是设置“释放锁的状态”的参数。由于“公平锁”是可重入的，所以对于同一个线程，每释放锁一次，锁的状态-1。 关于AQS, ReentrantLock 和 sync的关系如下： 12345678910public class ReentrantLock implements Lock, java.io.Serializable &#123; private final Sync sync; abstract static class Sync extends AbstractQueuedSynchronizer &#123; ... &#125; ...&#125; 从中，我们发现：sync是ReentrantLock.java中的成员对象，而Sync是AQS的子类。 release()release()在AQS中实现的，源码如下： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125; release()会先调用tryRelease()来尝试释放当前线程锁持有的锁。成功的话，则唤醒后继等待线程，并返回true。否则，直接返回false。 tryRelease()tryRelease()在ReentrantLock.java的Sync类中实现，源码如下： 1234567891011121314151617protected final boolean tryRelease(int releases) &#123; // c是本次释放锁之后的状态 int c = getState() - releases; // 如果“当前线程”不是“锁的持有者”，则抛出异常！ if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果“锁”已经被当前线程彻底释放，则设置“锁”的持有者为null，即锁是可获取状态。 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; // 设置当前线程的锁的状态。 setState(c); return free;&#125; tryRelease()的作用是尝试释放锁。如果“当前线程”不是“锁的持有者”，则抛出异常。如果“当前线程”在本次释放锁操作之后，对锁的拥有状态是0(即，当前线程彻底释放该“锁”)，则设置“锁”的持有者为null，即锁是可获取状态。同时，更新当前线程的锁的状态为0。 getExclusiveOwnerThread(), setExclusiveOwnerThread()在AQS的父类AbstractOwnableSynchronizer.java中定义，源码如下： 123456789101112131415161718public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; // “锁”的持有线程 private transient Thread exclusiveOwnerThread; // 设置“锁的持有线程”为t protected final void setExclusiveOwnerThread(Thread t) &#123; exclusiveOwnerThread = t; &#125; // 获取“锁的持有线程” protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125; ...&#125; unparkSuccessor()在release()中“当前线程”释放锁成功的话，会唤醒当前线程的后继线程。根据CLH队列的FIFO规则，“当前线程”(即已经获取锁的线程)肯定是head；如果CLH队列非空的话，则唤醒锁的下一个等待线程。下面看看unparkSuccessor()的源码，它在AQS中实现。 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; // 获取当前线程的状态 int ws = node.waitStatus; // 如果状态&lt;0，则设置状态=0 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); //获取当前节点的“有效的后继节点”，无效的话，则通过for循环进行获取。 // 这里的有效，是指“后继节点对应的线程状态&lt;=0” Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 唤醒“后继节点对应的线程” if (s != null) LockSupport.unpark(s.thread);&#125; unparkSuccessor()的作用是“唤醒当前线程的后继线程”。后继线程被唤醒之后，就可以获取该锁并恢复运行了。 总结“释放锁”的过程相对“获取锁”的过程比较简单。释放锁时，主要进行的操作，是更新当前线程对应的锁的状态。如果当前线程对锁已经彻底释放，则设置“锁”的持有线程为null，设置当前线程的状态为空，然后唤醒后继线程。 获取非公平锁lock()lock()在ReentrantLock.java的NonfairSync类中实现，它的源码如下： 123456final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1);&#125; lock()会先通过compareAndSet(0, 1)来判断“锁”是不是空闲状态。是的话，“当前线程”直接获取“锁”；否则的话，调用acquire(1)获取锁。compareAndSetState()是CAS函数，它的作用是比较并设置当前锁的状态。若锁的状态值为0，则设置锁的状态值为1。setExclusiveOwnerThread(Thread.currentThread())的作用是，设置“当前线程”为“锁”的持有者。 “公平锁”和“非公平锁”关于lock()的对比 12公平锁 -- 公平锁的lock()函数，会直接调用acquire(1)。非公平锁 -- 非公平锁会先判断当前锁的状态是不是空闲，是的话，就不排队，而是直接获取锁。 acquire()acquire()在AQS中实现的，它的源码如下： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; “当前线程”首先通过tryAcquire()尝试获取锁。获取成功的话，直接返回；尝试失败的话，进入到等待队列依次排序，然后获取锁。“当前线程”尝试失败的情况下，会先通过addWaiter(Node.EXCLUSIVE)来将“当前线程”加入到”CLH队列(非阻塞的FIFO队列)”末尾。然后，调用acquireQueued()获取锁。在acquireQueued()中，当前线程会等待它在“CLH队列”中前面的所有线程执行并释放锁之后，才能获取锁并返回。如果“当前线程”在休眠等待过程中被中断过，则调用selfInterrupt()来自己产生一个中断。 非公平锁的tryAcquire()在ReentrantLock.java的NonfairSync类中实现，源码如下： 123protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires);&#125; nonfairTryAcquire()在ReentrantLock.java的Sync类中实现，源码如下： 123456789101112131415161718192021222324final boolean nonfairTryAcquire(int acquires) &#123; // 获取“当前线程” final Thread current = Thread.currentThread(); // 获取“锁”的状态 int c = getState(); // c=0意味着“锁没有被任何线程锁拥有” if (c == 0) &#123; // 若“锁没有被任何线程锁拥有”，则通过CAS函数设置“锁”的状态为acquires。 // 同时，设置“当前线程”为锁的持有者。 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 如果“锁”的持有者已经是“当前线程”， // 则将更新锁的状态。 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false;&#125; 如果“锁”没有被任何线程拥有，则通过CAS函数设置“锁”的状态为acquires，同时，设置“当前线程”为锁的持有者，然后返回true。如果“锁”的持有者已经是当前线程，则将更新锁的状态即可。如果不是上面的两种情况，则认为尝试失败。 “公平锁”和“非公平锁”关于tryAcquire()的对比 123公平锁和非公平锁，它们尝试获取锁的方式不同。公平锁在尝试获取锁时，即使“锁”没有被任何线程锁持有，它也会判断自己是不是CLH等待队列的表头；是的话，才获取锁。而非公平锁在尝试获取锁时，如果“锁”没有被任何线程持有，则不管它在CLH队列的何处，它都直接获取锁。 总结公平锁和非公平锁的区别，是在获取锁的机制上的区别。表现在，在尝试获取锁时 —— 公平锁，只有在当前线程是CLH等待队列的表头时，才获取锁；而非公平锁，只要当前锁处于空闲状态，则直接获取锁，而不管CLH等待队列中的顺序。只有当非公平锁尝试获取锁失败的时候，它才会像公平锁一样，进入CLH等待队列排序等待。","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"并发编程 Tools&CountDownLatch&Semaphore","slug":"并发编程 CountDownLatch&Semaphore","date":"2021-07-06T16:00:00.000Z","updated":"2021-07-10T13:11:57.852Z","comments":true,"path":"2021/07/07/并发编程 CountDownLatch&Semaphore/","link":"","permalink":"https://tj-ever.github.io/2021/07/07/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%20CountDownLatch&Semaphore/","excerpt":"","text":"Semaphore 使用及原理Semaphore 通常我们叫它信号量， 可以用来控制同时访问特定资源的线程数量，通过协调各个线程，以保证合理的使用资源。 可以把它简单的理解成我们停车场入口立着的那个显示屏，每有一辆车进入停车场显示屏就会显示剩余车位减1，每有一辆车从停车场出去，显示屏上显示的剩余车辆就会加1，当显示屏上的剩余车位为0时，停车场入口的栏杆就不会再打开，车辆就无法进入停车场了，直到有一辆车从停车场出去为止。 使用场景通常用于那些资源有明确访问数量限制的场景，常用于限流 。 比如：数据库连接池，同时进行连接的线程有数量限制，连接不能超过一定的数量，当连接达到了限制数量后，后面的线程只能排队等前面的线程释放了数据库连接才能获得数据库连接。 比如：停车场场景，车位数量有限，同时只能容纳多少台车，车位满了之后只有等里面的车离开停车场外面的车才可以进入。 常用方法1234567891011121314151617181920212223242526272829303132333435#构造方法public Semaphore(int permits)public Semaphore(int permits, boolean fair)permits 表示许可线程的数量fair 表示公平性，如果这个设为 true 的话，下次执行的线程会是等待最久的线程acquire() 获取一个令牌，在获取到令牌、或者被其他线程调用中断之前线程一直处于阻塞状态。acquire(int permits) 获取一个令牌，在获取到令牌、或者被其他线程调用中断、或超时之前线程一直处于阻塞状态。 acquireUninterruptibly() 获取一个令牌，在获取到令牌之前线程一直处于阻塞状态（忽略中断）。 tryAcquire()尝试获得令牌，返回获取令牌成功或失败，不阻塞线程。tryAcquire(long timeout, TimeUnit unit)尝试获得令牌，在超时时间内循环尝试获取，直到尝试获取成功或超时返回，不阻塞线程。release()释放一个令牌，唤醒一个获取令牌不成功的阻塞线程。hasQueuedThreads()等待队列里是否还存在等待线程。getQueueLength()获取等待队列里阻塞的线程数。drainPermits()清空令牌把可用令牌数置为0，返回清空令牌的数量。availablePermits()返回可用的令牌数量。 案例每个停车场入口都有一个提示牌，上面显示着停车场的剩余车位还有多少，当剩余车位为0时，不允许车辆进入停车场，直到停车场里面有车离开停车场，这时提示牌上会显示新的剩余车位数。 业务场景 ： 1、停车场容纳总停车量10。 2、当一辆车进入停车场后，显示牌的剩余车位数响应的减1. 3、每有一辆车驶出停车场后，显示牌的剩余车位数响应的加1。 4、停车场剩余车位不足时，车辆只能在外面等待。 12345678910111213141516171819202122232425262728293031package com.example.demo.test;import java.util.Random;import java.util.concurrent.Semaphore;public class TestCar &#123; //停车场同时容纳的车辆10 private static Semaphore semaphore = new Semaphore(10); public static void main(String[] args) &#123; for (int i = 1; i &lt;= 100; i++) &#123; Thread thread = new Thread(() -&gt; &#123; try &#123; System.out.println(&quot;====&quot; + Thread.currentThread().getName() + &quot;来到停车场&quot;); if (semaphore.availablePermits() == 0) &#123; System.out.println(Thread.currentThread().getName()+&quot;请求车位，车位不足，请耐心等待&quot;); &#125; semaphore.acquire();//获取令牌尝试进入停车场 System.out.println(Thread.currentThread().getName() + &quot;成功进入停车场&quot;); Thread.sleep(new Random().nextInt(10000));//模拟车辆在停车场停留的时间 System.out.println(Thread.currentThread().getName() + &quot;驶出停车场&quot;); semaphore.release();//释放令牌，腾出停车场车位 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;, i + &quot;号车&quot;); thread.start(); &#125; &#125;&#125; 实现原理初始化1Semaphore semaphore=new Semaphore(2); 1、当调用new Semaphore(2) 方法时，默认会创建一个非公平的锁的同步阻塞队列。 2、把初始令牌数量赋值给同步队列的state状态，state的值就代表当前所剩余的令牌数量。 初始化完成后同步队列信息如下图： 获取令牌1semaphore.acquire(); 1、当前线程会尝试去同步队列获取一个令牌，获取令牌的过程也就是使用原子的操作去修改同步队列的state ,获取一个令牌则修改为state=state-1。 2、 当计算出来的state&lt;0，则代表令牌数量不足，此时会创建一个Node节点加入阻塞队列，挂起当前线程。 3、当计算出来的state&gt;=0，则代表获取令牌成功。 源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 获取1个令牌 */public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125;----------------------------------------------------------------------------------------------------------------/** * 共享模式下获取令牌，获取成功则返回，失败则加入阻塞队列，挂起线程 * @param arg * @throws InterruptedException */public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); //尝试获取令牌，arg为获取令牌个数，当可用令牌数减当前令牌数结果小于0,则创建一个节点加入阻塞队列，挂起当前线程。 if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125;----------------------------------------------------------------------------------------------------------------/** * 1、创建节点，加入阻塞队列， * 2、重双向链表的head，tail节点关系，清空无效节点 * 3、挂起当前节点线程 * @param arg * @throws InterruptedException */private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; //创建节点加入阻塞队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; //获得当前节点pre节点 final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg);//返回锁的state if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; //重组双向链表，清空无效节点，挂起当前线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 线程1、线程2、线程3、分别调用semaphore.acquire(),整个过程队列信息变化如下图： 释放令牌1semaphore.release(); 当调用semaphore.release() 方法时 1、线程会尝试释放一个令牌，释放令牌的过程也就是把同步队列的state修改为state=state+1的过程 2、释放令牌成功之后，同时会唤醒同步队列中的一个线程。 3、被唤醒的节点会重新尝试去修改state=state-1 的操作，如果state&gt;=0则获取令牌成功，否则重新进入阻塞队列，挂起线程。 源码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 释放令牌 */public void release() &#123; sync.releaseShared(1);&#125;/** * 释放共享锁，同时会唤醒同步队列中的一个线程。 * @param arg * @return */public final boolean releaseShared(int arg) &#123; //释放共享锁 if (tryReleaseShared(arg)) &#123; //唤醒所有共享节点线程 doReleaseShared(); return true; &#125; return false;&#125;/** * 唤醒同步队列中的一个线程 */private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123;//是否需要唤醒后继节点 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0))//修改状态为初始0 continue; unparkSuccessor(h);//唤醒h.nex节点线程 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)); &#125; if (h == head)// loop if head changed break; &#125;&#125; 继上面的图，当我们线程1调用semaphore.release(); 时候整个流程如下图： CountDownLatch使用及原理CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 CountDownLatch和CyclicBarrier的区别 CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待。 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 常用方法1234567891011121314151617CountDownLatch(int count)构造一个用给定计数初始化的 CountDownLatch。// 使当前线程在锁存器倒计数至零之前一直等待，除非线程被中断。void await() // 使当前线程在锁存器倒计数至零之前一直等待，除非线程被中断或超出了指定的等待时间。boolean await(long timeout, TimeUnit unit) // 递减锁存器的计数，如果计数到达零，则释放所有等待的线程。void countDown() // 返回当前计数。long getCount() // 返回标识此锁存器及其状态的字符串。String toString() 源码分析CountDownLatch(int count)1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count);&#125; 说明：该函数是创建一个Sync对象，而Sync是继承于AQS类。 123Sync(int count) &#123; setState(count);&#125; setState()在AQS中实现， 123protected final void setState(long newState) &#123; state = newState;&#125; 说明：在AQS中，state是一个private volatile long类型的对象。对于CountDownLatch而言，state表示的”锁计数器“。CountDownLatch中的getCount()最终是调用AQS中的getState()，返回的state对象，即”锁计数器“。 await()123public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 说明：该函数实际上是调用的AQS的acquireSharedInterruptibly(1); 1234567public final void acquireSharedInterruptibly(long arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 说明：acquireSharedInterruptibly()的作用是获取共享锁。如果当前线程是中断状态，则抛出异常InterruptedException。否则，调用tryAcquireShared(arg)尝试获取共享锁；尝试成功则返回，否则就调用doAcquireSharedInterruptibly()。 doAcquireSharedInterruptibly()会使当前线程一直等待，直到当前线程获取到共享锁(或被中断)才返回。 tryAcquireShared()在CountDownLatch.java中被重写，它的源码如下： 123protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; 说明：tryAcquireShared()的作用是尝试获取共享锁。 如果”锁计数器=0”，即锁是可获取状态，则返回1；否则，锁是不可获取状态，则返回-1。 1234567891011121314151617181920212223242526272829303132private void doAcquireSharedInterruptibly(long arg) throws InterruptedException &#123; // 创建&quot;当前线程&quot;的Node节点，且Node中记录的锁是&quot;共享锁&quot;类型；并将该节点添加到CLH队列末尾。 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 获取上一个节点。 // 如果上一节点是CLH队列的表头，则&quot;尝试获取共享锁&quot;。 final Node p = node.predecessor(); if (p == head) &#123; long r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; // (上一节点不是CLH队列的表头) 当前线程一直等待，直到获取到共享锁。 // 如果线程在等待过程中被中断过，则再次中断该线程(还原之前的中断状态)。 // 如果在尝试获取锁失败之后，线程应该等待，则返回true；否则，返回false。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; // 当前线程会进入等待状态，直到获取到共享锁才继续运行。 parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; countDown()123public void countDown() &#123; sync.releaseShared(1);&#125; 说明：该函数实际上调用releaseShared(1)释放共享锁。 releaseShared()在AQS中实现，源码如下： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 说明：releaseShared()的目的是让当前线程释放它所持有的共享锁。它首先会通过tryReleaseShared()去尝试释放共享锁。尝试成功，则直接返回；尝试失败，则通过doReleaseShared()去释放共享锁。 tryReleaseShared()在CountDownLatch.java中被重写，源码如下： 1234567891011121314protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; // 获取“锁计数器”的状态 int c = getState(); if (c == 0) return false; // “锁计数器”-1 int nextc = c-1; // 通过CAS函数进行赋值。 if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 说明：tryReleaseShared()的作用是释放共享锁，将“锁计数器”的值-1。 总结CountDownLatch是通过“共享锁”实现的。 在创建CountDownLatch中时，会传递一个int类型参数count，该参数是“锁计数器”的初始状态，表示该“共享锁”最多能被count给线程同时获取。当某线程调用该CountDownLatch对象的await()方法时，该线程会等待“共享锁”可用时，才能获取“共享锁”进而继续运行。而“共享锁”可用的条件，就是“锁计数器”的值为0！而“锁计数器”的初始值为count，每当一个线程调用该CountDownLatch对象的countDown()方法时，才将“锁计数器”-1；通过这种方式，必须有count个线程调用countDown()之后，“锁计数器”才为0，而前面提到的等待线程才能继续运行！ 案例下面通过CountDownLatch实现：”主线程”等待”5个子线程”全部都完成”指定的工作(休眠1000ms)”之后，再继续运行。 123456789101112131415161718192021222324252627282930313233343536373839import java.util.concurrent.CountDownLatch;import java.util.concurrent.CyclicBarrier;public class CountDownLatchTest1 &#123; private static int LATCH_SIZE = 5; private static CountDownLatch doneSignal; public static void main(String[] args) &#123; try &#123; doneSignal = new CountDownLatch(LATCH_SIZE); // 新建5个任务 for(int i=0; i&lt;LATCH_SIZE; i++) new InnerThread().start(); System.out.println(&quot;main await begin.&quot;); // &quot;主线程&quot;等待线程池中5个任务的完成 doneSignal.await(); System.out.println(&quot;main await finished.&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; static class InnerThread extends Thread&#123; public void run() &#123; try &#123; Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + &quot; sleep 1000ms.&quot;); // 将CountDownLatch的数值减1 doneSignal.countDown(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; CyclicBarrier使用及原理CyclicBarrier是一个同步辅助类，允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 注意比较CountDownLatch和CyclicBarrier： CountDownLatch的作用是允许1或N个线程等待其他线程完成执行；而CyclicBarrier则是允许N个线程相互等待。 CountDownLatch的计数器无法被重置；CyclicBarrier的计数器可以被重置后使用，因此它被称为是循环的barrier。 常用方法1234567891011121314151617181920212223CyclicBarrier(int parties)创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，但它不会在启动 barrier 时执行预定义的操作。CyclicBarrier(int parties, Runnable barrierAction)创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动 barrier 时执行给定的屏障操作，该操作由最后一个进入 barrier 的线程执行。int await()在所有参与者都已经在此 barrier 上调用 await 方法之前，将一直等待。int await(long timeout, TimeUnit unit)在所有参与者都已经在此屏障上调用 await 方法之前将一直等待,或者超出了指定的等待时间。int getNumberWaiting()返回当前在屏障处等待的参与者数目。int getParties()返回要求启动此 barrier 的参与者数目。boolean isBroken()查询此屏障是否处于损坏状态。void reset()将屏障重置为其初始状态。 源码分析构造函数123456789101112//CyclicBarrier的构造函数共2个：CyclicBarrier 和 CyclicBarrier(int parties, Runnable barrierAction)。//第1个构造函数是调用第2个构造函数来实现的，下面第2个构造函数的源码。public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); // parties表示“必须同时到达barrier的线程个数”。 this.parties = parties; // count表示“处在等待状态的线程个数”。 this.count = parties; // barrierCommand表示“parties个线程到达barrier时，会执行的动作”。 this.barrierCommand = barrierAction;&#125; 等待函数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen; &#125;&#125;private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; // 获取“独占锁(lock)” lock.lock(); try &#123; // 保存“当前的generation” final Generation g = generation; // 若“当前generation已损坏”，则抛出异常。 if (g.broken) throw new BrokenBarrierException(); // 如果当前线程被中断，则通过breakBarrier()终止CyclicBarrier，唤醒CyclicBarrier中所有等待线程。 if (Thread.interrupted()) &#123; breakBarrier(); throw new InterruptedException(); &#125; // 将“count计数器”-1 int index = --count; // 如果index=0，则意味着“有parties个线程到达barrier”。 if (index == 0) &#123; // tripped boolean ranAction = false; try &#123; // 如果barrierCommand不为null，则执行该动作。 final Runnable command = barrierCommand; if (command != null) command.run(); ranAction = true; // 唤醒所有等待线程，并更新generation。 nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) breakBarrier(); &#125; &#125; // 当前线程一直阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或 “超时”这3者之一发生， // 当前线程才继续执行。 for (;;) &#123; try &#123; // 如果不是“超时等待”，则调用awati()进行等待；否则，调用awaitNanos()进行等待。 if (!timed) trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; // 如果等待过程中，线程被中断，则执行下面的函数。 if (g == generation &amp;&amp; ! g.broken) &#123; breakBarrier(); throw ie; &#125; else &#123; Thread.currentThread().interrupt(); &#125; &#125; // 如果“当前generation已经损坏”，则抛出异常。 if (g.broken) throw new BrokenBarrierException(); // 如果“generation已经换代”，则返回index。 if (g != generation) return index; // 如果是“超时等待”，并且时间已到，则通过breakBarrier()终止CyclicBarrier，唤醒CyclicBarrier中所有等待线程。 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; // 释放“独占锁(lock)” lock.unlock(); &#125;&#125; 说明：dowait()的作用就是让当前线程阻塞，直到“有parties个线程到达barrier” 或 “当前线程被中断” 或 “超时”这3者之一发生，当前线程才继续执行。 (01) generation是CyclicBarrier的一个成员变量，它的定义如下： 12345private Generation generation = new Generation();private static class Generation &#123; boolean broken = false;&#125; 在CyclicBarrier中，同一批的线程属于同一代，即同一个Generation；CyclicBarrier中通过generation对象，记录属于哪一代。当有parties个线程到达barrier，generation就会被更新换代。 (02) 如果当前线程被中断，即Thread.interrupted()为true；则通过breakBarrier()终止CyclicBarrier。 breakBarrier()的源码如下： 12345private void breakBarrier() &#123; generation.broken = true; count = parties; trip.signalAll();&#125; breakBarrier()会设置当前中断标记broken为true，意味着“将该Generation中断”；同时，设置count=parties，即重新初始化count；最后，通过signalAll()唤醒CyclicBarrier上所有的等待线程。 (03) 将“count计数器”-1，即–count；然后判断是不是“有parties个线程到达barrier”，即index是不是为0。 当index=0时，如果barrierCommand不为null，则执行该barrierCommand，barrierCommand就是我们创建CyclicBarrier时，传入的Runnable对象。然后，调用nextGeneration()进行换代工作，nextGeneration()的源码如下： 12345private void nextGeneration() &#123; trip.signalAll(); count = parties; generation = new Generation();&#125; 首先，它会调用signalAll()唤醒CyclicBarrier上所有的等待线程；接着，重新初始化count；最后，更新generation的值。 (04) 在for(;;)循环中。timed是用来表示当前是不是“超时等待”线程。如果不是，则通过trip.await()进行等待；否则，调用awaitNanos()进行超时等待。 案例新建5个线程，这5个线程达到一定的条件时，它们才继续往后运行。 123456789101112131415161718192021222324252627282930313233package com.example.demo.test;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.BrokenBarrierException;public class CyclicBarrierTest1 &#123; private static CyclicBarrier cb = new CyclicBarrier(5);; public static void main(String[] args) &#123; // 新建5个任务 for(int i=0; i&lt;5; i++) new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName() + &quot; wait for CyclicBarrier.&quot;); // 将cb的参与者数量加1 try &#123; cb.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; // cb的参与者数量等于5时，才继续往后执行 System.out.println(Thread.currentThread().getName() + &quot; continued.&quot;); &#125;).start(); &#125;&#125; 结果说明：主线程中新建了5个线程，所有的这些线程都调用cb.await()等待。所有这些线程一直等待，直到cb中所有线程都达到barrier时，这些线程才继续运行！ 新建5个线程，当这5个线程达到一定的条件时，执行某项任务。 1234567891011121314151617181920212223242526272829303132333435package com.example.demo.test;import java.util.concurrent.CyclicBarrier;import java.util.concurrent.BrokenBarrierException;public class CyclicBarrierTest2 &#123; private static CyclicBarrier cb = new CyclicBarrier(5, () -&gt; &#123; System.out.println(&quot;到达之后执行runnable &quot;); &#125;); public static void main(String[] args) &#123; // 新建5个任务 for (int i = 0; i &lt; 5; i++) &#123; new Thread(() -&gt; &#123; System.out.println(Thread.currentThread().getName() + &quot; wait for CyclicBarrier.&quot;); // 将cb的参与者数量加1 try &#123; cb.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; // cb的参与者数量等于5时，才继续往后执行 System.out.println(Thread.currentThread().getName() + &quot; continued.&quot;); &#125;).start(); &#125; &#125;&#125;","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"并发编程 Synchronized&Lock&AQS","slug":"并发编程 synchronized&Lock&AQS","date":"2021-06-16T16:00:00.000Z","updated":"2021-07-07T02:44:18.475Z","comments":true,"path":"2021/06/17/并发编程 synchronized&Lock&AQS/","link":"","permalink":"https://tj-ever.github.io/2021/06/17/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%20synchronized&Lock&AQS/","excerpt":"","text":"Java锁体系 Synchronized使用场景修饰实例方法，对当前实例对象this加锁 锁方法 12345public class Synchronized &#123; public synchronized void husband()&#123; &#125;&#125; 修饰静态方法，对当前类的Class对象加锁 锁类 1234567public class Synchronized &#123; public void husband()&#123; synchronized(Synchronized.class)&#123; &#125; &#125;&#125; 修饰代码块，指定一个加锁的对象，给对象加锁 锁对象 1234567public class Synchronized &#123; public void husband()&#123; synchronized(new test())&#123; &#125; &#125;&#125; 底层原理Synchronized是基于JVM内置锁实现，通过内部对象Monitor (监视器锁)实现， 基于进入与退出Monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex Lock（互斥锁）实现，是一个重量级锁性能较低。 JVM在1.5版本后做了优化，如锁粗化、锁消除、轻量级锁、偏向锁、适应性自旋等技术来减少锁操作的开销,内置锁的并发性能已经基本与Lock持平。 synchronized关键字被编译成字节码后会被翻译成monitorenter 和 monitorexit 两条指令分别在同步块逻辑代码的起始位置与结束位置。 synchronized加锁加在对象上，每个对象的对象头(Mark Word)中记录了锁状态 对象的内存布局HotSpot虚拟机中，对象在内存中存储的布局可以以下三块： 对象头:比如 hash码，对象所属的年代，对象锁，锁状态标志，偏向锁(线程)ID，偏向时间，数组长度(数组对象)等 实例数据:即创建对象时，对象中成员变量，方法等 对齐填充:对象的大小必须是8字节的整数倍 对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟 机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内 存存储尽量多的数据，它会根据对象的状态复用自己的存储空间，也就是说， Mark Word会随着程序的运行发生变化，变化状态如下(32位虚拟机)： 锁的升级膨胀过程 在 synchronized 最初的实现方式是 “阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态切换需要耗费处理器时间，如果同步代码块中内容过于简单，这种切换的时间可能比用户代码执行的时间还长”，这种方式就是 synchronized实现同步最初的方式，这也是当初开发者诟病的地方，这也是在JDK6以前 synchronized效率低下的原因，JDK6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 锁状态一种有四种，从级别由低到高依次是：无锁、偏向锁，轻量级锁，重量级锁，锁状态只能升级，不能降级。 偏向锁为什么要引入偏向锁 因为经过HotSpot的作者大量的研究发现，大多数时候是不存在锁竞争的，常常是一个线程多次获得同一个锁，因此如果每次都要竞争锁会增大很多没有必要付出的代价，为了降低获取锁的代价，才引入的偏向锁。 偏向锁的升级 当线程1访问代码块并获取锁对象时，会在java对象头和栈帧中记录偏向的锁的threadID，因为偏向锁不会主动释放锁，因此以后线程1再次获取锁的时候，需要比较当前线程的threadID和Java对象头中的threadID是否一致，如果一致（还是线程1获取锁对象），则无需使用CAS来加锁、解锁；如果不一致（其他线程，如线程2要竞争锁对象，而偏向锁不会主动释放因此还是存储的线程1的threadID），那么需要查看Java对象头中记录的线程1是否存活，如果没有存活，那么锁对象被重置为无锁状态，其它线程（线程2）可以竞争将其设置为偏向锁；如果存活，那么立刻查找该线程（线程1）的栈帧信息，如果还是需要继续持有这个锁对象，那么暂停当前线程1，撤销偏向锁，升级为轻量级锁，如果线程1 不再使用该锁对象，那么将锁对象状态设为无锁状态，重新偏向新的线程。 偏向锁的取消 偏向锁是默认开启的，而且开始时间一般是比应用程序启动慢几秒，如果不想有这个延迟，那么可以使用XX:BiasedLockingStartUpDelay=0； 如果不想要偏向锁，那么可以通过-XX:-UseBiasedLocking = false来设置 轻量级锁为什么要引入轻量级锁 轻量级锁考虑的是竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景。因为阻塞线程需要CPU从用户态转到内核态，代价较大，如果刚刚阻塞不久这个锁就被释放了，那这个代价就有点得不偿失了，因此这个时候就干脆不阻塞这个线程，让它自旋这等待锁释放。 轻量级锁什么时候升级为重量级锁 线程1获取轻量级锁时会先把锁对象的对象头MarkWord复制一份到线程1的栈帧中创建的用于存储锁记录的空间，然后使用CAS把对象头中的内容替换为线程1存储的锁记录的地址； 如果在线程1复制对象头的同时（在线程1CAS之前），线程2也准备获取锁，复制了对象头到线程2的锁记录空间中，但是在线程2CAS的时候，发现线程1已经把对象头换了，线程2的CAS失败，那么线程2就尝试使用自旋锁来等待线程1释放锁。 但是如果自旋的时间太长也不行，因为自旋是要消耗CPU的，因此自旋的次数是有限制的，比如10次或者100次，如果自旋次数到了线程1还没有释放锁，或者线程1还在执行，线程2还在自旋等待，这时又有一个线程3过来竞争这个锁对象，那么这个时候轻量级锁就会膨胀为重量级锁。重量级锁把除了拥有锁的线程都阻塞，防止CPU空转。 为了避免无用的自旋，轻量级锁一旦膨胀为重量级锁就不会再降级为轻量级锁了；偏向锁升级为轻量级锁也不能再降级为偏向锁。一句话就是锁可以升级不可以降级，但是偏向锁状态可以被重置为无锁状态。 锁的升级过程图解 逃逸分析逃逸分析的基本行为就是分析对象动态作用域：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。 JVM判断新创建的对象是否逃逸的依据有：一、对象被赋值给堆中对象的字段和类的静态变量。二、对象被传进了不确定的代码中去运行。 对于第一种情况，因为对象被放进堆中，则其它线程就可以对其进行访问，所以对象的使用情况，编译器就无法再进行追踪。第二种情况相当于JVM在解析普通的字节码的时候，如果没有发生JIT即时编译，编译器是不能事先完整知道这段代码会对对象做什么操作。保守一点，这个时候也只能把对象是当作是逃逸来处理。 1234567891011121314151617181920212223242526public class EscapeTest &#123; public static Object globalVariableObject; public Object instanceObject; public void globalVariableEscape()&#123; globalVariableObject = new Object(); //静态变量,外部线程可见,发生逃逸 &#125; public void instanceObjectEscape()&#123; instanceObject = new Object(); //赋值给堆中实例字段,外部线程可见,发生逃逸 &#125; public Object returnObjectEscape()&#123; return new Object(); //返回实例,外部线程可见，发生逃逸 &#125; public void noEscape()&#123; synchronized (new Object())&#123; //仅创建线程可见,对象无逃逸 &#125; Object noEscape = new Object(); //仅创建线程可见,对象无逃逸 &#125;&#125; 基于逃逸分析的优化当判断出对象不发生逃逸时，编译器可以使用逃逸分析的结果作一些代码优化 将堆分配转化为栈分配。如果某个对象在子程序中被分配，并且指向该对象的指针永远不会逃逸，该对象就可以在分配在栈上，而不是在堆上。在有垃圾收集的语言中，这种优化可以降低垃圾收集器运行的频率。 同步消除。如果发现某个对象只能从一个线程可访问，那么在这个对象上的操作可以不需要同步。 分离对象或标量替换。如果某个对象的访问方式不要求该对象是一个连续的内存结构，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。 将堆分配转化为栈分配对于优化一将堆分配转化为栈分配，这个优化也很好理解。下面以代码例子说明： 虚拟机配置参数：-XX:+PrintGC -Xms5M -Xmn5M -XX:+DoEscapeAnalysis -XX:+DoEscapeAnalysis表示开启逃逸分析，JDK8是默认开启的 -XX:+PrintGC 表示打印GC信息 -Xms5M -Xmn5M 设置JVM内存大小是5M 123456789public static void main(String[] args)&#123; for(int i = 0; i &lt; 5_000_000; i++)&#123; createObject(); &#125;&#125;public static void createObject()&#123; new Object();&#125; 运行结果是没有GC。 把虚拟机参数改成 -XX:+PrintGC -Xms5M -Xmn5M -XX:-DoEscapeAnalysis。关闭逃逸分析得到结果的部分截图是，说明了进行了GC，并且次数还不少。 12345678[GC (Allocation Failure) 4096K-&gt;504K(5632K), 0.0012864 secs][GC (Allocation Failure) 4600K-&gt;456K(5632K), 0.0008329 secs][GC (Allocation Failure) 4552K-&gt;424K(5632K), 0.0006392 secs][GC (Allocation Failure) 4520K-&gt;440K(5632K), 0.0007061 secs][GC (Allocation Failure) 4536K-&gt;456K(5632K), 0.0009787 secs][GC (Allocation Failure) 4552K-&gt;440K(5632K), 0.0007206 secs][GC (Allocation Failure) 4536K-&gt;520K(5632K), 0.0009295 secs][GC (Allocation Failure) 4616K-&gt;512K(4608K), 0.0005874 secs] 这说明了JVM在逃逸分析之后，将对象分配在了方法createObject()方法栈上。方法栈上的对象在方法执行完之后，栈桢弹出，对象就会自动回收。这样的话就不需要等内存满时再触发内存回收。这样的好处是程序内存回收效率高，并且GC频率也会减少，程序的性能就提高了。 同步锁消除如果发现某个对象只能从一个线程可访问，那么在这个对象上的操作可以不需要同步。 虚拟机配置参数：-XX:+PrintGC -Xms500M -Xmn500M -XX:+DoEscapeAnalysis。配置500M是保证不触发GC。 12345678910111213public static void main(String[] args)&#123; long start = System.currentTimeMillis(); for(int i = 0; i &lt; 5_000_000; i++)&#123; createObject(); &#125; System.out.println(&quot;cost = &quot; + (System.currentTimeMillis() - start) + &quot;ms&quot;); &#125; public static void createObject()&#123; synchronized (new Object())&#123; &#125; &#125; 运行结果 1cost = 6ms 把逃逸分析关掉：-XX:+PrintGC -Xms500M -Xmn500M -XX:-DoEscapeAnalysis 运行结果 1cost = 270ms 说明了逃逸分析把锁消除了，并在性能上得到了很大的提升。这里说明一下Java的逃逸分析是方法级别的，因为JIT的即时编译是方法级别。 分离对象或标量替换这个简单来说就是把对象分解成一个个基本类型，并且内存分配不再是分配在堆上，而是分配在栈上。这样的好处有，一、减少内存使用，因为不用生成对象头。 二、程序内存回收效率高，并且GC频率也会减少，总的来说和上面优点一的效果差不多。 两道面试题 实例对象内存中存储在哪 如果实例对象存储在堆区时：实例对象内存存在堆区，实例的引用存在栈上，实例的元数据class存在方法区或者元空间 实例对象一定是存在堆区的吗 不一定，如果实例对象没有线程逃逸行为 AQSJava并发编程核心在于java.util.concurrent包，而juc当中的大多数同步实现都是围绕着共同的基础行为，比如等待队列、条件队列、独占获取、共享获取等，而这个行为的抽象就是基于AbstractQueuedSynchronizer简称AQS，AQS定义了一套多线程访问共享资源的同步器框架，是一个依赖状态(state)的同步器。 AQS具备特性： 阻塞等待队列 共享/独占 公平/非公平 可重入 允许中断 例如java.util.concurrent当中同步器的实现如Lock,Latch,Barrier等，都是基于AQS框架实现 一般通过定义内部类Sync继承AQS 将同步器所有调用都映射到Sync对应的方法 AQS内部维护属性 volatile int state（代表共享资源） state表示资源的可用状态 State三种访问方式 getState()、setState()、compareAndSetState() AQS定义两种资源共享方式 Exclusive-独占，只有一个线程能执行，如ReentrantLock Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatch AQS定义两种队列 同步等待队列 AQS当中的同步等待队列也称CLH队列，CLH队列是Craig、Landin、 Hagersten三人发明的一种基于双向链表数据结构的队列，是FIFO先入先出线程等待队列，Java中的CLH队列是原CLH队列的一个变种,线程由原自旋机制改为阻塞机制。 条件等待队列 Condition是一个多线程间协调通信的工具类，使得某个，或者某些线程一起等待某个条件(Condition),只有当该条件具备时，这些等待线程才会被唤 醒，从而重新争夺锁 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护 (如获取资源失败入队/唤醒出队等)，AQS已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法: isHeldExclusively():该线程是否正在独占资源。只有用到 condition才需要去实现它。 tryAcquire(int):独占方式。尝试获取资源，成功则返回true，失败 则返回false。 tryRelease(int):独占方式。尝试释放资源，成功则返回true，失败 则返回false。 tryAcquireShared(int):共享方式。尝试获取资源。负数表示失败; 0表示成功，但没有剩余可用资源;正数表示成功，且有剩余资源。 tryReleaseShared(int):共享方式。尝试释放资源，如果释放后允许 唤醒后续等待结点返回true，否则返回false。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的（state会累加），这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 再以CountDownLatch以例，任务分为N个子线程去执行，state也初始化为N（注意N要与线程个数一致）。这N个子线程是并行执行的，每个子线程执行完后countDown()一次，state会CAS减1。等到所有子线程都执行完后(即state=0)，会unpark()主调用线程，然后主调用线程就会从await()函数返回，继续后余动作。 一般来说，自定义同步器要么是独占方法，要么是共享方式，他们也只需实现tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。 源码分析结点状态waitStatusNode结点是对每一个等待获取资源的线程的封装，其包含了需要同步的线程本身及其等待状态，如是否被阻塞、是否等待唤醒、是否已经被取消等。变量waitStatus则表示当前Node结点的等待状态，共有5种取值CANCELLED、SIGNAL、CONDITION、PROPAGATE、0。 CANCELLED(1)：表示当前结点已取消调度。当timeout或被中断（响应中断的情况下），会触发变更为此状态，进入该状态后的结点将不会再变化。 SIGNAL(-1)：表示后继结点在等待当前结点唤醒。后继结点入队时，会将前继结点的状态更新为SIGNAL。 CONDITION(-2)：表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 PROPAGATE(-3)：共享模式下，前继结点不仅会唤醒其后继结点，同时也可能会唤醒后继的后继结点。 0：新结点入队时的默认状态。 注意，负值表示结点处于有效等待状态，而正值表示结点已被取消。所以源码中很多地方用&gt;0、&lt;0来判断结点的状态是否正常。 acquire(int)此方法是独占模式下线程获取共享资源的顶层入口。如果获取到资源，线程直接返回，否则进入等待队列，直到获取到资源为止，且整个过程忽略中断的影响。这也正是lock()的语义，当然不仅仅只限于lock()。获取到资源后，线程就可以去执行其临界区代码了。 源码： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 函数流程如下： tryAcquire()尝试直接去获取资源，如果成功则直接返回（这里体现了非公平锁，每个线程获取锁时会尝试直接抢占加塞一次，而CLH队列中可能还有别的线程在等待）； addWaiter()将该线程加入等待队列的尾部，并标记为独占模式； acquireQueued()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 tryAcquire(int)此方法尝试去获取独占资源。如果获取成功，则直接返回true，否则直接返回false。这也正是tryLock()的语义，还是那句话，当然不仅仅只限于tryLock()。 源码： 123protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 该方法直接throw异常，因为AQS只是一个框架，具体资源的获取/释放方式交由自定义同步器去实现。 AQS这里只定义了一个接口，具体资源的获取交由自定义同步器去实现了（通过state的get/set/CAS）至于能不能重入，能不能加塞，那就看具体的自定义同步器怎么去设计，当然，自定义同步器在进行资源访问时要考虑线程安全的影响。 这里之所以没有定义成abstract，是因为独占模式下只用实现tryAcquire-tryRelease，而共享模式下只用实现tryAcquireShared-tryReleaseShared。如果都定义成abstract，那么每个模式也要去实现另一模式下的接口。说到底，Doug Lea还是站在咱们开发者的角度，尽量减少不必要的工作量。 addWaiter(Node)此方法用于将当前线程加入到等待队列的队尾，并返回当前线程所在的结点。 源码： 123456789101112131415161718private Node addWaiter(Node mode) &#123; //以给定模式构造结点。mode有两种：EXCLUSIVE（独占）和SHARED（共享） Node node = new Node(Thread.currentThread(), mode); //尝试快速方式直接放到队尾。 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; //上一步失败则通过enq入队。 enq(node); return node;&#125; enq(Node)此方法用于将node加入队尾。 源码： 12345678910111213141516private Node enq(final Node node) &#123; //CAS&quot;自旋&quot;，直到成功加入队尾 for (;;) &#123; Node t = tail; if (t == null) &#123; // 队列为空，创建一个空的标志结点作为head结点，并将tail也指向它。 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123;//正常流程，放入队尾 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; 如果你看过AtomicInteger.getAndIncrement()函数源码，那么相信你一眼便看出这段代码的精华。CAS自旋volatile变量，是一种很经典的用法。 acquireQueued(Node, int)通过tryAcquire()和addWaiter()，该线程获取资源失败，已经被放入等待队列尾部了。 下一步，进入等待状态休息，直到其他线程彻底释放资源后唤醒自己，自己再拿到资源，然后就可以去干自己想干的事了。跟医院排队拿号有点相似。 acquireQueued()就是干这件事：在等待队列中排队拿号（中间没其它事干可以休息），直到拿到号后再返回。 源码： 1234567891011121314151617181920212223242526final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true;//标记是否成功拿到资源 try &#123; boolean interrupted = false;//标记等待过程中是否被中断过 //又是一个“自旋”！ for (;;) &#123; final Node p = node.predecessor();//拿到前驱 //如果前驱是head，即该结点已成老二，那么便有资格去尝试获取资源（可能是老大释放完资源唤醒自己的，当然也可能被interrupt了）。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node);//拿到资源后，将head指向该结点。所以head所指的标杆结点，就是当前获取到资源的那个结点或null。 p.next = null; // setHead中node.prev已置为null，此处再将head.next置为null，就是为了方便GC回收以前的head结点。也就意味着之前拿完资源的结点出队了！ failed = false; // 成功获取资源 return interrupted;//返回等待过程中是否被中断过 &#125; //如果自己可以休息了，就通过park()进入waiting状态，直到被unpark()。如果不可中断的情况下被中断了，那么会从park()中醒过来，发现拿不到资源，从而继续进入park()等待。 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true;//如果等待过程中被中断过，哪怕只有那么一次，就将interrupted标记为true &#125; &#125; finally &#123; if (failed) // 如果等待过程中没有成功获取资源（如timeout，或者可中断的情况下被中断了），那么取消结点在队列中的等待。 cancelAcquire(node); &#125;&#125; shouldParkAfterFailedAcquire(Node, Node)此方法主要用于检查状态，看看自己是否真的可以去休息了，万一队列前边的线程都放弃了只是瞎站着，那也说不定。 1234567891011121314151617181920private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus;//拿到前驱的状态 if (ws == Node.SIGNAL) //如果已经告诉前驱拿完号后通知自己一下，那就可以安心休息了 return true; if (ws &gt; 0) &#123; /* * 如果前驱放弃了，那就一直往前找，直到找到最近一个正常等待的状态，并排在它的后边。 * 注意：那些放弃的结点，由于被自己“加塞”到它们前边，它们相当于形成一个无引用链，稍后就会被保安大叔赶走了(GC回收)！ */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果前驱正常，那就把前驱的状态设置成SIGNAL，告诉它拿完号后通知自己一下。有可能失败，人家说不定刚刚释放完呢！ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 整个流程中，如果前驱结点的状态不是SIGNAL，那么自己就不能安心去休息，需要去找个安心的休息点，同时可以再尝试下看有没有机会轮到自己拿号。 parkAndCheckInterrupt()如果线程找好安全休息点后，那就可以安心去休息了。此方法就是让线程去休息，真正进入等待状态。 123456private final boolean parkAndCheckInterrupt() &#123; //调用park()使线程进入waiting状态 LockSupport.park(this); //如果被唤醒，查看自己是不是被中断的。 return Thread.interrupted();&#125; park()会让当前线程进入waiting状态。在此状态下，有两种途径可以唤醒该线程：1）被unpark()；2）被interrupt()。需要注意的是，Thread.interrupted()会清除当前线程的中断标记位。 小结看了shouldParkAfterFailedAcquire()和parkAndCheckInterrupt()，现在让我们再回到acquireQueued()，总结下该函数的具体流程： 结点进入队尾后，检查状态，找到安全休息点； 调用park()进入waiting状态，等待unpark()或interrupt()唤醒自己； 被唤醒后，看自己是不是有资格能拿到号。如果拿到，head指向当前结点，并返回从入队到拿到号的整个过程中是否被中断过；如果没拿到，继续流程1。 总结acquireQueued()分析完之后，再回到acquire()。 源码： 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 再来总结下流程： 调用自定义同步器的tryAcquire()尝试直接去获取资源，如果成功则直接返回； 没成功，则addWaiter()将该线程加入等待队列的尾部，并标记为独占模式； acquireQueued()使线程在等待队列中休息，有机会时（轮到自己，会被unpark()）会去尝试获取资源。获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。 至此，acquire()的流程终于算是告一段落了。这也就是ReentrantLock.lock()的流程，不信你去看其lock()源码吧，整个函数就是一条acquire(1)。 release(int)acquire()的反操作release()。 此方法是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。这也正是unlock()的语义，当然不仅仅只限于unlock()。 源码： 123456789public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head;//找到头结点 if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h);//唤醒等待队列里的下一个线程 return true; &#125; return false;&#125; tryRelease(int)此方法尝试去释放指定量的资源。 源码： 123protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 跟tryAcquire()一样，这个方法是需要独占模式的自定义同步器去实现的。正常来说，tryRelease()都会成功的，因为这是独占模式，该线程来释放资源，那么它肯定已经拿到独占资源了，直接减掉相应量的资源即可(state-=arg)，也不需要考虑线程安全的问题。但要注意它的返回值，上面已经提到了，release()是根据tryRelease()的返回值来判断该线程是否已经完成释放掉资源了！所以自义定同步器在实现时，如果已经彻底释放资源(state=0)，要返回true，否则返回false。 unparkSuccessor(Node)此方法用于唤醒等待队列中下一个线程。 源码： 12345678910111213141516private void unparkSuccessor(Node node) &#123; //这里，node一般为当前线程所在的结点。 int ws = node.waitStatus; if (ws &lt; 0)//置零当前线程所在的结点状态，允许失败。 compareAndSetWaitStatus(node, ws, 0); Node s = node.next;//找到下一个需要唤醒的结点s if (s == null || s.waitStatus &gt; 0) &#123;//如果为空或已取消 s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) // 从后向前找。 if (t.waitStatus &lt;= 0)//从这里可以看出，&lt;=0的结点，都是还有效的结点。 s = t; &#125; if (s != null) LockSupport.unpark(s.thread);//唤醒&#125; 一句话概括：用unpark()唤醒等待队列中最前边的那个未放弃线程，这里我们也用s来表示吧。此时，再和acquireQueued()联系起来，s被唤醒后，进入if (p == head &amp;&amp; tryAcquire(arg))的判断（即使p!=head也没关系，它会再进入shouldParkAfterFailedAcquire()寻找一个安全点。这里既然s已经是等待队列中最前边的那个未放弃线程了，那么通过shouldParkAfterFailedAcquire()的调整，s也必然会跑到head的next结点，下一次自旋p==head就成立了），然后s把自己设置成head标杆结点，表示自己已经获取到资源了，acquire()也返回了。 小结release()是独占模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果彻底释放了（即state=0）,它会唤醒等待队列里的其他线程来获取资源。 一个非常有趣的问题：如果获取锁的线程在release时异常了，没有unpark队列中的其他结点，这时队列中的其他结点会怎么办？是不是没法再被唤醒了？ 答案是YES！！！这时，队列中等待锁的线程将永远处于park状态，无法再被唤醒！！！但是我们再回头想想，获取锁的线程在什么情形下会release抛出异常呢？？ 线程突然死掉了？可以通过thread.stop来停止线程的执行，但该函数的执行条件要严苛的多，而且函数注明是非线程安全的，已经标明Deprecated； 线程被interupt了？线程在运行态是不响应中断的，所以也不会抛出异常； release代码有bug，抛出异常了？目前来看，Doug Lea的release方法还是比较健壮的，没有看出能引发异常的情形（如果有，恐怕早被用户吐槽了）。除非自己写的tryRelease()有bug，那就没啥说的，自己写的bug只能自己含着泪去承受了。 acquireShared(int)此方法是共享模式下线程获取共享资源的顶层入口。它会获取指定量的资源，获取成功则直接返回，获取失败则进入等待队列，直到获取到资源为止，整个过程忽略中断。 源码： 1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 这里tryAcquireShared()依然需要自定义同步器去实现。但是AQS已经把其返回值的语义定义好了：负值代表获取失败；0代表获取成功，但没有剩余资源；正数表示获取成功，还有剩余资源，其他线程还可以去获取。所以这里acquireShared()的流程就是： tryAcquireShared()尝试获取资源，成功则直接返回； 失败则通过doAcquireShared()进入等待队列，直到获取到资源为止才返回。 doAcquireShared(int)此方法用于将当前线程加入等待队列尾部休息，直到其他线程释放资源唤醒自己，自己成功拿到相应量的资源后才返回。 源码： 1234567891011121314151617181920212223242526272829private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED);//加入队列尾部 boolean failed = true;//是否成功标志 try &#123; boolean interrupted = false;//等待过程中是否被中断过的标志 for (;;) &#123; final Node p = node.predecessor();//前驱 if (p == head) &#123;//如果到head的下一个，因为head是拿到资源的线程，此时node被唤醒，很可能是head用完资源来唤醒自己的 int r = tryAcquireShared(arg);//尝试获取资源 if (r &gt;= 0) &#123;//成功 setHeadAndPropagate(node, r);//将head指向自己，还有剩余资源可以再唤醒之后的线程 p.next = null; // help GC if (interrupted)//如果等待过程中被打断过，此时将中断补上。 selfInterrupt(); failed = false; return; &#125; &#125; //判断状态，寻找安全点，进入waiting状态，等着被unpark()或interrupt() if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 有木有觉得跟acquireQueued()很相似？对，其实流程并没有太大区别。 只不过这里将补中断的selfInterrupt()放到doAcquireShared()里了，而独占模式是放到acquireQueued()之外，其实都一样. 跟独占模式比，还有一点需要注意的是，这里只有线程是head.next时（“老二”），才会去尝试获取资源，有剩余的话还会唤醒之后的队友。那么问题就来了，假如老大用完后释放了5个资源，而老二需要6个，老三需要1个，老四需要2个。老大先唤醒老二，老二一看资源不够，他是把资源让给老三呢，还是不让？答案是否定的！老二会继续park()等待其他线程释放资源，也更不会去唤醒老三和老四了。独占模式，同一时刻只有一个线程去执行，这样做未尝不可；但共享模式下，多个线程是可以同时执行的，现在因为老二的资源需求量大，而把后面量小的老三和老四也都卡住了。当然，这并不是问题，只是AQS保证严格按照入队顺序唤醒罢了（保证公平，但降低了并发）。 setHeadAndPropagate(Node, int)12345678910private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; setHead(node);//head指向自己 //如果还有剩余量，继续唤醒下一个邻居线程 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 此方法在setHead()的基础上多了一步，就是自己苏醒的同时，如果条件符合（比如还有剩余资源），还会去唤醒后继结点，毕竟是共享模式！ 小结至此，acquireShared()也要告一段落了。让我们再梳理一下它的流程： tryAcquireShared()尝试获取资源，成功则直接返回； 失败则通过doAcquireShared()进入等待队列park()，直到被unpark()/interrupt()并成功获取到资源才返回。整个等待过程也是忽略中断的。 其实跟acquire()的流程大同小异，只不过多了个自己拿到资源后，还会去唤醒后继队友的操作（这才是共享嘛） releaseShared()acquireShared()反操作releaseShared()。 此方法是共享模式下线程释放共享资源的顶层入口。它会释放指定量的资源，如果成功释放且允许唤醒等待线程，它会唤醒等待队列里的其他线程来获取资源。 源码： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123;//尝试释放资源 doReleaseShared();//唤醒后继结点 return true; &#125; return false;&#125; 一句话概括：释放掉资源后，唤醒后继。 跟独占模式下的release()相似，但有一点稍微需要注意：独占模式下的tryRelease()在完全释放掉资源（state=0）后，才会返回true去唤醒其他线程，这主要是基于独占下可重入的考量；而共享模式下的releaseShared()则没有这种要求，共享模式实质就是控制一定量的线程并发执行，那么拥有资源的线程在释放掉部分资源时就可以唤醒后继等待结点。 例如，资源总量是13，A（5）和B（7）分别获取到资源并发运行，C（4）来时只剩1个资源就需要等待。A在运行过程中释放掉2个资源量，然后tryReleaseShared(2)返回true唤醒C，C一看只有3个仍不够继续等待；随后B又释放2个，tryReleaseShared(2)返回true唤醒C，C一看有5个够自己用了，然后C就可以跟A和B一起运行。 而ReentrantReadWriteLock读锁的tryReleaseShared()只有在完全释放掉资源（state=0）才返回true，所以自定义同步器可以根据需要决定tryReleaseShared()的返回值。 doReleaseShared()此方法主要用于唤醒后继。 源码： 123456789101112131415161718private void doReleaseShared() &#123; for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; unparkSuccessor(h);//唤醒后继 &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; &#125; if (h == head)// head发生变化 break; &#125;&#125; 小结本节我们详解了独占和共享两种模式下获取-释放资源(acquire-release、acquireShared-releaseShared)的源码。 值得注意的是，acquire()和acquireShared()两种方法下，线程在等待队列中都是忽略中断的。 AQS也支持响应中断的，acquireInterruptibly()/acquireSharedInterruptibly()即是，相应的源码跟acquire()和acquireShared()差不多，这里就不再详解了。 简单应用 互斥锁Mutex是一个不可重入的互斥锁实现。锁资源（AQS里的state）只有两种状态：0表示未锁定，1表示锁定。 核心源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Mutex implements Lock, java.io.Serializable &#123; // 自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 判断是否锁定状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 尝试获取资源，立即返回。成功则返回true，否则false。 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // 这里限定只能为1个量 if (compareAndSetState(0, 1)) &#123;//state为0才设置为1，不可重入！ setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源 return true; &#125; return false; &#125; // 尝试释放资源，立即返回。成功则为true，否则false。 protected boolean tryRelease(int releases) &#123; assert releases == 1; // 限定为1个量 if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！ throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0);//释放资源，放弃占有状态 return true; &#125; &#125; // 真正同步类的实现都依赖继承于AQS的自定义同步器！ private final Sync sync = new Sync(); //lock&lt;--&gt;acquire。两者语义一样：获取资源，即便等待，直到成功才返回。 public void lock() &#123; sync.acquire(1); &#125; //tryLock&lt;--&gt;tryAcquire。两者语义一样：尝试获取资源，要求立即返回。成功则为true，失败则为false。 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; //unlock&lt;--&gt;release。两者语文一样：释放资源。 public void unlock() &#123; sync.release(1); &#125; //锁是否占有状态 public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125;&#125; 同步类在实现时一般都将自定义同步器（sync）定义为内部类，供自己使用；而同步类自己（Mutex）则实现某个接口，对外服务。当然，接口的实现要直接依赖sync，它们在语义上也存在某种对应关系. 而sync只用实现资源state的获取-释放方式tryAcquire-tryRelelase，至于线程的排队、等待、唤醒等，上层的AQS都已经实现好了，我们不用关心。 除了Mutex，ReentrantLock/CountDownLatch/Semphore这些同步类的实现方式都差不多，不同的地方就在获取-释放资源的方式tryAcquire-tryRelelase。掌握了这点，AQS的核心便被攻破了！","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"并发编程 JMM模型和volatile","slug":"并发编程 JMM模型和volatile","date":"2021-06-13T16:00:00.000Z","updated":"2021-07-07T02:43:46.721Z","comments":true,"path":"2021/06/14/并发编程 JMM模型和volatile/","link":"","permalink":"https://tj-ever.github.io/2021/06/14/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%20JMM%E6%A8%A1%E5%9E%8B%E5%92%8Cvolatile/","excerpt":"","text":"计算机硬件结构 多CPU一个现代CPU除了处理器核心之外还包括寄存器、L1L2L3缓存这些存储设备、浮点运算单元、整数运算单元等一些辅助运算设备以及内部总线等。 一个多核的CPU也就是一个CPU上有多个处理器核心。比如说现在我们要在一台计算机上跑一个多线程的程序，因为是一个进程里的线程，所以需要一些共享一些存储变量，如果这台计算机都是单核单线程CPU的话，就意味着这个程序的不同线程需要经常在CPU之间的外部总线上通信，同时还要处理不同CPU之间不同缓存导致数据不一致的问题，所以在这种场景下多核单CPU的架构能发挥很大的优势，通信都在内部总线，共用同一个缓存。 CPU寄存器每个CPU都包含一系列的寄存器，它们是CPU内内存的基础。CPU在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为CPU访问寄存器的速度远大于主存。 CPU缓存即高速缓冲存储器，是位于CPU与主内存间的一种容量较小但速度很高的存储器。 它的容量比内存小的多但是交换速度却比内存要快得多。CPU高速缓存的出现主要是为了解决CPU运算速度与内存读写速度不匹配的矛盾，因为CPU运算速度要比内存读写速度快很多，这样会使CPU花费很长时间等待数据到来或把数据写入内存。在缓存中的数据是内存中的一小部分，但这一小部分是短时间内CPU即将访问的，当CPU调用大量数据时，就可先缓存中调用，从而加快读取速度。 当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。一般来说，每级缓存的命中率大概都在80%左右，也就是说全部数据量的80%都可以在一级缓存中找到，只剩下20%的总数据量才需要从二级缓存、三级缓存或内存中读取，由此可见一级缓存是整个CPU缓存架构中最为重要的部分。 内存一个计算机还包含一个主存。所有的CPU都可以访问主存。主存通常比CPU中的缓存大得 多。 CPU读取存储器数据过程 CPU取寄存器XX的值，只需要一步:直接读取。 CPU取L1 cache的某个值，需要把cache行锁住，把某个数据拿来，解锁。 CPU取L2 cache的某个值，先要到L1 cache里取，L1当中不存在，在L2里，L2开始加锁，加锁以后，把L2里的数据复制到L1，再执行读L1的过程，上面的3步，再解锁。 CPU取L3 cache的也是一样，只不过先由L3复制到L2，从L2复制到L1，从L1到CPU。 CPU取内存则最复杂，通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，等待回应，回应数据保存到L3(如果没有就到L2)，再从L3/2到L1，再从L1到CPU，之后解除总线锁定。 缓存一致性问题 缓存一致性问题 在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存(MainMemory)。基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是 也引入了新的问题:缓存一致性(CacheCoherence)。当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致的情况，如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢?为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，这类协议有MSI、 MESI(IllinoisProtocol)、MOSI、Synapse、Firefly及DragonProtocol，等等 指令重排问题为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行(Out-Of-Order Execution)优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的 顺序一致。因此，如果存在一个计算任务依赖另一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的指令重排序(Instruction Reorder)优化 多线程用户线程指不需要内核支持而在用户程序中实现的线程，其不依赖于操作系统核心，应 用进程利用线程库提供创建、同步、调度和管理线程的函数来控制用户线程。另外，用户线程 是由应用进程利用线程库创建和管理，不依赖于操作系统核心。不需要用户态/核心态切换， 速度快。操作系统内核不知道多线程的存在，因此一个线程阻塞将使得整个进程(包括它的所 有线程)阻塞。由于这里的处理器时间片分配是以进程为基本单位，所以每个线程执行的时间 相对减少。 内核线程线程的所有管理操作都是由操作系统内核完成的。内核保存线程的状态和上下 文信息，当一个线程执行了引起阻塞的系统调用时，内核可以调度该进程的其他线程执行。在 多处理器系统上，内核可以分派属于同一进程的多个线程在多个处理器上运行，提高进程执行 的并行度。由于需要内核完成线程的创建、调度和管理，所以和用户级线程相比这些操作要慢 得多，但是仍然比进程的创建和管理操作要快。 线程生命周期 上下文切换CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个 任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。 JMM模型JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存）中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量的副本 JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存(有些地方称为栈空间)，用于存储线程私有的数据。Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问。 但线程对变量的操作必须在工作内存中进行，所以首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量， 工作内存中存储着主内存中的变量副本拷贝。 工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过主内存来完成。 八种操作 lock(锁定):作用于主内存的变量，把一个变量标记为一条线程独占状态 unlock(解锁):作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的 变量才可以被其他线程锁定 read(读取):作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中， 以便随后的load动作使用 load(载入):作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作 内存的变量副本中 use(使用):作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 assign(赋值):作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存 的变量 store(存储):作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中， 以便随后的write的操作 write(写入):作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送 到主内存的变量中 并发编程三大特性原子性：原子性指的是一个操作是不可中断的，即使是在多线程环境下，一个操作一旦开始就不会被其他线程影响。 除了JVM自身提供的对基本数据类型读写操作的原子性外，可以通过 synchronized和 Lock实现原子性。因为synchronized和Lock能够保证任一时刻只有一个线程访问该代码块。 可见性：可见性指的是当一个线程修改了某个共享变量的值，其他线程是否能够马上得知这个修改的值。 由于线程对共享变量的操作都是线程拷贝到各自的工作内存进行操作后才写回到主内存中的，这就可能存在一个线程A修改了共享变量x的值，还未写回主内存时，另外一个线程B又对主内存中同一个共享变量x进行操作，但 此时A线程工作内存中共享变量x对线程B来说并不可见，这种工作内存与主内存同步延迟现象就造成了可见性问题。 volatile关键字保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值立即被 其他的线程看到，即修改的值立即更新到主存中，当其他线程需要读取时，它会去内存中读取新值。synchronized和Lock也可以保证可见性，因为它们可以保证任一时刻只有一个线程能访问共享资源，并在其释放锁之前将修改的变量刷新到内存中。 另外指令重排以及编译器优化也可能导致可见性问题，无论是编译器优化还是处理器优化的重排现象，在多线程环境下，确实会导致程 序轮序执行的问题，从而也就导致可见性问题。 有序性：有序性是指对于单线程的执行代码，我们总是认为代码的执行是按顺序依次执行的，这样的理解并没有毛病，毕竟对于单线程而言确实如此，但对于多线程环境，则可能出现乱序现象，因为程序编译成机器码指令后可能会出现指令重排现象，重排后的指令与原指令的顺序未必一致。 要明白的是，在Java程序中，倘若在本线程内，所有操作都视为有序行为，如果是多线程环境下，一个线程中观察另外一个线程，所有操作都是无序的，前半句指的是单线程内保证串行语义执行的一致性，后半句则指指令重排现象和工作内存与主内存同步延迟现象。 在Java里面，可以通过volatile关键字来保证一定的“有序性”(具体原理在下一节讲述 volatile关键字)。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized 和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就 保证了有序性。 volatilevolatile是Java虚拟机提供的轻量级的同步机制。volatile关键字有如下两个作用 保证被volatile修饰的共享变量对所有线程总数可见的，也就是当一个线程修改了一个被volatile修饰共享变量的值，新值总是可以被其他线程立即得知。 禁止指令重排序优化。 volatile无法保证原子性volatile只能保证可见性，原子性可以使用synchronized保证。需要注意的是一旦使用synchronized修饰方法后，由于synchronized本身也具备与volatile相同的特性，即可见性，因此在这样种情况下就可以省去volatile修饰变量。 volatile禁止重排优化volatile关键字另一个作用就是禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象。 内存屏障内存屏障，又称内存栅栏，是一个CPU指令，它的作用有两个： 保证特定操作的执行顺序 保证某些变量的内存可见性(利用该特性实现volatile的内存可见性)。 由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器 和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。总之， volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。 DCL单例模式DCL：Double Check Lock 123456789101112131415public class Singleton &#123; private static volatile Singleton instance; private Singleton() &#123;&#125; public static Singleton getInstance() &#123; if (instance == null) &#123; // 1 synchronized (Singleton.class) &#123; if (instance == null) &#123; // 2 instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; https://blog.csdn.net/qq_26817225/article/details/107215878 volatile在DCL单例中不是使用它的线程可见性，而是禁止指令重排序。 对象的创建过程结论：对象的创建不是原子性操作，所以有指令重排序的可能。为了禁止指令重排序，所以要引入volatile。 初始化一个对象 instance = new DoubleCheckLock()；可以分为以下3步完成(伪代码) 申请对象内存空间 memory = allocate(); 初始化对象（比如int a = 5等） instance(memory); 设置instance指向刚申请的内存地址， instance!=null instance = memory; 由于步骤2和步骤3间可能会重排序，如下: 申请对象内存空间 memory = allocate(); 设置instance指向刚申请的内存地址， instance!=null，但是对象还没有初始化完成! instance = memory; 初始化对象（比如int a = 5等） instance(memory); 由于步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。 但是指令重排只会保证串行语义的执行的一致性(单线程)，但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null 时，由于instance实例未必已初始化完成，也就造成了线程安全问题。那么该如何解决呢，使用volatile禁止instance变量被执行指令重排优化即可。 volatile内存屏障下图是JMM针对编译器制定的volatile重排序规则表。 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。 JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。 在每个volatile写操作的前面插入一个StoreStore屏障，后面插入一个StoreLoad屏障。 在每个volatile读操作的后面插入一个LoadLoad屏障和一个LoadStore屏障。 这种xy形式的指令，其语义如下：在xy之前的x操作，不能与xy之后的y操作进行重排序。 下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图 StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意 处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。 volatile写后面的StoreLoad屏障。此屏障的作用是避免 volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在 一个volatile写的后面 是否需要插入一个StoreLoad屏障(比如，一个volatile写之后方 法立即return)，所以基于保守策略，在每个volatile写的后面，或者在每个volatile 读的前面插入一个StoreLoad屏障。 下图是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"docker容器迁移，备份","slug":"Docker容器迁移，备份","date":"2020-12-01T16:00:00.000Z","updated":"2021-06-14T16:10:30.502Z","comments":true,"path":"2020/12/02/Docker容器迁移，备份/","link":"","permalink":"https://tj-ever.github.io/2020/12/02/Docker%E5%AE%B9%E5%99%A8%E8%BF%81%E7%A7%BB%EF%BC%8C%E5%A4%87%E4%BB%BD/","excerpt":"","text":"以备份MySQL数据库为例 先运行一个mysql容器 12docker pull registry.cn-hangzhou.aliyuncs.com/choerodon-tools/mysql:5.7.17docker run -d -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=root --privileged=true 954 查看容器挂载的目录 1docker inspect mysql|grep Mounts -A 20 可以看到容器数据挂载再/var/lib/mysql下，我们只要将该目录复制出来或者使用tar打包即可完成备份，恢复数据也是如此。 使用临时容器导出数据进行备份 123//启动一个临时容器（--rm用完即删，--volumes-froms挂载容器数据共享） //挂载宿主机当前目录到容器内/backup目录下，容器运行后将要备份的内容（/var/lib/mysql文件夹）备份到/backup/data.tar，然后删除容器，备份后的data.tar就留在了当前目录。docker run --rm --volumes-from mysql -v $(pwd):/backup ubuntu tar cvf /backup/data.tar /var/lib/mysql 恢复数据 1234//启动一个mysql容器docker run -d -p 3306:3306 --name mysql -e MYSQL_ROOT_PASSWORD=root --privileged=true 954//挂载宿主机当前目录到容器的/backup下，之前备份的data.tar在当前目录下，那么它在容器中的/backup也能访问到，容器启动后将这个存档文件中的/var/lib/mysql 恢复到根目录下，然后删除容器，恢复后的数据在mysql的volume中了docker run --rm --volumes-from mysql -v $(pwd):/backup ubuntu tar xvf /backup/data.tar -C /","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://tj-ever.github.io/tags/docker/"}]},{"title":"Awk用法","slug":"Awk文本处理工具","date":"2020-11-15T16:00:00.000Z","updated":"2020-11-20T06:06:37.901Z","comments":true,"path":"2020/11/16/Awk文本处理工具/","link":"","permalink":"https://tj-ever.github.io/2020/11/16/Awk%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/","excerpt":"","text":"Awk 文本处理工具123&#x2F;&#x2F;删除jar进程kill -9 $(ps -ef|grep jar|awk &#39;!&#x2F;grep&#x2F; &#123;print $2&#125;&#39;)","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://tj-ever.github.io/tags/linux/"}]},{"title":"Docker安装Oracle数据库","slug":"Docker搭建Oracle","date":"2020-11-13T16:00:00.000Z","updated":"2021-06-14T16:09:13.585Z","comments":true,"path":"2020/11/14/Docker搭建Oracle/","link":"","permalink":"https://tj-ever.github.io/2020/11/14/Docker%E6%90%AD%E5%BB%BAOracle/","excerpt":"","text":"拉取镜像 1docker pull registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 创建容器 1docker run -d -p 1521:1521 --name oracle registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 进入容器 1docker exec -it oracle bash 切换到root用户下（密码helowin） 1su root 配置环境变量 123456vi /etc/profile//添加下面三行export ORACLE_HOME=/home/oracle/app/oracle/product/11.2.0/dbhome_2export ORACLE_SID=helowinexport PATH=$ORACLE_HOME/bin:$PATH 创建软连接 1ln -s $ORACLE_HOME/bin/sqlplus /usr/bin 切换到oracle用户 1su - oracle 登录sqlplus并修改sys，system用户密码 12345678910sqlplus /nolog;conn /as sysdba;//修改密码alter user system identified by system;alter user sys identified by sys;//创建用户create user test identified by test;//赋予权限grant connect,resource,dba to test; 使用navicat连接","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://tj-ever.github.io/tags/docker/"},{"name":"oracle","slug":"oracle","permalink":"https://tj-ever.github.io/tags/oracle/"}]},{"title":"死锁查询","slug":"死锁查询","date":"2020-11-13T16:00:00.000Z","updated":"2021-06-14T16:10:45.153Z","comments":true,"path":"2020/11/14/死锁查询/","link":"","permalink":"https://tj-ever.github.io/2020/11/14/%E6%AD%BB%E9%94%81%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"死锁查询 123456789select sess.sid, sess.serial#, lo.oracle_username, lo.os_user_name, ao.object_name, lo.locked_mode from v$locked_object lo, dba_objects ao, v$session sess where ao.object_id = lo.object_id and lo.session_id = sess.sid;","categories":[],"tags":[{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"静默打印实现方式","slug":"静默打印","date":"2020-11-12T04:04:48.361Z","updated":"2020-12-02T08:17:07.848Z","comments":true,"path":"2020/11/12/静默打印/","link":"","permalink":"https://tj-ever.github.io/2020/11/12/%E9%9D%99%E9%BB%98%E6%89%93%E5%8D%B0/","excerpt":"","text":"首先在浏览器设置 创建一个谷歌浏览器的快捷方式 右键快捷方式，点击【属性】，点击【起始位置】，在【目标】尾部位置添加“ –kiosk-printing”注意空格 然后调用下面两个方法，自行传入需要打印的url或者自行填充body内容 使用新开窗口打印1234567891011function useNewWindowPrint(url) &#123; // debugger; var newWindow; //打开一个新的窗口 newWindow = window.open(url); newWindow.onload = function()&#123;//页面所有元素加载完毕 newWindow.print(); newWindow.close(); &#125; return false; &#125; 使用iframe打印12345678910111213141516171819function useIframePrint(url)&#123; var iframe=document.getElementById(&quot;print-iframe&quot;); if (iframe)&#123; document.body.removeChild(iframe); &#125; iframe = document.createElement(&#x27;IFRAME&#x27;); iframe.setAttribute(&quot;id&quot;, &quot;print-iframe&quot;); iframe.setAttribute(&quot;src&quot;, url); iframe.setAttribute(&#x27;style&#x27;, &#x27;position:absolute;display:none&#x27;); document.body.appendChild(iframe); // var doc = iframe.contentWindow.document; // // 这里可以自定义样式 // doc.write(&quot;&lt;LINK rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;css/print.css&quot;&gt;&quot;); // doc.write(&#x27;&lt;div&gt;&#x27; + el.innerHTML + &#x27;&lt;/div&gt;&#x27;); // doc.close(); iframe.contentWindow.focus(); iframe.contentWindow.print(); &#125;","categories":[],"tags":[{"name":"前端","slug":"前端","permalink":"https://tj-ever.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Redisson分布式锁实现抢单功能","slug":"redisson分布式锁实现抢单功能","date":"2020-11-11T16:00:00.000Z","updated":"2020-12-02T08:42:20.396Z","comments":true,"path":"2020/11/12/redisson分布式锁实现抢单功能/","link":"","permalink":"https://tj-ever.github.io/2020/11/12/redisson%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0%E6%8A%A2%E5%8D%95%E5%8A%9F%E8%83%BD/","excerpt":"","text":"redisson帮我们封装了底层很多操作，通过简单的注入即可使用。 核心思路是每次抢单前判断redis中是否有该订单的id，如果有则加锁并执行业务操作进行抢单，否则说明该订单状态不可抢或者已经被抢。 订单发布（业务操作），发布后才可进行抢单。通过在redis中设置该订单的key，代表该订单可抢。 订单取消（业务操作），删除订单在redis中的key，代表该订单不可抢。 容错处理，应用重启时初始化redis数据 控制层进行加锁，注入redission获取锁，finally中释放。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://tj-ever.github.io/tags/redis/"}]},{"title":"基础环境及中间件搭建","slug":"基础环境及中间件搭建","date":"2020-11-11T16:00:00.000Z","updated":"2021-10-22T04:23:48.991Z","comments":true,"path":"2020/11/12/基础环境及中间件搭建/","link":"","permalink":"https://tj-ever.github.io/2020/11/12/%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%8F%8A%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%90%AD%E5%BB%BA/","excerpt":"","text":"基础环境搭建YUM源更新1234567891011121314151617181920212223242526272829303132yum install -y vim wget//进入源目录：cd /etc/yum.repos.d///下载163源：wget http://mirrors.163.com/.help/CentOS6-Base-163.repo//把文件里面的$releasever全部替换为版本号6：sed -i &#x27;s#$releasever#6#g&#x27; CentOS6-Base-163.repo//清除原有缓存：yum clean all//重建缓存，以提高搜索安装软件的速度：yum makecache//更新系统：yum update//gcc等环境安装，后续有些软件安装需要这些基础环境//gcc安装：yum install -y gcc-c++//PCRE pcre-devel安装：yum install -y pcre pcre-devel//zlib 安装：yum install -y zlib zlib-devel//OpenSSL 安装：yum install -y openssl openssl-devel 安装jdk123456789101112131415161718192021222324&#x2F;&#x2F;登录下载安装包上传至服务器https:&#x2F;&#x2F;www.oracle.com&#x2F;java&#x2F;technologies&#x2F;javase&#x2F;javase-jdk8-downloads.html&#x2F;&#x2F;移动至&#x2F;usr&#x2F;local&#x2F;src目录 解压mv jdk-8u271-linux-x64.tar.gz &#x2F;usr&#x2F;local&#x2F;srctar -zxvf jdk-8u271-linux-x64.tar.gz&#x2F;&#x2F;将解压好的JDK移动到&#x2F;usr&#x2F;local下mv jdk1.8.0_271 &#x2F;usr&#x2F;local&#x2F;&#x2F;配置环境变量vim &#x2F;etc&#x2F;profile&#x2F;&#x2F;在最后添加如下环境变量配置后保存并退出：export JAVA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.8.0_271export JRE_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;jdk1.8.0_271&#x2F;jreexport PATH&#x3D;$JAVA_HOME&#x2F;bin:$PATHexport CLASSPATH&#x3D;.:$JAVA_HOME&#x2F;lib&#x2F;tools.jar:$JRE_HOME&#x2F;lib&#x2F;&#x2F;执行如下命令使配置文件生效。source &#x2F;etc&#x2F;profile&#x2F;&#x2F;验证JDK安装情况java -version 安装git12345678910111213141516171819202122232425&#x2F;&#x2F;在&#x2F;usr&#x2F;local&#x2F;src目录下下载Git压缩包cd &#x2F;usr&#x2F;local&#x2F;srcwget https:&#x2F;&#x2F;www.kernel.org&#x2F;pub&#x2F;software&#x2F;scm&#x2F;git&#x2F;git-2.9.4.tar.gz&#x2F;&#x2F;解压压缩包tar -zxvf git-2.9.4.tar.gz&#x2F;&#x2F;安装编译Git时需要的包yum install curl-devel expat-devel gettext-devel openssl-devel zlib-develyum install gcc perl-ExtUtils-MakeMaker&#x2F;&#x2F;删除已有的Gityum remove git&#x2F;&#x2F;进入根目录cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;git-2.9.4&#x2F;&#x2F;安装到&#x2F;usr&#x2F;local&#x2F;git目录.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;git&#x2F;&#x2F;编译安装make &amp;&amp; make install&#x2F;&#x2F;验证GIT安装情况git --version 安装maven12345678910111213141516171819202122&#x2F;&#x2F;在&#x2F;usr&#x2F;local&#x2F;src目录下下载maven压缩包wget http:&#x2F;&#x2F;mirror.bit.edu.cn&#x2F;apache&#x2F;maven&#x2F;maven-3&#x2F;3.3.9&#x2F;binaries&#x2F;apache-maven-3.3.9-bin.tar.gz&#x2F;&#x2F;解压压缩包tar -zxvf apache-maven-3.3.9-bin.tar.gz&#x2F;&#x2F;移动到&#x2F;usr&#x2F;localmv apache-maven-3.3.9 &#x2F;usr&#x2F;local&#x2F;maven3&#x2F;&#x2F;配置环境变量vim &#x2F;etc&#x2F;profile&#x2F;&#x2F;在最后添加如下环境变量后保存退出export MAVEN_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;maven3export PATH&#x3D;$MAVEN_HOME&#x2F;bin:$PATH&#x2F;&#x2F;输入命令使配置生效source &#x2F;etc&#x2F;profile&#x2F;&#x2F;检查是否安装成功mvn -v 安装node执行如下命令下载Node，也可以在本地下载好之后上传到服务器。 1wget https:&#x2F;&#x2F;nodejs.org&#x2F;dist&#x2F;v12.18.3&#x2F;node-v12.18.3-linux-x64.tar.xz 解压并移动到/usr/local/目录下。 12tar -xvf node-v12.18.3-linux-x64.tar.xzmv node-v12.18.3-linux-x64 &#x2F;usr&#x2F;local&#x2F;node-v12.18.3 创建软链接。 123ln -s &#x2F;usr&#x2F;local&#x2F;node-v12.18.3&#x2F;bin&#x2F;node &#x2F;usr&#x2F;local&#x2F;bin&#x2F;nodeln -s &#x2F;usr&#x2F;local&#x2F;node-v12.18.3&#x2F;bin&#x2F;npm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;npmln -s &#x2F;usr&#x2F;local&#x2F;node-v12.18.3&#x2F;bin&#x2F;npx &#x2F;usr&#x2F;local&#x2F;bin&#x2F;npx 验证 123node -vnpm -vnpx -v 安装nginxdocker方式12345678910111213141516171819// 拉取镜像docker pull nginx// 创建文件夹mkdir -p /home/nginx/&#123;html,logs,conf&#125;// 启动一个默认容器 用来复制配置文件docker run --rm --name nginx-test -d nginxdocker cp nginx-test:/etc/nginx/nginx.conf /home/nginx/conf/// 删除镜像docker stop nginx-testdocker rm nginx-test// 运行docker run -d -p 80:80 --name nginx \\ -v /home/nginx/html:/usr/share/nginx/html \\ -v /home/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\ -v /home/nginx/logs:/var/log/nginx \\ nginx 安装包方式准备nginx 1234wget http:&#x2F;&#x2F;nginx.org&#x2F;download&#x2F;nginx-1.18.0.tar.gztar -zxvf nginx-1.18.0.tar.gzmv nginx-1.18.0 &#x2F;usr&#x2F;local&#x2F;srccd &#x2F;usr&#x2F;local&#x2F;src&#x2F;nginx-1.18.0 配置nginx 1.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-http_stub_status_module --with-http_ssl_module 编译安装 1make &amp;&amp; make install 查看nginx版本 123cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbinln -s &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx &#x2F;usr&#x2F;local&#x2F;bin&#x2F;nginxnginx -v 安装docker卸载旧版本 1yum remove docker docker-common docker-selinux 安装需要的依赖包 1yum install -y yum-utils device-mapper-persistent-data 配置稳定仓库 1yum-config-manager --add-repo https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo 安装 1yum install -y docker-ce 启动docker 1systemctl start docker 加入开机启动 1systemctl enable docker 验证安装是否成功 1docker -v 中间件安装MySQL安装docker方式下载MySQL5.7的docker镜像 1docker pull mysql:5.7 使用如下命令启动MySQL服务 123456docker run -p 3306:3306 --name mysql \\-v /data/mysql/log:/var/log/mysql \\-v /data/mysql/data:/var/lib/mysql \\-v /data/mysql/conf:/etc/mysql \\-e MYSQL_ROOT_PASSWORD=root \\-d mysql:5.7 参数说明 -p 3306:3306：将容器的3306端口映射到主机的3306端口 -v /data/mysql/conf:/etc/mysql：将配置文件夹挂在到主机 -v /data/mysql/log:/var/log/mysql：将日志文件夹挂载到主机 -v /data/mysql/data:/var/lib/mysql/：将数据文件夹挂载到主机 -e MYSQL_ROOT_PASSWORD=root：初始化root用户的密码 进入运行MySQL的docker容器 1docker exec -it mysql /bin/bash 使用MySQL命令打开客户端： 1mysql -uroot -proot --default-character-set=utf8 修改默认配置 12345678// 新建/data/mysql/my.cnf配置文件，添加如下配置项。[mysqld] max_connections=2000max_allowed_packet=32Mlower_case_table_names=1character_set_server=utf8mb4collation_server=utf8mb4_bin yum方式由于很多系统yum库中带有MySQL安装包，但由于版本比较老，本次采用yum安装的方式进行较新的数据库版本安装操作。 下载RPM12345678&#x2F;&#x2F;下载RPM，本次安装使用mysql57-community-release-el7-8.noarch.rpm。wget http:&#x2F;&#x2F;dev.mysql.com&#x2F;get&#x2F;mysql57-community-release-el7-8.noarch.rpm&#x2F;&#x2F;下载完成后将Yum库导入到服务器。yum localinstall mysql57-community-release-el7-8.noarch.rpm&#x2F;&#x2F;检查是否安装成功。yum repolist enabled | grep &quot;mysql.*-community.*&quot; 安装MySQL通过第一步的操作，当前的Yum库中已经包含了MySQLServer、MySQL工作台管理工具以及ODBC驱动，现在通过下面的命令简单的安装MySQL。 1234&#x2F;&#x2F;安装mysql服务yum install mysql-community-server至此就可以使用Yum简单的管理MySQL更新，并能确保总是从官网软件库得到最新的发布版。 启动MySQL12345&#x2F;&#x2F;启动MYSQLsystemctl start mysqld&#x2F;&#x2F;查看MySQL的启动状态。systemctl status mysqld 其他设置1234567&#x2F;&#x2F; 开机启动systemctl enable mysqldsystemctl daemon-reload&#x2F;&#x2F;修改MySQL root账号密码&#x2F;&#x2F;MySQL安装完成之后会在&#x2F;var&#x2F;log&#x2F;mysqld.log文件中给root生成了一个默认密码，找到root的默认密码，然后登陆MySQL进行修改。grep &#39;temporary password&#39; &#x2F;var&#x2F;log&#x2F;mysqld.log 1234567891011121314151617181920212223242526&#x2F;&#x2F;使用上一步获取到的root默认密码来登陆MySQL。mysql -uroot -p&#x2F;&#x2F;修改root账号密码 (不能使用弱密码)alter user &#39;root&#39;@&#39;localhost&#39; identified by &#39;Admin@123!&#39;;&#x2F;&#x2F;创建远程登录管理用户&#x2F;&#x2F;为了保证安全以及数据库权限管理方便，root用户不建议开启远程访问，下面我们创建一个可远程访问的用户对数据库进行日常管理工作。GRANT ALL PRIVILEGES ON *.* TO &#39;hzero&#39;@&#39;%&#39; IDENTIFIED BY &#39;s&#39; WITH GRANT OPTION;&#x2F;&#x2F;调整数据库默认配置&#x2F;&#x2F;进入&#x2F;etc&#x2F;my.cnf配置文件，添加如下配置项。max_connections&#x3D;2000max_allowed_packet&#x3D;32Mlower_case_table_names&#x3D;1character_set_server&#x3D;utf8mb4collation_server&#x3D;utf8mb4_bin&#x2F;&#x2F;配置调整好并保存后，请执行下面的命令重启数据库，否则添加的配置不会生效。systemctl restart mysqld&#x2F;&#x2F;MySQL的一些常用的默认文件路径。配置文件：&#x2F;etc&#x2F;my.cnf 日志文件：&#x2F;var&#x2F;log&#x2F;&#x2F;var&#x2F;log&#x2F;mysqld.log 服务启动脚本：&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;mysqld.service socket文件：&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid redis安装docker方式下载Redis5.0的docker镜像 1docker pull redis:5 使用如下命令启动Redis服务： 123docker run -p 6379:6379 --name redis \\-v &#x2F;data&#x2F;redis&#x2F;data:&#x2F;data \\-d redis:5 redis-server --appendonly yes 进入Redis容器使用redis-cli命令进行连接： 1docker exec -it redis redis-cli 安装包方式123456789101112//下载rediscd /usr/localwget http://download.redis.io/releases/redis-4.0.6.tar.gz//解压压缩包tar -zxvf redis-4.0.6.tar.gz//Yum安装gcc依赖，并编译安装rediscd /usr/local/redis-4.0.6yum install gcc -ymake MALLOC=libccd src &amp;&amp; make install 123456789101112131415161718192021222324252627282930//直接启动./redis-server//以后台进程方式启动，需编辑redis.conf文件，并设置daemonize yes。设置后启动如下命令。./redis-server /usr/local/redis-4.0.6/redis.conf//设置redis开机自启动。1.在/etc目录下新建redis目录。cd /etcmkdir redis2.将/usr/local/redis-4.0.6/redis.conf 文件复制一份到/etc/redis目录下，并命名为6379.conf。cp /usr/local/redis-4.0.6/redis.conf /etc/redis/6379.conf3.将redis的启动脚本复制一份放到/etc/init.d目录下。cp /usr/local/redis-4.0.6/utils/redis\\_init\\_script /etc/init.d/redisd4.使用vim编辑redisd文件，在第一行加入如下两行注释，保存退出。vim /etc/init.d/redisd# chkconfig: 2345 90 10# description: Redis is a persistent key-value database5.切换到/etc/init.d目录下,执行自启命令cd /etc/init.dchkconfig redisd on6.以服务的方式启动或关闭redisservice redisd startservice redisd stop minio安装docker方式123456docker run -p 9000:9000 --name minio \\ -e &quot;MINIO_ACCESS_KEY&#x3D;minio&quot; \\ -e &quot;MINIO_SECRET_KEY&#x3D;gulimall_minio&quot; \\ -v &#x2F;data&#x2F;minio&#x2F;data:&#x2F;data \\ -v &#x2F;data&#x2F;minio&#x2F;config:&#x2F;root&#x2F;.minio \\ -d minio&#x2F;minio server &#x2F;data 安装包方式1234567&#x2F;&#x2F;下载安装介质cd &#x2F;usr&#x2F;localwget https:&#x2F;&#x2F;dl.minio.io&#x2F;server&#x2F;minio&#x2F;release&#x2F;linux-amd64&#x2F;minio&#x2F;&#x2F;安装（下文中ip指代的是Minio所在的服务器地址）chmod +x minio.&#x2F;minio server &#x2F;minio&#x2F;data 1234567891011121314&#x2F;&#x2F;开机自启动&#x2F;&#x2F;编写脚本 minioSysInit.sh，脚本内容如下。# !&#x2F;bin&#x2F;bash&#x2F;usr&#x2F;local&#x2F;minio server &#x2F;minio&#x2F;data&#x2F;&#x2F;更改文件权限。chmod +x &#x2F;usr&#x2F;local&#x2F;minioSysInit.sh&#x2F;&#x2F;编辑 rc.local文件，加入脚本。vim &#x2F;etc&#x2F;rc.d&#x2F;rc.local&#x2F;usr&#x2F;local&#x2F;minioSysInit.sh&#x2F;&#x2F;更新rc.local权限chmod +x &#x2F;etc&#x2F;rc.d&#x2F;rc.local jenkins安装1docker run -d --name jenkins -p 9090:8080 -p 50000:50000 -v &#x2F;data&#x2F;jenkins:&#x2F;home&#x2F;jenkins_home --privileged&#x3D;true jenkins&#x2F;jenkins 安装 Publish Over SSH 和 SSH 插件，用于连接各个服务 创建软链 12345Jenkins 通过shell脚本调用 java、mvn 等命令的时候，是从 &#x2F;usr&#x2F;bin 文件夹中找命令的，这个时候需要做个软链接ln -s &#x2F;usr&#x2F;local&#x2F;maven3&#x2F;bin&#x2F;mvn &#x2F;usr&#x2F;bin&#x2F;mvn ln -s &#x2F;usr&#x2F;local&#x2F;jdk1.8.0_172&#x2F;bin&#x2F;jps &#x2F;usr&#x2F;bin&#x2F;jpsln -s &#x2F;usr&#x2F;local&#x2F;jdk1.8.0_172&#x2F;bin&#x2F;java &#x2F;usr&#x2F;bin&#x2F;javaln -s &#x2F;usr&#x2F;local&#x2F;jdk1.8.0_172&#x2F;bin&#x2F;javac &#x2F;usr&#x2F;bin&#x2F;javac zookeeper安装docker方式12345678910111213141516171819202122// 创建挂载目录mkdir -p /zookeeper/confmkdir -p /zookeeper/datamkdir -p /zookeeper/log// 拉取docker pull zookeeper// 启动容器 复制配置文件docker run -d --name zookeeper --restart always zookeeperdocker cp -a zookeeper:/conf/zoo.cfg /Users/tianjie/zookeeper/conf/zoo.cfg// 删除镜像docker rm -f zookeeper//启动容器docker run -d --name zookeeper --restart always \\-p 2181:2181 -p 2888:2888 -p 3888:3888 \\-v /Users/tianjie/zookeeper/conf/zoo.cfg:/conf/zoo.cfg \\-v /Users/tianjie/zookeeper/data:/data \\-v /Users/tianjie/zookeeper/log:/datalog \\zookeeper rabbitmq安装docker方式 1234docker pull rabbitmq:management&#x2F;&#x2F;注意：如果docker pull rabbitmq 后面不带management，启动rabbitmq后是无法打开管理界面的，所以我们要下载带management插件的rabbitmq.docker run -d --name rabbitmq -e RABBITMQ_DEFAULT_USER&#x3D;admin -e RABBITMQ_DEFAULT_PASS&#x3D;admin -p 15672:15672 -p 5672:5672 rabbitmq:management","categories":[],"tags":[{"name":"环境搭建","slug":"环境搭建","permalink":"https://tj-ever.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"}]},{"title":"DOCKER下MYSQL备份还原","slug":"DOCKER下MYSQL备份还原","date":"2020-10-07T14:30:02.000Z","updated":"2020-10-07T15:33:40.232Z","comments":true,"path":"2020/10/07/DOCKER下MYSQL备份还原/","link":"","permalink":"https://tj-ever.github.io/2020/10/07/DOCKER%E4%B8%8BMYSQL%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F/","excerpt":"","text":"12345678910111213141516171819进入mysql容器内docker exec -it mysql bash执行备份mysqldump -uroot -p密码 数据库名&gt; &#x2F;usr&#x2F;local&#x2F;src&#x2F;bak.sql拷贝生成的备份文件至主机目录docker cp mysql:&#x2F;usr&#x2F;local&#x2F;src&#x2F;bak.sql &#x2F;var&#x2F;sqlbak自行下载文件至本地将文件复制到主机mysql容器中docker cp &#x2F;Desktop&#x2F;bak.sql mysql:&#x2F;usr&#x2F;local&#x2F;src恢复数据mysql -u root -p ***create database database1;use database;source &#x2F;home&#x2F;bak.sql","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"https://tj-ever.github.io/tags/docker/"}]},{"title":"ORACLE SQL 常用总结","slug":"ORACLE SQL 常用总结","date":"2020-10-07T14:30:02.000Z","updated":"2020-10-07T15:33:40.231Z","comments":true,"path":"2020/10/07/ORACLE SQL 常用总结/","link":"","permalink":"https://tj-ever.github.io/2020/10/07/ORACLE%20SQL%20%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/","excerpt":"","text":"查询当月数据避免在索引列上使用函数 1234SELECT * FROM table tWHERE 1&#x3D;1AND t.creation_date &gt;&#x3D; TRUNC(SYSDATE, &#39;MM&#39;)AND t.creation_date &lt;&#x3D; last_day(SYSDATE) 查询当天数据避免在索引列上使用函数 1234SELECT * FROM table tWHERE 1&#x3D;1AND t.creation_date &gt;&#x3D; TRUNC(SYSDATE)AND t.creation_date &lt;&#x3D; TRUNC(SYSDATE)+1 查询24小时列表12SELECT lpad(LEVEL - 1, &#39;2&#39;, &#39;0&#39;) hour FROM dual CONNECT BY LEVEL &lt;&#x3D; 24 查询当月天数列表12SELECT lpad(LEVEL, &#39;2&#39;, &#39;0&#39;) day FROM dual CONNECT BY LEVEL &lt;&#x3D; (select to_char(last_day(sysdate), &#39;dd&#39;) from dual) 查询月份列表12select lpad(LEVEL,&#x27;2&#x27;,&#x27;0&#x27;) mm from dualconnect by level &lt;= 12;","categories":[],"tags":[{"name":"sql","slug":"sql","permalink":"https://tj-ever.github.io/tags/sql/"}]},{"title":"REDIS 主从，哨兵，集群，水平扩容","slug":"REDIS 主从，哨兵，集群，水平扩容","date":"2020-10-07T14:30:02.000Z","updated":"2020-10-08T07:24:20.571Z","comments":true,"path":"2020/10/07/REDIS 主从，哨兵，集群，水平扩容/","link":"","permalink":"https://tj-ever.github.io/2020/10/07/REDIS%20%E4%B8%BB%E4%BB%8E%EF%BC%8C%E5%93%A8%E5%85%B5%EF%BC%8C%E9%9B%86%E7%BE%A4%EF%BC%8C%E6%B0%B4%E5%B9%B3%E6%89%A9%E5%AE%B9/","excerpt":"","text":"Redis单实例安装这里使用5.0.X版本，貌似6.0以上版本编译有问题 1234567891011121314151617181920212223242526272829&#x2F;&#x2F;安装gccyum install -y gcc&#x2F;&#x2F;下载redis 解压移动到&#x2F;usr&#x2F;localwget http:&#x2F;&#x2F;download.redis.io&#x2F;releases&#x2F;redis-5.0.8.tar.gztar xvf redis-5.0.8.tar.gz -C &#x2F;usr&#x2F;local&#x2F;cd &#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;&#x2F;编译安装make&#x2F;&#x2F;修改配置文件bind 0.0.0.0daemonize yeslogfile&quot;6380.log&quot;dir&#x2F;usr&#x2F;local&#x2F;redis‐5.0.3&#x2F;data&#x2F;6380&#x2F;&#x2F;创建日志文件目录mkdir -p .&#x2F;data&#x2F;&#123;6379,6380,6381&#125;&#x2F;&#x2F;启动redis-serversrc&#x2F;redis‐server redis.conf&#x2F;&#x2F;查看是否启动成功ps ‐ef|grep redis&#x2F;&#x2F;退出redis1. pkill redis‐server2. kill 进程号3. redis‐cli shutdown Redis主从搭建复制一份redis.conf文件 命名为redis-6380.conf 1234567891011121314151617181920修改相关配置port 6380pidfile &#x2F;var&#x2F;run&#x2F;redis_6380.pidlogfile &quot;6380.log&quot;dir &#x2F;usr&#x2F;local&#x2F;redis‐5.0.8&#x2F;data&#x2F;6380#配置主从#从本机6379的redis实例复制数据replicaof 192.168.8.230 6379replica‐read‐only yes&#x2F;&#x2F;启动从节点src&#x2F;redis-server redis-6380.conf&#x2F;&#x2F;同样操作启动端口为6381的从节点src&#x2F;redis-server redis-6381.conf&#x2F;&#x2F;查看是否启动成功ps ‐ef|grep redis 验证数据同步在6379节点设置一个键 name 在6380节点获取name Redis哨兵搭建 复制一份sentinel.conf文件 命名为sentinel-26379.conf 123456789101112131415161718&#x2F;&#x2F;修改相关配置port 26379daemonize yespidfile &quot;&#x2F;var&#x2F;run&#x2F;redis‐sentinel‐26379.pid&quot;logfile &quot;26379.log&quot;dir &quot;&#x2F;usr&#x2F;local&#x2F;redis‐5.0.3&#x2F;data&quot;#sentinel monitor &lt;master‐name&gt; &lt;ip&gt; &lt;redis‐port&gt; &lt;quorum&gt;#quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为:sentinel总数&#x2F;2+ 1)，master才算真正失效sentinel monitor mymaster 192.168.8.230 6379 2&#x2F;&#x2F;启动哨兵src&#x2F;redis-sentinel sentinel-26379.conf&#x2F;&#x2F;同样方式启动26380，26381两个哨兵&#x2F;&#x2F;查看哨兵ps -ef|grep redis 12&#x2F;&#x2F;查看sentinel的info信息src&#x2F;redis‐cli ‐p 26379 Redis集群搭建 在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率 redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。Redis集群不需要 sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单 集群架构 master slave 192.168.8.230:6379 192.168.8.230:6380 192.168.8.231:6379 192.168.8.231:6380 192.168.8.232:6379 192.168.8.232:6380 123456789101112131415161718192021222324252627&#x2F;&#x2F;分别在三台机器执行 mkdir -p &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;&#123;6379,6380&#125;修改配置文件daemonize yesport 6379dir &#x2F;usr&#x2F;local&#x2F;redis‐cluster&#x2F;6379&#x2F;cluster‐enabled yescluster‐config‐file nodes‐6379.confcluster‐node‐timeout 5000bind 0.0.0.0protected‐mode noappendonly yesrequirepass 123456masterauth 123456&#x2F;&#x2F;修改后的文件分发到每台机器的&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;6379&#x2F;目录下scp redis.conf root@192.168.8.231:&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;6379&#x2F;&#x2F;&#x2F;修改上述配置文件端口为6380&#x2F;&#x2F;再分发到每台机器的&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;6380&#x2F;目录下scp redis.conf root@192.168.8.231:&#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;6380&#x2F;&#x2F;&#x2F;分别启动三台机器的6个redis实例&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-server &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;6379&#x2F;redis.conf&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-server &#x2F;usr&#x2F;local&#x2F;redis-cluster&#x2F;6380&#x2F;redis.conf 12&#x2F;&#x2F;启动集群&#x2F;usr&#x2F;local&#x2F;redis‐5.0.8&#x2F;src&#x2F;redis‐cli ‐a 123456 ‐‐cluster create ‐‐cluster‐replicas 1 192.168.8.230:6379 192.168.8.231:6379 192.168.8.232:6379 192.168.8.230:6380 192.168.8.231:6380 192.168.8.232:6380 启动过程中要输入yes 12345&#x2F;&#x2F;验证集群 连接任意一个客户端&#x2F;usr&#x2F;local&#x2F;redis‐5.0.8&#x2F;src&#x2F;redis‐cli ‐a 123456 ‐c ‐h 192.168.8.230 ‐p 6379&#x2F;&#x2F;查看集群信息cluster info 12&#x2F;&#x2F;查看节点列表cluster nodes //验证数据 12&#x2F;&#x2F;关闭集群 需要一个一个手动关闭&#x2F;usr&#x2F;local&#x2F;redis‐5.0.8&#x2F;src&#x2F;redis‐cli ‐a 123456 ‐c ‐h 192.168.8.230 ‐p 6379 shutdown Redis 集群水平扩容新开一个虚拟机（192.168.8.233） 同上述步骤安装好redis-cluster 12&#x2F;&#x2F;启动查看状态ps -ef|grep redis 123&#x2F;&#x2F;使用add-node命令新增一个主节点192.168.8.233:6380(master)，&#x2F;&#x2F;前面的ip:port为新增节点，后面的ip:port为已知存在节点，&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 --cluster add-node 192.168.8.233:6379 192.168.8.230:6379 看到日志最后有”[OK] New node added correctly”提示代表加入成功 12&#x2F;&#x2F;再次查看集群节点状态，新加入的节点为master，但未分配槽位cluster nodes 当添加节点成功以后，新增的节点不会有任何数据，因为它还没有分配任何的slot(hash槽)，我们需要为新节点手工分配hash槽 12&#x2F;&#x2F;使用redis-cli命令为6379分配hash槽，找到集群中的任意一个主节点，对其进行重新分片工作&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 --cluster reshared 192.168.8.230:6379 输入要分配的槽位 比如2000输入被分配的节点id 1234567Please enter all the source node IDs.Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.Type &#39;done&#39; once you entered all the source nodes IDs.&#x2F;&#x2F;这里输入all，代表从所有主节点抽取槽位平均分配Source node 1:all&#x2F;&#x2F;接下来输入yes 使用默认的分配计划后执行完毕 查看发现 该节点从其他节点分配了三个槽位 共2000个 12&#x2F;&#x2F;添加192.168.8.233:6380从节点到集群中&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 --cluster add-node 192.168.8.233:6380 192.168.8.230:6379 再次查看集群状态 发现新加入的还是master节点,没有被分配任何的hash槽。 我们需要执行replicate命令来指定当前节点(从节点)的主节点id为哪个,首先需要连接新加的从节点的客户端，然后使用集群命令进行 操作，把当前的从节点指定到一个主节点下(这里使用之前创建的192.168.8.233:6379主节点) 12345&#x2F;&#x2F;链接从节点&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 -c -h 192.168.8.233 -p 6380&#x2F;&#x2F;指定主节点cluster replicate 5300b222af6045d38886fc1c7c01f240c24ba09e 再次查看集群状态，已经成功添加指定主节点的从节点 删除从节点12&#x2F;&#x2F;删除指定从节点&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 --cluster del-node 192.168.8.233:6380 adbb4548f6cc0ba6f79c98552b3f41eaa63b7e49 删除主节点删除主节点需要将之前分配的槽位转移到其他可用的主节点中，然后在进行移除主节点操作 12&#x2F;&#x2F;将192.168.8.233:6379的槽位转移到192.168.8.230:6379&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 --cluster reshard 192.168.8.230:6379 步骤同添加时一样不同的是source node #1 步骤输入 待删除的主节点IDsource node #2 步骤输入 done 表示立即执行 再次查看集群状态发现该节点已经没有槽位 12&#x2F;&#x2F;最后再直接使用del-node删除主节点&#x2F;usr&#x2F;local&#x2F;redis-5.0.8&#x2F;src&#x2F;redis-cli -a 123456 --cluster del-node 192.168.8.233:6379 5300b222af6045d38886fc1c7c01f240c24ba09e 最后查看集群状态 主节点已经成功删除","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://tj-ever.github.io/tags/redis/"}]},{"title":"二进制部署K8S集群","slug":"二进制部署K8S集群","date":"2020-10-07T14:30:02.000Z","updated":"2020-10-08T07:17:27.067Z","comments":true,"path":"2020/10/07/二进制部署K8S集群/","link":"","permalink":"https://tj-ever.github.io/2020/10/07/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2K8S%E9%9B%86%E7%BE%A4/","excerpt":"","text":"环境信息资源划分 角色 ip 组件 master 192.168.8.130 kube-apiserver,kube-controller-manager,kube-scheduler,etcd node1 192.168.8.131 kubelet,kube-proxy,docker,flannel,etcd node2 192.168.8.132 kubelet,kube-proxy,docker,flannel,etcd 软件版本 软件 版本 操作系统 centos7.6 docker 18.09.0 kubernetes 1.17.6 etcd 3.2.7 flannel 0.10.0 上述机器配置为1台master节点，2台node节点，使用的软件百度自行下载，版本号最好对应 证书创建为了方便脚本，在每台机器上设置环境变量，其中CURRENT_IP为当前机器的ip 1234export MASTER_IP&#x3D;192.168.8.130 export NODE1_IP&#x3D;192.168.8.131 export NODE2_IP&#x3D;192.168.8.132 export CURRENT_IP&#x3D;192.168.8.130 安装cfssl 证书工具 12345678910111213wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssl_linux-amd64 wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssljson_linux-amd64 wget https:&#x2F;&#x2F;pkg.cfssl.org&#x2F;R1.2&#x2F;cfssl-certinfo_linux-amd64 chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64 mv cfssl_linux-amd64 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;cfssl mv cfssljson_linux-amd64 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;cfssljson mv cfssl-certinfo_linux-amd64 &#x2F;usr&#x2F;bin&#x2F;cfssl-certinfo cat &gt; &#x2F;etc&#x2F;profile.d&#x2F;cfssl.sh &lt;&lt;EOF export PATH&#x3D;&#x2F;usr&#x2F;bin&#x2F;:$PATH EOF source &#x2F;etc&#x2F;profile 创建证书目录，生成的目录都放在该文件夹中 1mkdir -p &#x2F;opt&#x2F;certs &amp;&amp; cd &#x2F;opt&#x2F;certs 创建证书机构 1234567891011121314151617181920212223242526272829303132333435363738394041cat &gt; ca-config.json &lt;&lt;EOF &#123; &quot;signing&quot;: &#123; &quot;default&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot; &#125;, &quot;profiles&quot;: &#123; &quot;kubernetes&quot;: &#123; &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] &#125; &#125; &#125; &#125; EOF cat &gt; ca-csr.json &lt;&lt;EOF &#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ] &#125; EOF cfssl gencert -initca ca-csr.json | cfssljson -bare ca 创建etcd证书 12345678910111213141516171819202122232425cat &gt; etcd-csr.json &lt;&lt;EOF &#123; &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;$&#123;MASTER_IP&#125;&quot;, &quot;$&#123;NODE1_IP&#125;&quot;, &quot;$&#123;NODE2_IP&#125;&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ] &#125; EOF cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes etcd-csr.json | cfssljson -bare etcd 创建kube-apiserver证书 1234567891011121314151617181920212223242526272829303132cat &gt; kube-apiserver-csr.json &lt;&lt;EOF &#123; &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;10.0.0.1&quot;, &quot;127.0.0.1&quot;, &quot;$&#123;MASTER_IP&#125;&quot;, &quot;$&#123;NODE1_IP&#125;&quot;, &quot;$&#123;NODE2_IP&#125;&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ] &#125; EOF cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver 创建kube-proxy证书 123456789101112131415161718192021cat &gt; kube-proxy-csr.json &lt;&lt;EOF &#123; &quot;CN&quot;: &quot;system:kube-proxy&quot;, &quot;hosts&quot;: [], &quot;key&quot;: &#123; &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 &#125;, &quot;names&quot;: [ &#123; &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; &#125; ] &#125; EOF cfssl gencert -ca&#x3D;ca.pem -ca-key&#x3D;ca-key.pem -config&#x3D;ca-config.json -profile&#x3D;kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 查看生成的证书，如果和下方截图一致，代表创建成功 分发证书 分发证书至每个机器节点上对应的目录上，在生成证书的主机执以下命令，自行替换主机ip 1234ssh root@$&#123;MASTER_IP&#125; &quot;mkdir -p &#x2F;opt&#x2F;kubernetes&#x2F;ssl&quot; scp &#x2F;opt&#x2F;certs&#x2F;*pem root@$&#123;MASTER_IP&#125;:&#x2F;opt&#x2F;kubernetes&#x2F;ssh root@$&#123;MASTER_IP&#125; &quot;mkdir -p &#x2F;opt&#x2F;etcd&#x2F;ssl&quot; scp &#x2F;opt&#x2F;certs&#x2F;*pem root@$&#123;MASTER_IP&#125;:&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F; 安装etcd集群下载etcd-v3.2.7-linux-amd64.tar.gz到每台主机上 1wget https:&#x2F;&#x2F;github.com&#x2F;etcd-io&#x2F;etcd&#x2F;releases&#x2F;download&#x2F;v3.2.7&#x2F;etcd-v3.2.7-linux-amd64.tar.gz 解压并生成对应目录 1234567891011mkdir &#x2F;opt&#x2F;etcd&#x2F;&#123;bin,cfg,ssl&#125; -p tar zxvf etcd-v3.2.7-linux-amd64.tar.gz mv etcd-v3.2.7-linux-amd64&#x2F;&#123;etcd,etcdctl&#125; &#x2F;opt&#x2F;etcd&#x2F;bin&#x2F; cat &gt; &#x2F;etc&#x2F;profile.d&#x2F;etcd.sh &lt;&lt;EOF export PATH&#x3D;&#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;:$PATH EOF source &#x2F;etc&#x2F;profile 使用systemd管理etcd，并生成配置文件，以下命令需要在每台主机上分别执行etcd集群的名称使用etcd前缀拼接主机名形成 此处注意各个ip对应的环境变量是否有值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950cat &gt; &#x2F;opt&#x2F;etcd&#x2F;cfg&#x2F;etcd &lt;&lt;EOF #[Member] ETCD_NAME&#x3D;&quot;etcd-$HOSTNAME&quot; ETCD_DATA_DIR&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;default.etcd&quot; ETCD_LISTEN_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;$&#123;CURRENT_IP&#125;:2380&quot; ETCD_LISTEN_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;$&#123;CURRENT_IP&#125;:2379&quot; #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS&#x3D;&quot;https:&#x2F;&#x2F;$&#123;CURRENT_IP&#125;:2380&quot; ETCD_ADVERTISE_CLIENT_URLS&#x3D;&quot;https:&#x2F;&#x2F;$&#123;CURRENT_IP&#125;:2379&quot; ETCD_INITIAL_CLUSTER&#x3D;&quot;etcd-master&#x3D;https:&#x2F;&#x2F;$&#123;MASTER_IP&#125;:2380,etcd-node1&#x3D;https:&#x2F;&#x2F;$&#123;NODE1_IP&#125;:2380,etcd-node2&#x3D;https:&#x2F;&#x2F;$&#123;NODE2_IP&#125;:2380&quot; ETCD_INITIAL_CLUSTER_TOKEN&#x3D;&quot;etcd-cluster&quot; ETCD_INITIAL_CLUSTER_STATE&#x3D;&quot;new&quot; EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;etcd.service &lt;&lt;EOF [Unit] Description&#x3D;Etcd Server After&#x3D;network.target After&#x3D;network-online.target Wants&#x3D;network-online.target [Service] Type&#x3D;notify EnvironmentFile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;cfg&#x2F;etcd ExecStart&#x3D;&#x2F;opt&#x2F;etcd&#x2F;bin&#x2F;etcd \\ --name&#x3D;\\$&#123;ETCD_NAME&#125; \\ --data-dir&#x3D;\\$&#123;ETCD_DATA_DIR&#125; \\ --listen-peer-urls&#x3D;\\$&#123;ETCD_LISTEN_PEER_URLS&#125; \\ --listen-client-urls&#x3D;\\$&#123;ETCD_LISTEN_CLIENT_URLS&#125;,http:&#x2F;&#x2F;127.0.0.1:2379 \\ --advertise-client-urls&#x3D;\\$&#123;ETCD_ADVERTISE_CLIENT_URLS&#125; \\ --initial-advertise-peer-urls&#x3D;\\$&#123;ETCD_INITIAL_ADVERTISE_PEER_URLS&#125; \\ --initial-cluster&#x3D;\\$&#123;ETCD_INITIAL_CLUSTER&#125; \\ --initial-cluster-token&#x3D;\\$&#123;ETCD_INITIAL_CLUSTER_TOKEN&#125; \\ --initial-cluster-state&#x3D;new \\ --cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd.pem \\ --key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd-key.pem \\ --peer-cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd.pem \\ --peer-key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd-key.pem \\ --trusted-ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \\ --peer-trusted-ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem Restart&#x3D;on-failure LimitNOFILE&#x3D;65536 [Install] WantedBy&#x3D;multi-user.target EOF 启动etcd，设置开机启动（三台集群都要启动） 12systemctl start etcd systemctl enable etcd 在任一台etcd节点上查看集群健康状态 1234etcdctl \\ --ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem --cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd.pem --key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd-key.pem \\ --endpoints&#x3D;&quot;https:&#x2F;&#x2F;$&#123;MASTER_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE1_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE2_IP&#125;:2379&quot; \\ cluster-health 看到如下截图代表etcd集群搭建成功 Node节点安装Docker分别在两台node节点执行以下命令安装docker卸载旧版本 1yum remove docker docker-common docker-selinux 安装需要的依赖包： 1yum install -y yum-utils device-mapper-persistent-data 配置稳定仓库： 1yum-config-manager --add-repo https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo 安装： 1yum install docker-ce 启动docker： 1systemctl start docker 加入开机启动： 1systemctl enable docker 验证安装是否成功： 1docker -v 安装flannel网络Falnnel要用etcd存储自身一个子网信息，所以要保证能成功连接Etcd，写入预定义子网段，在任一个节点执行如下命令即可 1234etcdctl \\ --ca-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem --cert-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd.pem --key-file&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd-key.pem \\ --endpoints&#x3D;&quot;https:&#x2F;&#x2F;$&#123;MASTER_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE1_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE2_IP&#125;:2379&quot; \\ set &#x2F;coreos.com&#x2F;network&#x2F;config &#39;&#123; &quot;Network&quot;: &quot;172.17.0.0&#x2F;16&quot;, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&#39; 执行完成会返回网段信息 下载flannel文件，解压并生成相应目录 1234wget https:&#x2F;&#x2F;github.com&#x2F;coreos&#x2F;flannel&#x2F;releases&#x2F;download&#x2F;v0.10.0&#x2F;flannel-v0.10.0-linux-amd64.tar.gz tar zxvf flannel-v0.10.0-linux-amd64.tar.gz mkdir -p &#x2F;opt&#x2F;kubernetes&#x2F;&#123;bin,cfg,ssl&#125; mv flanneld mk-docker-opts.sh &#x2F;opt&#x2F;kubernetes&#x2F;bin 使用systemd管理flannel，并生成对应配置文件 1234567891011121314151617181920212223cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;flanneld &lt;&lt;EOF FLANNEL_OPTIONS&#x3D;&quot;--etcd-endpoints&#x3D;https:&#x2F;&#x2F;$&#123;MASTER_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE1_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE2_IP&#125;:2379 -etcd-cafile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem -etcd-certfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd.pem -etcd-keyfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd-key.pem&quot; EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;flanneld.service &lt;&lt;EOF [Unit] Description&#x3D;Flanneld overlay address etcd agent After&#x3D;network-online.target network.target Before&#x3D;docker.service [Service] Type&#x3D;notify EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;flanneld ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;flanneld --ip-masq $FLANNEL_OPTIONS ExecStartPost&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d &#x2F;run&#x2F;flannel&#x2F;subnet.env Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target EOF 配置Docker启动指定子网段指定网段环境EnvironmentFile=/run/flannel/subnet.env 123456789101112131415161718192021222324252627cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service &lt;&lt;EOF [Unit] Description&#x3D;Docker Application Container Engine Documentation&#x3D;https:&#x2F;&#x2F;docs.docker.com After&#x3D;network-online.target firewalld.service Wants&#x3D;network-online.target [Service] Type&#x3D;notify EnvironmentFile&#x3D;&#x2F;run&#x2F;flannel&#x2F;subnet.env ExecStart&#x3D;&#x2F;usr&#x2F;bin&#x2F;dockerd $DOCKER_NETWORK_OPTIONS ExecReload&#x3D;&#x2F;bin&#x2F;kill -s HUP $MAINPID LimitNOFILE&#x3D;infinity LimitNPROC&#x3D;infinity LimitCORE&#x3D;infinity TimeoutStartSec&#x3D;0 Delegate&#x3D;yes KillMode&#x3D;process Restart&#x3D;on-failure StartLimitBurst&#x3D;3 StartLimitInterval&#x3D;60s [Install] WantedBy&#x3D;multi-user.target EOF 启动flanneld服务（注意先启动flanneld，再启动docker），查看运行状态 12345systemctl daemon-reload systemctl start flanneld systemctl enable flanneld systemctl restart docker systemctl status flanneld 安装kube-apiserver在master节点上安装kube-apiserver服务下载kube-apiserver安装包需要的文件，包含了所需的所有组件。 文件下载地址 1https:&#x2F;&#x2F;dl.k8s.io&#x2F;v1.17.6&#x2F;kubernetes-server-linux-arm64.tar.gz 下载解压文件至对应目录 12345678910mkdir &#x2F;opt&#x2F;kubernetes&#x2F;&#123;bin,cfg,ssl&#125; -p tar zxvf kubernetes-server-linux-amd64.tar.gz cd kubernetes&#x2F;server&#x2F;bin cp kube-apiserver kube-scheduler kube-controller-manager kubectl &#x2F;opt&#x2F;kubernetes&#x2F;bincat &gt; &#x2F;etc&#x2F;profile.d&#x2F;k8s.sh &lt;&lt;EOF export PATH&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;:$PATH EOF source &#x2F;etc&#x2F;profile 新建token文件 1234export BOOTSTRAP_TOKEN&#x3D;$(head -c 16 &#x2F;dev&#x2F;urandom | od -An -t x | tr -d &#39; &#39;) cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;token.csv &lt;&lt;EOF $&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot; EOF 使用systemd管理kube-apiserver，并生成对应配置文件 1234567891011121314151617181920212223242526272829303132333435363738cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-apiserver &lt;&lt;EOF KUBE_APISERVER_OPTS&#x3D;&quot;--logtostderr&#x3D;true \\ --v&#x3D;4 \\ --etcd-servers&#x3D;https:&#x2F;&#x2F;$&#123;MASTER_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE1_IP&#125;:2379,https:&#x2F;&#x2F;$&#123;NODE2_IP&#125;:2379 \\ --bind-address&#x3D;$&#123;MASTER_IP&#125; \\ --secure-port&#x3D;6443 \\ --advertise-address&#x3D;$&#123;MASTER_IP&#125; \\ --allow-privileged&#x3D;true \\ --service-cluster-ip-range&#x3D;10.0.0.0&#x2F;24 \\ --enable-admission-plugins&#x3D;NamespaceLifecycle,LimitRanger,ServiceAccount,ResourceQuota,NodeRestriction \\ --authorization-mode&#x3D;RBAC,Node \\ --enable-bootstrap-token-auth \\ --token-auth-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;token.csv \\ --service-node-port-range&#x3D;30000-50000 \\ --tls-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;kube-apiserver.pem \\ --tls-private-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;kube-apiserver-key.pem \\ --client-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\ --service-account-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem \\ --etcd-cafile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;ca.pem \\ --etcd-certfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd.pem \\ --etcd-keyfile&#x3D;&#x2F;opt&#x2F;etcd&#x2F;ssl&#x2F;etcd-key.pem&quot; EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-apiserver.service &lt;&lt;EOF [Unit] Description&#x3D;Kubernetes API Server Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes [Service] EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-apiserver ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-apiserver \\$KUBE_APISERVER_OPTS Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target EOF 启动kube-apiserver服务，查看服务状态 1234systemctl daemon-reload systemctl enable kube-apiserversystemctl start kube-apiserver systemctl status kube-apiserver 安装kube-scheduler在master节点上安装kube-scheduler服务 使用systemd管理kube-scheduler，并生成对应配置文件 1234567891011121314151617181920212223cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler &lt;&lt;EOF KUBE_SCHEDULER_OPTS&#x3D;&quot;--logtostderr&#x3D;true \\ --v&#x3D;4 \\ --master&#x3D;127.0.0.1:8080 \\ --leader-elect&quot; EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-scheduler.service &lt;&lt;EOF [Unit] Description&#x3D;Kubernetes Scheduler Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes [Service] EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-scheduler ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-scheduler \\$KUBE_SCHEDULER_OPTS Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target EOF 启动kube-scheduler服务，并查看服务状态 1234systemctl daemon-reload systemctl enable kube-scheduler systemctl start kube-scheduler systemctl status kube-scheduler 安装kube-controller-manager在master节点上安装kube-controller-manager服务 使用systemd管理kube-controller-manager，并生成对应配置文件 12345678910111213141516171819202122232425262728cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager &lt;&lt;EOF KUBE_CONTROLLER_MANAGER_OPTS&#x3D;&quot;--logtostderr&#x3D;true \\ --v&#x3D;4 \\ --master&#x3D;127.0.0.1:8080 \\ --leader-elect&#x3D;true \\ --address&#x3D;127.0.0.1 \\ --service-cluster-ip-range&#x3D;10.0.0.0&#x2F;24 \\ --cluster-name&#x3D;kubernetes \\ --cluster-signing-cert-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\ --cluster-signing-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem \\ --root-ca-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\ --service-account-private-key-file&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca-key.pem&quot; EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-controller-manager.service &lt;&lt;EOF [Unit] Description&#x3D;Kubernetes Controller Manager Documentation&#x3D;https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes [Service] EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-controller-manager ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-controller-manager \\$KUBE_CONTROLLER_MANAGER_OPTS Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target EOF 启动controller-manager服务，并查看服务状态 1234systemctl daemon-reload systemctl enable kube-controller-manager systemctl start kube-controller-manager systemctl status kube-controller-manager 检查master节点组件状态执行到这一步，master节点上需要的组件已经安装完毕，使用kubectl检查节点健康状态。 1kubectl get cs 调试方法（个人经验三种）： 如果某个组件启动失败，可以去/usr/lib/systemd/system/目录下找到对应组件的service文件，然后手动拼接参数，执行命令，这样可以看出是哪个参数导致的启动失败 使用systemctl status [服务名] 命令，去查看组件的失败原因 使用journalctl -u [服务名] 命令，查看启动日志 部署Node节点在master节点执行以下命令,将kubelet-bootstrap用户绑定到系统集群角色 123kubectl create clusterrolebinding kubelet-bootstrap \\ --clusterrole&#x3D;system:node-bootstrapper \\ --user&#x3D;kubelet-bootstrap 创建kubeconfig文件,对应kube-apiserver和kube-proxy组件(每个文件四步骤) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748cd &#x2F;opt&#x2F;kubernetes&#x2F;cfg export KUBE_APISERVER&#x3D;&quot;https:&#x2F;&#x2F;$&#123;MASTER_IP&#125;:6443&quot; # 设置集群参数 kubectl config set-cluster kubernetes \\ --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\ --embed-certs&#x3D;true \\ --server&#x3D;$&#123;KUBE_APISERVER&#125; \\ --kubeconfig&#x3D;bootstrap.kubeconfig # 设置客户端认证参数 kubectl config set-credentials kubelet-bootstrap \\ --token&#x3D;$&#123;BOOTSTRAP_TOKEN&#125; \\ --kubeconfig&#x3D;bootstrap.kubeconfig # 设置上下文参数 kubectl config set-context default \\ --cluster&#x3D;kubernetes \\ --user&#x3D;kubelet-bootstrap \\ --kubeconfig&#x3D;bootstrap.kubeconfig # 设置默认上下文 kubectl config use-context default --kubeconfig&#x3D;bootstrap.kubeconfig # 设置集群参数 kubectl config set-cluster kubernetes \\ --certificate-authority&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;ca.pem \\ --embed-certs&#x3D;true \\ --server&#x3D;$&#123;KUBE_APISERVER&#125; \\ --kubeconfig&#x3D;kube-proxy.kubeconfig # 设置客户端认证参数 kubectl config set-credentials kube-proxy \\ --client-certificate&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;kube-proxy.pem \\ --client-key&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl&#x2F;kube-proxy-key.pem \\ --embed-certs&#x3D;true \\ --kubeconfig&#x3D;kube-proxy.kubeconfig # 设置上下文参数 kubectl config set-context default \\ --cluster&#x3D;kubernetes \\ --user&#x3D;kube-proxy \\ --kubeconfig&#x3D;kube-proxy.kubeconfig # 设置默认上下文 kubectl config use-context default --kubeconfig&#x3D;kube-proxy.kubeconfig 执行完后会生成两个配置文件，如下图 将这两个文件分发到node节点的/opt/kubernetes/cfg目录下，自行替换ip 1scp *kubeconfig root@$&#123;NODE1_IP&#125;:&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F; 部署kubelet组件将前面下载的二进制包server/bin文件夹下的kubelet和kube-proxy分发到每个node节点的/opt/kubernetes/bin目录下,自行替换ip 在master节点执行 12scp &#x2F;root&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kubelet $&#123;NODE1_IP&#125;:&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F; scp &#x2F;root&#x2F;kubernetes&#x2F;server&#x2F;bin&#x2F;kube-proxy $&#123;NODE1_IP&#125;:&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F; 设置环境变量方便调用，在每个node节点执行 12345cat &gt; &#x2F;etc&#x2F;profile.d&#x2F;k8s.sh &lt;&lt;EOF export PATH&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;:$PATH EOF source &#x2F;etc&#x2F;profile 使用systemd管理kubelet，并生成对应配置文件，在每个node节点执行 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet &lt;&lt;EOF KUBELET_OPTS&#x3D;&quot;--logtostderr&#x3D;true \\ --v&#x3D;4 \\ --hostname-override&#x3D;$&#123;CURRENT_IP&#125; \\ --kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.kubeconfig \\ --bootstrap-kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;bootstrap.kubeconfig \\ --config&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.config \\ --cert-dir&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;ssl \\ --pod-infra-container-image&#x3D;registry.cn-hangzhou.aliyuncs.com&#x2F;google-containers&#x2F;pause-amd64:3.0&quot; EOF cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet.config &lt;&lt;EOF kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io&#x2F;v1beta1 address: $&#123;CURRENT_IP&#125; port: 10250 readOnlyPort: 10255 cgroupDriver: cgroupfs clusterDNS: [&quot;10.0.0.2&quot;] clusterDomain: cluster.local. failSwapOn: false authentication: anonymous: enabled: true webhook: enabled: false EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kubelet.service &lt;&lt;EOF [Unit] Description&#x3D;Kubernetes Kubelet After&#x3D;docker.service Requires&#x3D;docker.service [Service] EnvironmentFile&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kubelet ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kubelet \\$KUBELET_OPTS Restart&#x3D;on-failure KillMode&#x3D;process [Install] WantedBy&#x3D;multi-user.target EOF 启动kubelet服务，并查看服务状态 1234systemctl daemon-reload systemctl enable kubelet systemctl start kubelet systemctl status kubelet 部署kube-proxy组件在每个node节点部署kube-proxy组件 使用systemd管理kube-proxy，并生成对应配置文件，在每个node节点执行 1234567891011121314151617181920212223cat &gt; &#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy &lt;&lt;EOF KUBE_PROXY_OPTS&#x3D;&quot;--logtostderr&#x3D;true \\ --v&#x3D;4 \\ --hostname-override&#x3D;$&#123;CURRENT_IP&#125; \\ --cluster-cidr&#x3D;10.0.0.0&#x2F;24 \\ --kubeconfig&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy.kubeconfig&quot; EOF cat &gt; &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;kube-proxy.service &lt;&lt;EOF [Unit] Description&#x3D;Kubernetes Proxy After&#x3D;network.target [Service] EnvironmentFile&#x3D;-&#x2F;opt&#x2F;kubernetes&#x2F;cfg&#x2F;kube-proxy ExecStart&#x3D;&#x2F;opt&#x2F;kubernetes&#x2F;bin&#x2F;kube-proxy \\$KUBE_PROXY_OPTS Restart&#x3D;on-failure [Install] WantedBy&#x3D;multi-user.target EOF 启动kube-proxy服务，并查看服务状态 1234systemctl daemon-reload systemctl enable kube-proxy systemctl start kube-proxy systemctl status kube-proxy Node节点加入集群在Master审批Node加入集群，在master节点执行以下操作 1kubectl get csr 可以看到两个node节点状态都是pending状态 12kubectl certificate approve node-csr-8iAugiIKMh7XiOPMsJrYK5jmO14kjRUwQaWnxpVL8Z4kubectl certificate approve node-csr-ZPkSYyZFId00gKSQ-d3jiB5y72-Gj7EwucBWVf7WEgA 审批通过两个node节点后，可以看到状态变为如下：此时检查集群状态（这一步要等待，启动有一定过程） 1kubectl get node 1kubectl get cs 创建pod测试集群创建Nginx 服务，判断集群是否正常工作 创建三个副本的nginx容器 1kubectl run nginx --image&#x3D;nginx --replicas&#x3D;3 暴露端口 1kubectl expose deployment nginx --port&#x3D;88 --target-port&#x3D;80 --type&#x3D;NodePort 查看pod和service 12kubectl get podskubectl get svc 可以看到分配端口号为38868 查看一下pod被调度到哪台机器上 1kubectl get pod -o wide 可以看到两台在node1节点，1台在node2节点 此时访问node1节点的38868端口，即可看到nginx服务启动成功，说明k8s集群搭建成功。","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://tj-ever.github.io/tags/k8s/"}]},{"title":"REDIS 缓存设计和性能优化","slug":"REDIS 缓存设计和性能优化","date":"2020-10-07T14:11:34.000Z","updated":"2020-10-08T07:21:11.853Z","comments":true,"path":"2020/10/07/REDIS 缓存设计和性能优化/","link":"","permalink":"https://tj-ever.github.io/2020/10/07/REDIS%20%E7%BC%93%E5%AD%98%E8%AE%BE%E8%AE%A1%E5%92%8C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","excerpt":"","text":"缓存穿透 缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常出于容错的考虑，如果从存储层查不到数据则不写入缓存层。缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。 造成缓存穿透的基本原因有两个: 自身业务代码或者数据出现问题。 恶意攻击、 爬虫等造成大量空命中。 解决方案请求在存储层查不到数据时，将该key值缓存一个空对象，避免后续继续请求存储层。 123456789101112131415161718String get(String key) &#123; &#x2F;&#x2F; 从缓存中获取数据 String cacheValue &#x3D; cache.get(key); &#x2F;&#x2F; 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; &#x2F;&#x2F; 从存储中获取 String storageValue &#x3D; storage.get(key); cache.set(key, storageValue); &#x2F;&#x2F; 如果存储数据为空， 需要设置一个过期时间(300秒) if (storageValue &#x3D;&#x3D; null) &#123; cache.expire(key, 60 * 5); &#125; return storageValue; &#125; else &#123; &#x2F;&#x2F; 缓存非空 return cacheValue; &#125; &#125; 布隆过滤器 对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。 布隆过滤器就是一个大型的位数组和几个不一样的无偏 hash 函数。所谓无偏就是能够把元素的 hash 值算得比较均匀。向布隆过滤器中添加 key 时，会使用多个 hash 函数对 key 进行 hash 算得一个整数索引值然后对位数组长度进行取模运算得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 的几个位置都算出来，看看位数组中这几个位 置是否都为 1，只要有一个位为 0，那么说明布隆过滤器中这个key 不存在。如果都是 1，这并不能说明这个 key 就一定存在，只是极有可能存在，因为这些位被置为 1 可能是因为其它的 key 存在所致。如果这个位数组比较稀疏，这个概率就会很大，如果这个位数组比较拥挤，这个概率就会降低。这种方法适用于数据命中不高，数据相对固定，实时性低(通常是数据集较大) 的应用场景，代码维护较为复杂，但是缓存空间占用很少。 缓存失效 由于大批量缓存在同一时间失效可能导致大量请求同时穿透缓存直达数据库，可能会造成数据库瞬间压力过大甚至挂掉，对于这种情况我们在批量增加缓存时最好将这一批数据的缓存过期时间设置为一个时间段内的不同时间。 解决方案同一批数据缓存时间设置为一段随机时间。 12345678910111213141516171819String get(String key) &#123; &#x2F;&#x2F; 从缓存中获取数据 String cacheValue &#x3D; cache.get(key); &#x2F;&#x2F; 缓存为空 if (StringUtils.isBlank(cacheValue)) &#123; &#x2F;&#x2F; 从存储中获取 String storageValue &#x3D; storage.get(key); cache.set(key, storageValue); &#x2F;&#x2F;设置一个过期时间(300到600之间的一个随机数) int expireTime &#x3D; new Random().nextInt(300) + 300; if (storageValue &#x3D;&#x3D; null) &#123; cache.expire(key, expireTime); &#125; return storageValue; &#125; else &#123; &#x2F;&#x2F; 缓存非空 return cacheValue; &#125; &#125; 缓存雪崩 缓存雪崩指的是缓存层支撑不住或宕掉后，请求全部打向后端存储层。由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不能提供服务(比如超大并发过来，缓存层支撑不住，或者由于缓存设计不好，类似大量请求访问bigkey，导致缓存能支撑的并发急剧下降)，于是大量请求都会达到存储层，存储层的调用量会暴增，造成存储层也会级联宕机的情况。 解决方案预防和解决缓存雪崩问题，可从以下三个方面进行着手。 保证缓存层服务高可用性，使用Redis Sentinel或Redis Cluster。 依赖隔离组件为后端限流并降级。使用Hystrix限流降级组件。 提前演练。在项目上线前演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。 热点缓存key重建优化 开发人员使用“缓存+过期时间”的策略既可以加速数据读写， 又保证数据的定期更新， 这种模式基本能够满足绝大部分需求。 但是有两个问题如果同时出现，可能就会对应用造成致命的危害: 当前key是一个热点key(例如一个热门的娱乐新闻)，并发量非常大。 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、 多次IO、 多个依赖等。 在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。 解决方案要解决这个问题主要就是要避免大量线程同时重建缓存，可以利用互斥锁来解决。如果是单机，可以用synchronized或者lock来处理。如果是分布式环境可以用分布式锁（比如memcache的add, redis的setnx, zookeeper的添加节点操作）。 使用redis的setnx，此方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行完，重新从缓存获取数据即可。 12345678910111213141516171819202122String get(String key) &#123; &#x2F;&#x2F; 从Redis中获取数据 String value &#x3D; redis.get(key); &#x2F;&#x2F; 如果value为空， 则开始重构缓存 if (value &#x3D;&#x3D; null) &#123; &#x2F;&#x2F; 只允许一个线程重建缓存， 使用nx， 并设置过期时间ex String mutexKey &#x3D; &quot;mutext:key:&quot; + key; if (redis.set(mutexKey, &quot;1&quot;, &quot;ex 180&quot;, &quot;nx&quot;)) &#123; &#x2F;&#x2F; 从数据源获取数据 value &#x3D; db.get(key); &#x2F;&#x2F; 回写Redis， 并设置过期时间 redis.setex(key, timeout, value); &#x2F;&#x2F; 删除key_mutex redis.delete(mutexKey); &#125;&#x2F;&#x2F; 其他线程休息50毫秒后重试 else &#123; Thread.sleep(50); get(key); &#125; &#125; return value; &#125; Bigkey问题 在Redis中，一个字符串最大512MB，一个二级数据结构(例如hash、list、set、zset)可以存储大约40亿个(2^32-1)个元素，但实际中如果下面两种情况，会认为它是bigkey。 字符串类型:它的big体现在单个value值很大，一般认为超过10KB就是bigkey。 非字符串类型:哈希、列表、集合、有序集合，它们的big体现在元素个数太多。 一般来说，string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞) bigkey 危害 导致redis阻塞 网络拥塞bigkey也就意味着每次获取要产生的网络流量较大，假设一个bigkey为1MB，客户端每秒访问量为1000，那么每秒产生1000MB的流量，对于普通的千兆网卡(按照字节算是128MB/s)的服务器来说简直是灭顶之灾，而且一般服务器会采用单机多实例的方式来部署，也就是说一个bigkey 可能会对其他实例也造成影响，其后果不堪设想。 过期删除一个bigkey，它只执行简单的命令，例如hget、lpop、zscore等，但它设置了过期时间，当它过期后会被删除，如果没有使用Redis 4.0的过期异步删除(lazyfree-lazy-expire yes)，就会存在阻塞Redis的可能性。 bigkey优化 拆分big list: list1、list2、…listNbig hash:可以讲数据分段存储，比如一个大的key，假设存了1百万的用户数据，可以拆分成 200个key，每个key下面存放5000个用户数据 如果bigkey不可避免，也要思考一下要不要每次把所有元素都取出来(例如有时候仅仅需要 hmget，而不是hgetall)，删除也是一样，尽量使用优雅的方式来处理。 Redis 连接池 maxTotal最大连接数，早期的版本叫maxActive比如一次命令时间(borrow|return resource + Jedis执行命令(含网络) )的平均耗时约为1ms，一个连接的QPS大约是1000，业务期望的QPS是50000，那么理论上需要的资源池大小是50000 / 1000 = 50个。但事实上这是个理论值，还要考虑到要比理论值预留一些资源，通常来讲maxTotal可以比理论值大一些。 但这个值不是越大越好，一方面连接太多占用客户端和服务端资源，另一方面对于Redis这种高QPS的服务器，一个大命令的阻塞即使设置再大资源池仍然会无济于事。 maxIdlemaxIdle实际上才是业务需要的最大连接数，maxTotal是为了给出余量，所以maxIdle不要设置 过小，否则会有new Jedis(新连接)开销。连接池的最佳性能是maxTotal = maxIdle，这样就避免连接池伸缩带来的性能干扰。但是如果并发量不大或者maxTotal设置过高，会导致不必要的连接资源浪费。一般推荐maxIdle可以设置为按上面的业务期望QPS计算出来的理论连接数，maxTotal可以再放大一倍。 minIdleminIdle(最小空闲连接数)，与其说是最小空闲连接数，不如说是”至少需要保持的空闲连接数”。在使用连接的过程中，如果连接数超过了minIdle，那么继续建立连接，如果超过了 maxIdle，当超过的连接执行完业务后会慢慢被移出连接池释放掉。 如果系统启动完马上就会有很多的请求过来，那么可以给redis连接池做预热，比如快速的创建一 些redis连接，执行简单命令，类似ping()，快速的将连接池里的空闲连接提升到minIdle的数量。","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://tj-ever.github.io/tags/redis/"}]}],"categories":[],"tags":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"https://tj-ever.github.io/tags/rabbitmq/"},{"name":"Zookeeper","slug":"Zookeeper","permalink":"https://tj-ever.github.io/tags/Zookeeper/"},{"name":"MySQL","slug":"MySQL","permalink":"https://tj-ever.github.io/tags/MySQL/"},{"name":"JVM Arthas","slug":"JVM-Arthas","permalink":"https://tj-ever.github.io/tags/JVM-Arthas/"},{"name":"JVM","slug":"JVM","permalink":"https://tj-ever.github.io/tags/JVM/"},{"name":"并发编程","slug":"并发编程","permalink":"https://tj-ever.github.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"hashmap","slug":"hashmap","permalink":"https://tj-ever.github.io/tags/hashmap/"},{"name":"docker","slug":"docker","permalink":"https://tj-ever.github.io/tags/docker/"},{"name":"linux","slug":"linux","permalink":"https://tj-ever.github.io/tags/linux/"},{"name":"oracle","slug":"oracle","permalink":"https://tj-ever.github.io/tags/oracle/"},{"name":"前端","slug":"前端","permalink":"https://tj-ever.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"redis","slug":"redis","permalink":"https://tj-ever.github.io/tags/redis/"},{"name":"环境搭建","slug":"环境搭建","permalink":"https://tj-ever.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"},{"name":"sql","slug":"sql","permalink":"https://tj-ever.github.io/tags/sql/"},{"name":"k8s","slug":"k8s","permalink":"https://tj-ever.github.io/tags/k8s/"}]}